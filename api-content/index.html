{"posts":[{"title":"FFmpeg介绍和使用","content":"FFmpeg介绍和使用 安装FFmpeg 在Mac上通过brew安装FFmpeg brew tap homebrew-ffmpeg/ffmpeg brew options homebrew-ffmpeg/ffmpeg/ffmpeg brew install homebrew-ffmpeg/ffmpeg/ffmpeg --with-chromaprint --with-decklink --with-fdk-aac --with-game-music-emu --with-libbluray --with-libbs2b --with-libcaca --with-libgsm --with-libmodplug --with-librsvg --with-libsoxr --with-libssh --with-libvidstab --with-libvmaf --with-libxml2 --with-opencore-amr --with-openh264 --with-openjpeg --with-openssl --with-openssl@1.1 --with-rav1e --with-rtmpdump --with-rubberband --with-speex --with-srt --with-tesseract --with-two-lame --with-webp --with-xvid --with-zeromq --with-zimg --HEAD 验证是否安装成功 ffmpeg -version 使用FFmpeg 获取视频信息 ffmpeg -i test.mp4 将图片序列合成视频 ffmpeg -f image2 -i image%d.jpg video.mpg 可把当前目录下的图片（名字如：image1.jpg、image2.jpg 等）合并成video.mpg 将视频分解成图片 ffmpeg -i video.mpg image%d.jpg 从视频中抽取声音 视频截图 package main import ( &quot;bytes&quot; &quot;fmt&quot; &quot;io/ioutil&quot; &quot;os/exec&quot; ) func main() { filename := &quot;http://www.xxxxxxx.com/yyyy.mp4&quot; width := 640 height := 360 cmd := exec.Command(&quot;ffmpeg&quot;, &quot;-i&quot;, filename, &quot;-vframes&quot;, &quot;10&quot;, &quot;-s&quot;, fmt.Sprintf(&quot;%dx%d&quot;, width, height), &quot;-f&quot;, &quot;singlejpeg&quot;, &quot;-&quot;) var buffer bytes.Buffer cmd.Stdout = &amp;buffer if cmd.Run() != nil { panic(&quot;could not generate frame&quot;) } ioutil.WriteFile(&quot;./frame.jpg&quot;, []byte(buffer.String()), 0666) } 视频添加图片水印 ffmpeg -i input.mp4 -vf &quot;movie=水印图片.png[watermark];[in][watermark] overlay=main_w-overlay_w-10:main_h-overlay_h-10[out] &quot; output.mp4 -i：表示输入 -vf：滤镜相关，视频裁剪，水印等等操作都需要它完成 overlay：水印参数 main_w-overlay_w-10：水印在x轴的位置，也可以写成x=main_w-overlay_w-10 main_h-overlay_h-10：水印在y轴的位置 或者也可以使用命令 ffmpeg -i input.mp4 -i logo.png -filter_complex 'overlay=main_w-overlay_w-10:main_h-overlay_h-10' output.mp4 视频添加文字水印 ffmpeg -i input.mp4 -vf &quot;drawtext=fontfile=simhei.ttf: text='abc-watermark':x=10:y=10:fontsize=24:fontcolor=white:shadowy=2&quot; output.mp4 在视频左上角添加一条白色字体的文字水印 ","link":"https://ninglg.com/post/ffmpeg-intro-and-usage/"},{"title":"年度目标","content":" 努力工作，认真生活 2022 有目标，有方向，有动力。 持续学习，深入思考，拥抱变化，及时行动。 目标达成 = 制定目标 + 详细计划 + 坚持执行 + 及时修正。 2021 方向 目标 是否完成 读书 读10本书 Doing 源码学习 2个知名项目的源码 Doing 写博客 完成10篇博客文章 Doing 技术全栈化 APP(Flutter)/FE(Vue.js)/Backend(语言、中间件、基础架构) Doing 健身 锻体修真😝 Doing 好习惯 把更多的时间用于学习和创造 增加阅读量 更多的了解经济学原理 努力工作 创造多种收入来源 ","link":"https://ninglg.com/post/annual-goals/"},{"title":"阅读书单","content":"2023 类别 书名 文学 《一只特立独行的猪》 技术 《Netty实战》 文学 《有些事根本不配占有你的情绪》 社会｜《重口味心理学》 2022 类别 书名 经济 《贫穷的本质：我们为什么摆脱不了贫穷（修订版）》 社会 《出身：不平等的选拔与精英的自我复制》 管理 《冯唐成事心法》 历史 《一看就停不下来的中国史》 技术 《Head First Java》 技术 《Spring MVC学习指南》 技术 《Spring Boot实战》 政治 《民主的细节：美国当代政治观察随笔》 2021 类别 书名 传记 《硅谷钢铁侠：埃隆·马斯克的冒险人生》 商业 《一往无前：雷军亲述小米热血10年》 专著 《Model Y 用户手册》 文献 《安全驾驶交通规范》 技术 《自适应学习：人工智能时代的教育革命》 商业 《重来：更为简单有效的商业思维》 技术 《Go语言高并发与微服务实战》 技术 《gRPC与云原生应用开发》 技术 《etcd技术内幕》 技术 《Flutter 从0基础到App上线》 2020 类别 书名 技术 《Kafka权威指南》 技术 《Elasticsearch实战》 社会 《关于性、金钱、天才和背叛》 经管 《成为技术领导者：掌握全面解决问题的方法》 文学 《红楼梦》小学生美绘本 文学 《水浒传》小学生美绘本 文学 《西游记》小学生美绘本 文学 《三国演义》小学生美绘本 经管 《原则》 技术 《计算机科学精粹》 技术 《Flutter从0基础到App上线》 经管 《10人以下小团队管理手册》 技术 《图解HTTP》 2019 类别 书名 育儿 《年糕妈妈辅食日志》 育儿 《新生儿婴儿幼儿护理大百科》 经济 《半小时漫画经济学：生活常识篇+经济危机篇(1-2)》 商业 《重新理解创业》 社会 《来到地球第一天》 小说 《庆余年》 地理 《极致之美》 励志 《靠自己去成功》 经管 《创业时，我们在知乎聊什么？》 ","link":"https://ninglg.com/post/book-reading-list/"},{"title":"Flutter Dart面向对象","content":"Flutter Dart面向对象 ","link":"https://ninglg.com/post/dart-object/"},{"title":"Flutter Dart语言基础","content":"此篇介绍一下Dart语言的基础知识 说明 Dart是Fuchsia操作系统的官方开发语言 Dart是一门强类型语言，但同时仍然支持弱类型语言的某些特性 Dart有自己的VM，可以像Java语言一样运行在虚拟机上，又可以被编译成Native Code直接运行在硬件上（比如Flutter） 在Dart中，一切皆是对象，一切数据类型均继承自Object，即使是一个整数或方法，甚至null Dart可以推断变量的类型，除非开发者明确表示某个变量不被指定为任何一种类型。建议使用静态类型，这样可以增强代码可读性，也方便代码分析。 没有指定类型的变量将会默认指定为dynamic类型 Dart可以应用于前后端。比如可以开发客户端Web应用（Angular 2框架），同时也可以运行在服务端（借助DartVM） 作为库，可能包含一个或多个*.dart文件 在大多数情况下，所有的变量、方法和类等对外均可见，除非它们以“_”开头 Dart提供两种运行模式：Production和Checked。默认情况下以Production方式运行，优先考虑性能，关闭类型检查和断言；而Checked模式更利于在开发阶段调试使用 Dart支持顶级方法和顶级变量 Dart代码分析工具可以指出警告和错误，错误分为编译错误和运行错误，编译错误会直接阻止代码运行，运行错误会在运行时抛出异常 代码简单示例 main(List&lt;String&gt; args) { print(&quot;Hello Dart!&quot;); } 变量 变量的初始化方法 var name = &quot;XiaoWang&quot; print(name) 当然也可以使用String或dynamic类型，而不是用var类对name进行声明。 对于局部变量，根据代码建议风格来说，优先建议使用var来声明变量。 未经初始化的变量的默认值为null 常量 在Dart语言中，可以使用final或const关键字来声明一个常量 final weight = 60.5 final int height = 180 const int age = 17 const gender = &quot;male&quot; const声明的常量是一种编译时常量。const关键字也可以用来创建不变的值，甚至定义构造函数为const类型，即不可变对象，且任意变量都可以有一个不变的值。 // 使用const创建常量值 var intList = const[]; intList = [1, 2, 3]; 虽然intList的值为常量不可变，但由于其本身声明使用了var，因此它仍然可以改变其引用。相当于： // 使用const创建常量值 const temp = []; var intList_2 = temp; intList_2 = [1, 2, 3]; 基本数据类型 Dart的数值包含Int和Double两种类型。声明Double类型的变量，如果值是一个整数，则会自动转换成Double类型。 字符串有单引号字符串和双引号字符串。有转义符，另外可以用加号连接字符串。还有三个单引号或双引号，可以保持大段文本的原格式。 var userName = &quot;小刚&quot;; final welcome = &quot;$userName，欢迎使用&quot;; print(welcome); 类型转换 // String转换为int String s = &quot;1000&quot;; int i = int.parse(s); // int转换为String int i = 1000; String s = i.toString(); // 指定位数，输出3.14 print(3.14159.toStringAsFixed(2)); Dart提供三种核心集合类型： （1）列表List var listExp = [1, &quot;Hello&quot;, 3.14] // 列表中的元素可以混合不同类型 print(listExp.length) print(&quot;长度为：&quot; + listExp.length.toString()) （2）集合Set var setExp = {'A', 'B', 'C', 1, 2, 3} // 集合提供add()、remove()、contains()、clear()等方法 setExp.add('D') setExp.remove('C') print(setExp.contains(3)) setExp.clear() // 另外还有一次性追加多个二元素的addAll()方法，以及removeAll()方法和containsAll()方法。 // 集合运算操作，有difference()、union()、intersection()等。 （3）映射Map var mapExp = { &quot;a&quot; : &quot;aaa&quot;, &quot;b&quot; : &quot;bbb&quot;, }; // 提供remove()方法和containsKey()判断，提供length()长度。 Dart中的字符串是UTF-16编码的，对于超过的情况需要接入Runes类型。 只有一个表达式的方法，可以简单写法成： int getInt() =&gt; 2 * getNumber(); // 这里=&gt;等同于return，称为箭头语法 参数：必选参数和可选参数 （1）在参数列表中，必选参数在最前面，可选参数随后。 （2）参数在方法体中的引用方式需要使用$。 （3）在Dart中，可选参数分为可选命名参数和基于位置的参数，二者是互斥关系，不能同时出现。 // 可选命名参数示例：大括号 int getPrice({bookName : &quot;一般图书&quot;}) { if (bookName == &quot;热门图书&quot;) { return 50; } else { return 10; } } // 可选位置参数示例：中括号 String sayWelcome([String name = &quot;你好&quot;]) { return &quot;$name，欢迎使用&quot;; } 主方法main方法返回void（即无返回值），有一个可选的参数List。 检查两个方法是否相等，使用连等号（==）来判断。 在Dart中，如果一个方法没有声明返回类型和return语句，则默认为return null。 在Dart中，做除法无法整除时，会返回小数。如果只想要整数部分，可以使用“~/”。 print(9 ~/2); 如果两个对象均返回null，即使其类型不同，但其值相同，也是相等的。 类型判定运算符 (1) as 类型转换 (2) is 是指定类型 (3) is! 非指定类型 级联运算符 (1) 本质是一个特殊语法 (2) 写法是两个点，用于在同一对象上的连续调用 示例如： // 原始写法 Point pExp = new Point(); pExp.setX(10); pExp.setY(20); pExp.setZ(30); print(pExp.toString()); // 级联写法 print(new Point()..setX(10)..setY(20)..setZ(30)..toString()) 条件成员访问运算符 ?. 如果左边的对象不是null，则返回右边的值；反之则返回null 断言只在开发模式下起作用，在生产环境中无效。断言可以检查程序中某些可能出现的运行逻辑错误。 var intValue = 1000; assert(intValue == 999); // 开发环境中看到控制台报错，在生产环境中不会收到提示 异常 (1) Dart语言提供了 Exception 和 Error 两类异常。还有它们的子类，还可以自定义异常类型，其中自定义的异常类型不能为空值。 throw new FormatException(&quot;Data format exception occurred&quot;); // 抛出一个自定义的异常 throw 'custom exception'; (2) 在实际生产环境中，自定义异常通常的做法是写一个类，声明Error或Exception类中的方法。 Catch try { // xxxxx } catch (e) { print(e.toString()); // yyyyy } // 捕捉不同的多种类型异常 try { } on RangeError { } on FormatError { } catch(e) { } // 再次抛出异常使用rethrow try { } on RangeError { // xxxxx rethrow; } catch (e) { } Finally try { } catch (e) { } finally { print(&quot;done&quot;); } ","link":"https://ninglg.com/post/dart-start/"},{"title":"Flutter开发环境","content":"此篇介绍初期学习Flutter的一些知识。 环境安装 由于国内访问限制，首先需要设置Flutter镜像环境变量（解决被墙导致的失败问题） export PUB_HOSTED_URL=https://pub.flutter-io.cn export FLUTTER_STORAGE_BASE_URL=https://storage.flutter-io.cn 下载Flutter SDK git clone -b stable https://github.com/flutter/flutter.git 并将Flutter的Bin目录加入到PATH中 export PATH=pwd/flutter/bin:$PATH 运行 flutter doctor 命令检查环境是否已正确配置，如有错误需逐项解决 macOS 可以允许开发 iOS、Android 和 Web（技术预览版正式发布）三个平台的 Flutter 应用 要为Android开发Flutter应用，需要在电脑上安装和配置Android Studio，并在手机设备上启用“开发人员选项”和“USB调试”。或者使用Visual Studio Code，并安装flutter插件使用 如使用VSCode，“查看”——“命令面板”——“Flutter：New Project”创建新的Flutter项目，使用“调试”——“启动调试”可以传输包到模拟器上，并显示效果，修改后还可以使用热重载观看修改后的效果 示例代码 第一个Flutter应用的代码：startup_name_generator import 'package:flutter/material.dart'; import 'package:english_words/english_words.dart'; void main() =&gt; runApp(new MyApp()); class MyApp extends StatelessWidget { @override Widget build(BuildContext context) { return new MaterialApp( title: 'Startup Name Generator', theme: new ThemeData( primaryColor: Colors.white, ), home: new RandomWords(), ); } } class RandomWords extends StatefulWidget { @override createState() =&gt; new RandomWordsState(); } class RandomWordsState extends State&lt;RandomWords&gt; { final _suggestions = &lt;WordPair&gt;[]; final _saved = new Set&lt;WordPair&gt;(); final _biggerFont = const TextStyle(fontSize: 18.0); @override Widget build(BuildContext context) { return new Scaffold( appBar: new AppBar( title: new Text('Startup Name Generator'), actions: &lt;Widget&gt;[ new IconButton(icon: new Icon(Icons.list), onPressed: _pushSaved) ], ), body: _buildSuggestions(), ); } Widget _buildSuggestions() { return new ListView.builder( padding: const EdgeInsets.all(16.0), itemBuilder: (context, i) { if (i.isOdd) return new Divider(); final index = i ~/ 2; if (index &gt;= _suggestions.length) { _suggestions.addAll(generateWordPairs().take(10)); } return _buildRow(_suggestions[index]); }, ); } Widget _buildRow(WordPair pair) { final alreadySaved = _saved.contains(pair); return new ListTile( title: new Text( pair.asPascalCase, style: _biggerFont, ), trailing: new Icon( alreadySaved ? Icons.favorite : Icons.favorite_border, color: alreadySaved ? Colors.red : null, ), onTap: () { setState( () { if (alreadySaved) { _saved.remove(pair); } else { _saved.add(pair); } }, ); }, ); } void _pushSaved() { Navigator.of(context).push( new MaterialPageRoute( builder: (context) { final tiles = _saved.map( (pair) { return new ListTile( title: new Text( pair.asPascalCase, style: _biggerFont, ), ); }, ); final divided = ListTile .divideTiles( context: context, tiles: tiles, ) .toList(); return new Scaffold( appBar: new AppBar( title: new Text('Saved Suggestions'), ), body: new ListView(children: divided), ); }, ), ); } } 简单命令 flutter create myapp //创建Flutter工程 flutter devices //查看运行的设备 flutter run //运行应用程序 flutter build ios --debug //iOS debug模式打包 flutter build ios --release //iOS release模式打包(release包不能在模拟器上正常运行) flutter channel //查看当前channel flutter channel beta //切换到beta channel flutter upgrade //升级 将项目运行在模拟器上 注意Project name必须以小写字母开头，而且不可以有空格。 Flutter的热修复特性 Flutter具有热修复（在某些情况下称之为热重载）特性。所谓热修复，是指无需重新启动App，即可快速的将修改后的源代码文件注入正在运行的Dart虚拟机中，而Dart虚拟机会立即套用修改后的代码。 Flutter框架会自动重新构建组件树实现热修复。 有几种情况下无法执行热修复： （1）代码编译错误 （2）修改后的代码影响了修改前的状态（即数据） （3）对于静态字段如final修饰的常量值，在修改后不会变化，仍未修改前的值 （4）对于UI组件，如果修改后的代码不会因为重新构建Widget组件树而被重新执行的话，热修复就对其不起作用，并且不会抛出任何异常 （5）枚举类型更改为常规类，或常规类更改为枚举类型，都会导致热修复失败 （6）更改泛型类型声明会导致热修复失败 升级Flutter 1、升级Flutter SDK可以执行命令 flutter upgrade 命令会获取最新稳定版本，并在升级后自动执行flutter doctor命令来检查环境配置 升级依赖库 App可能会依赖多个库，这些库在pubspec.yaml文件中被列出。如果要获取依赖库，需要执行命令： flutter packages get 如果想升级依赖库到最新版本，需要执行命令： flutter packages upgrade 命令行编译包 生成Android平台App包： flutter build apk 生成iOS平台App包： flutter build ios 显示可用设备（已连接到开发计算机） flutter devices 在devices列表中的第一个设备上编译并以调试模式（默认模式）运行 flutter run 或者指定特定设备ID flutter run -d 000507e0a52252f43eaa151dcbc4ebfa52bd92f0 在chrome上运行 flutter run -d chrome ","link":"https://ninglg.com/post/flutter-start/"},{"title":"Flutter简介","content":"Flutter简介 Flutter支持Android/iOS App开发，也支持Fuchsia平台的开发 应用产品实例如闲鱼、京东金融等 Flutter也可以应用于Google新的操作系统Fuchsia开发 使用Flutter需要掌握其本身常用的API，并且掌握一门新的语言Dart Flutter自身具有热修复（热重载）的功能，不过有使用上的限制 Flutter SDK支持修复崩溃和继续从应用程序停止的地方进行调试 达到原生性能，Flutter提供了一种响应式视图，无需JavaScript做桥接 高性能的渲染机制使得120FPS（frames per second，帧每秒）的高帧率可以轻易实现 当界面上的图片越多时，与React Native相比，Flutter的优势会越来越明显 灵活的跨平台开发，Flutter可以单独作为开发框架完成整个App的开发，也可以与现有原生代码相结合实现Hybrid混合模式的开发 Flutter可以访问本地功能和SDK Flutter保持了不同平台的UI设计理念，如对于iOS平台使用Cupertino风格，对于Android平台使用Material Design风格 Flutter是一个分级结构框架，自上而下依次是： （1）Framework（框架层）：使用Dart实现，包含了所有和UI相关的组件、动画、手势等 （2）Engine（引擎层）：使用C/C++实现，主要涵盖了Skia、Dart和Text。其中Skia是开源的图形库，提供适用于多种软硬件平台的API，Dart层包含了在Dart运行时的垃圾收集、JIT编译（Just In Time动态即时编译，用于Debug模式）、AOT编译（Ahead Of Time静态提前编译，用于Release/Profile模式），Text负责文本渲染 （3）Embedder（嵌入层）：能确保各平台的兼容性 其中App都是基于Framework开发并运行在Engine层上的 Flutter内部的渲染机制是整个Flutter跨平台技术的核心。它直接使用Skia引擎来渲染每个组件，既摆脱了对浏览器的束缚，又摆脱了和平台密切相关的原生控件 由于Flutter对Android/iOS都是采用AOT编译的方式，因此确保了使用Flutter开发技术的App都能够使用本机指令集运行。这一设计既满足了所谓统一的应用开发体验，又确保了App的运行性能 UI设计风格都使用了Widget层的控件，只不过是做了很多的搭配组合，Widget层也依赖Rendering层来构建。如果其中某一层无法满足项目需求，也可以使用下一层的能力来自定义。如此灵活的层级结构满足了多种需求 ","link":"https://ninglg.com/post/flutter-intro/"},{"title":"疯狂HTML5讲义","content":"疯狂HTML5讲义 第1章 HTML5简介 使用autofocus自动获取焦点 &lt;body&gt; &lt;input type=&quot;text&quot; autofocus name=price/&gt; &lt;/body&gt; 为页面布局提供更明确的语义元素 &lt;header&gt;...&lt;/header&gt; &lt;nav&gt;...&lt;/nav&gt; &lt;article&gt; &lt;section&gt; &lt;/section&gt; &lt;/article&gt; &lt;footer&gt;...&lt;/footer&gt; 支持语义的强调元素 &lt;time&gt;2012-12-12&lt;/time&gt; &lt;mark&gt;重点标记文本&lt;/mark&gt; DTD的全称是Document Type Defination，即文档类型定义。HTML5是“妥协式”的规范，照顾了大量不规范的HTML页面，并不需要严格意义上的DTD。 HTML5对元素大小写不再严格区分，开发者可以随意使用大小写字符来定义HTML元素。对于一份基本的HTML5文档，总有如下结构： &lt;!DOCTYPE html&gt; &lt;html&gt; &lt;head&gt; &lt;title&gt;页面标题&lt;/title&gt; &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=gb2312&quot; /&gt; &lt;!-- 可继续插入其它meta、样式表等信息 --&gt; &lt;/head&gt; &lt;body&gt; 页面内容 &lt;/body&gt; &lt;/html&gt; HTML5支持两种方式来指定页面的字符集： 使用 Content-Type 指定页面所用的字符集，如 &lt;meta http-equiv=&quot;Content-Type&quot; content=&quot;text/html; charset=gb2312&quot; /&gt; 或者，直接使用 charset 指定页面所用的字符集，如 &lt;meta charset=&quot;gb2312&quot;&gt; 不要在和之间插入任何内容，也不要在和之间，或者和之间插入任何内容。 HTML5的标签不再区分大小写，即使开始标签和结束标签分别使用不同的大小写也符合HTML5规范。 W3C提供了一个在线验证页面 http://validator.w3.org 来验证一份HTML页面是否符合规范。 HTML5允许部分HTML元素生态略结束标签，甚至允许HTML元素同时省略开始标签和结束标签。HTML5中的省略标签可以分为如下3种： （1）空元素语法的元素 area、base、br、col、command、embed、hr、img、input、keygen、link、meta、param、source、wbr （2）可以省略结束标签的元素 colgroup、dt、dd、li、optgroup、option、p、rt、rp、thread、tbody、tfoot、tr、td、t （3）可以省略全部标签的元素 html、head、body、tbody HTML5允许部分“标志性”的属性可以省略属性值 checked、readonly、disabled、selected、defer、ismap、nohref、noshade、nowrap、multiple、noresize HTML5允许属性值不使用引号 &lt;img src=a.gif alt=test&gt; 第2章 HTML5的常用元素与属性 HTML5推荐使用CSS样式单来控制HTML文档样式； HTML5新增的拖放API可以让HTML页面的任意元素都变成可拖动的； h1到h6定义标题一到标题六； 几乎所有的HTML元素 ","link":"https://ninglg.com/post/crazy-html5-note/"},{"title":"B+树和LSM树","content":"介绍一下B+树和LSM树。 无论何种存储介质，顺序读写性能都远高于随机读写性能。 文件索引和数据库索引 大部分用B+树，少部分用B树。 哈希表虽然能够在 O(1) 查找到目标数据，但要进行模糊查找的话，却只能遍历所有数据。另外如果出现了极端情况，哈希表冲突的元素太多，也会导致线性时间的查找效率的。 二叉查找树虽然也很快，但由于文件索引是存放在磁盘上的，所以不仅要考虑查找效率，还要考虑磁盘的寻址加载次数。 B+ B树相当于是一棵多叉查找树。 实际上磁盘的加载次数，基本上是和树的高度相关联的。高度越高，加载次数越多，高度越矮，加载次数越少。所以对于文件索引的存储，一般会选择矮胖的树形结构。 LSM LSM Tree的最早概念，诞生于1996年google的“BigTable”论文。 要提高读写性能，思路是在落盘的数据是顺序写入的同时，还保证这些数据是有序的。这就需要利用内存访问速度比硬盘快的原理，将写入的请求先在内存中缓存起来，按一定的有序结构进行组织，达到一定量后再写入硬盘，从而使得硬盘顺序写入了有序的数据。 在写入时要先写一份log，防止断电时便于进行数据恢复。 写入数据的内存缓存，MemTable中存储的是有序的数据。这里不同的实现可能不相同，LevelDB使用的是SkipList有序结构，Hbase使用的是B Tree有序结构。 MemTable中的数据随时在增加，当其增加到一定量后将其变为不可变数据（ImmutableMemTable）。新生成一份MemTable用于后续的数据写入。ImmutableMemTable中的数据，将被写入到硬盘中的SSTable。 SSTable 全称Sorted String Table，实际上就是被写入数据的有序存储文件。 数据读取的大致流程：从MemTable中查找——从ImmutableMemTable中查找——从最新的SSTable中查找——从剩下的最新的SSTable中继续查找。其中还用到了布隆表达式来提高查找效率。 为了保证数据的顺序写，所有SSTable都不会因为删除和更新而在原数据所在位置进行更改。在更新时，是插入一个最新的值去写到新的SSTable中。在删除时，是插入一个基于该Key的删除标记，写入最新的SSTable中。由于查找某个Key是基于时间新鲜度，反向依次查找SSTable，所以读取某个Key始终读的是最新的值。 随着日积月累，SSTable的文件数会增多，导致查找时性能下降。同时由于数据的更新或删除，老的SSTable中数据的有效性逐渐降低，太多的过期数据会占用SSTable，同样会降低查询效率。所以一般数据库引擎，都会有一个SSTable的定期合并操作。移除过时数据，将多个小SSTable合并成大的SSTable。 在大内存的条件下，部分数据库还会将最近读取的SSTable索引缓存至内存中，进一步加速查找的过程。 采用 LSM Tree 作为存储结构的数据库有：Google的LevelDB，Facebook的RockDB（RockDB来源于LevelDB），Cassandra，HBase等。 ","link":"https://ninglg.com/post/b-tree-and-lsm-tree/"},{"title":"《Elasticsearch实战》阅读笔记","content":"《Elasticsearch实战》阅读笔记 第1章 Elasticsearch介绍 第2章 深入功能 第3章 索引、更新和删除数据 第4章 搜索数据 第5章 分析数据 第6章 使用相关性进行搜索 第7章 使用聚集来探索数据 第8章 文档间的关系 第9章 向外扩展 第10章 提升性能 第11章 管理集群 ","link":"https://ninglg.com/post/elasticsearch-in-action-note/"},{"title":"《Kafka权威指南》阅读笔记","content":"《Kafka权威指南》阅读笔记 序 Kafka 是一个流平台：在这个平台上可以发布和订阅数据流，并把它们保存起来进行处理。 Kafka经常会被拿来与现有的技术作比较：企业级消息系统、大数据系统（如Hadoop）和数据集成或ETL工具。这里的每一项比较都有一定的道理，但也有失偏颇。 作为一个现代的分布式系统，Kafka 以集群的方式运行，Kafka 集群并不是一组独立运行的broker，它可以自由伸缩，处理公司的所有应用程序的数据流。其次，Kafka 可以按照你的要求存储数据，保留多长时间完全可以由你来决定。作为数据连接层，Kafka 提供了数据传递保证——可复制、持久化。 Kafka 可以看做是实时版的Hadoop。Hadoop可以存储和定期处理大量的数据文件，而 Kafka 可以存储和持续的处理大型的数据流。Hadoop 和大数据主要应用在数据分析上，而 Kafka 因其低延迟的特点更适合用在核心的业务应用上。 Kafka 和 ETL 工具都擅长移动数据，不过 Kafka 并非只是把数据从一个系统拆解出来再塞进另一个系统，它还可以将现有的应用程序和数据系统连接起来，加强这些触发相同数据流的应用，这是以数据流为中心的架构。 除了3、4、5的不同点之外，对于那些习惯了开发请求与响应风格应用和关系型数据库的人来说，学会基于持续数据流构建应用程序也是一个巨大的思维转变。 前言 Kafka 的一些典型应用场景：用于事件驱动的微服务系统的消息总线、流式应用和大规模数据管道。 第1章 初识 Kafka 花费越少的精力在数据移动上，就越能专注于核心业务。这就是为什么在一个以数据为驱动的企业里，数据管道会成为关键性组件。如何移动数据，几乎变得与数据本身一样重要。 发布与订阅消息系统：发布与订阅系统一般会有一个 broker，也就是发布消息的中心点。 业务中有很多的场景需要用到消息系统。此时，你真正需要的是一个单一的集中式系统，它可以用来发布通用类型的数据，其规模可以随着公司业务的增长而增长。 Kafka 是一款基于发布与订阅的消息系统。它一般被称为 “分布式提交日志”或者“分布式流平台”。Kafka 的数据是按照一定顺序持久化保存的，可以按需读取。此外，Kafka 的数据分布在整个系统里，具备数据故障保护和性能伸缩能力。 消息和批次 Kafka 的数据单元被称为消息。消息由字节数组组成，所以 对于 Kafka 来说，消息里的数据没有特别的格式或含义。消息可以有一个可选的元数据， 也就是键。键也是一个字节数组，与消息一样，对于 Kafka 来说也没有特殊的含义。当消息以一种可控的方式写入不同的分区时，会用到键。最简单的例子就是为键生成一个一致性散列值，然后使用散列值对主题分区数进行取模，为消息选取分区。这样可以保证具有相同键的消息总是被写到相同的分区上。 为了提高效率，消息被分批次写入 Kafka。批次就是一组消息，这些消息属于同一个主题和分区。把消息分成批次传输可以减少网络开销。不过，这要在时间延迟和吞吐量之间作出权衡。 模式 消息模式（schema）有许多可用的选项。像 JSON 和 XML 这些简单的系统，不仅易用，而且可读性好。不过，它们缺乏强类型处理能力，不同版本之间的兼容性也不是很好。Kafka 的许多开发者喜欢使用 Apache Avro，它最初是为 Hadoop 开发的一款序列化框架。Avro 提供了一种紧凑的序列化格式，模式和消息体是分开的，当模式发生变化时，不需要重新生成代码；它还支持强类型和模式进化，其版本既向前兼容，也向后兼容。 数据格式的一致性对于 Kafka 来说很重要，它消除了消息读写操作之间的耦合性。 主题和分区 Kafka 的消息通过主题（Topic）进行分类。一个主题可以被分为若干个分区，消息以追加的方式写入分区，然后以先入先出的顺序读取。要注意，由于一个主题一般包含几个分区，因此无法在整个主题范围内保证消息的顺序，但可以保证消息在单个分区内的顺序。 Kafka 通过分区来实现数据冗余和伸缩性。分区可以分布在不同的服务器上，也就是说，一个主题可以横跨多个服务器，以此来提供比单个服务器更强大的性能。 生产者和消费者：Kafka 的客户端被分为两种基本类型：生产者和消费者。除此之外，还有其它高级客户端 API——用于数据集成的 Kafka Connect API 和用于流式处理 的 Kafka Streams。这些高级客户端 API 使用生产者和消费者作为内部组件，提供了高级的功能。 生产者创建消息。一般情况下，一个消息会被发布到一个特定的主题上。生产者在默认情况下把消息均衡地分布到主题的所有分区上，而并不关心特定消息会被写到哪个分区。 不过，在某些情况下，生产者会把消息直接写到指定的分区。这通常是通过消息键和分区器来实现的，分区器为键生成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到同一个分区上。生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。 消费者读取消息。消费者订阅一个或多个主题，并按照消息生成的顺序读取它们。消费者通过检查消息的偏移量来区分已经读取过的消息。偏移量是另一种元数据，它是一个不断递增的整数值，在创建消息时，Kafka 会把它添加到消息里。在给定的分区里，每个消息的偏移量都是唯一的。消费者把每个分区最后读取的消息偏移量保存在 Zookeeper 或 Kafka 上，如果消费者关闭或重启，它的读取状态不会丢失。 消费者是消费者群组（Group）的一部分，也就是说，会有一个或多个消费者共同读取一个主题。群组保证每个分区只能被一个消费者使用。如果一个消费者失效，群组里的其他消费者可以接管失效消费者的工作。 broker和集群 一个独立的 Kafka 服务器被称为 broker。broker 接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。 根据特定的硬件及其性能特征，单个 broker 可以轻松处理数千个分区以及每秒百万级的消息量。 broker 是集群的组成部分。每个集群都有一个 broker 同时充当了集群控制器的角色。 一个分区可以分配给多个 broker，这个时候会发生分区复制。这种复制机制为分区提供了消息冗余。 保留消息 保留消息（在一定期限内）是 Kafka 的一个重要特性。Kafka broker 默认的消息保留策略是这样的:要么保留一段时间（比如 7 天），要么保留到消息达到一定大小的字节数（比 如 1GB）。当消息数量达到这些上限时，旧消息就会过期并被删除。所以在任何时刻，可用消息的总量都不会超过配置参数所指定的大小。 Topic可以配置自己的保留策略，可以将消息保留到不再使用它们为止。 可以通过配置把Topic当作紧凑型日志，只有最后一个带有特定键的消息会被保留下来。这种情况对于变更日志类型的数据来说比较适用，因为人们只关心最后时刻发生的那个变更。 多集群 Kafka 的消息复制机制只能在单个集群里进行，不能在多个集群之间进行。 Kafka 提供了一个叫作 MirrorMaker 的工具，可以用它来实现集群间的消息复制。 MirrorMaker 的核心组件包含了一个生产者和一个消费者，两者之间通过一个队列相连。消费者从一个集群读取消息，生产者把消息发送到另一个集群上。 为什么选择Kafka 多个生产者 多个消费者 基于磁盘的数据存储 伸缩性 高性能 数据生态系统 使用场景 活动跟踪 传递消息 度量指标和日志记录 提交日志 流处理 起源故事 Kafka 使用 Avro 作为消息序列化框架，每天高效地处理数十亿级别的度量指标和用户活动跟踪信息。 第2章 安装Kafka 安装 Kafka 所需环境 建议在Linux平台上先后安装Java8、Zookeeper、Kafka。 Kafka 使用 Zookeeper 保存集群的元数据信息和消费者信息。 Kafka 发行版也自带了Zookeeper，可以直接从脚本启动。 可以连到 Zookeeper 端口上，通过发送命令 srvr 来验证 Zookeeper 是否安装正确： # telnet localhost 2181 srvr Zookeeper 使用的是一致性协议，所以建议每个群组里应该包含奇数个节点（比如 3 个、5 个等），因为只有当群组里的大多数节点（也就是法定人数)）处于可用状态，Zookeeper 才能处理外部的请求。即如果你有一个包含 3 个节点 的群组，那么它允许1个节点失效。如果群组包含 5 个节点，那么它允许 2 个节点失效。 不过，也不建议一个群组包含超过 7 个节点，因为 Zookeeper 使用了一致性协议，节点过多会降低整个群组的性能。 验证安装结果 一旦 Kafka 创建完毕，就可以对这个集群做一些简单的操作来验证它是否安装正确，比如创建一个测试主题，发布一些消息，然后读取它们。 创建并验证主题： # /usr/local/kafka/bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test Created topic &quot;test&quot;. # /usr/local/kafka/bin/kafka-topics.sh --zookeeper localhost:2181 --describe --topic test Topic:test PartitionCount:1 ReplicationFactor:1 Configs: Topic: test Partition: 0 Leader: 0 Replicas: 0 Isr: 0 # 往测试主题上发布消息： # /usr/local/kafka/bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test Test Message 1 Test Message 2 ^D # 从测试主题上读取消息： # /usr/local/kafka/bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning Test Message 1 Test Message 2 ^C Consumed 2 messages # 配置 Zookeeper监听 2181 端口。 Kafka监听 9092 端口。 单个broker对分区个数是有限制的，因为分区越多，占用的内存就越多，完成Leader选举需要的时间也越长。 估算出Topic的吞吐量和消费者吞吐量，可以用主题吞吐量除以消费者吞吐量算出分区的个数。如果不知道这些信息，那么根据经验，把分区的大小限制在 25GB 以内可以得到比较理想的效果。 Kafka 通常根据时间来决定数据可以被保留多久。另一种方式是通过保留的消息字节数来判断消息是否过期。如果同时指定了这两个条件，那只要任意一个条件得到满足，消息就会被删除。 一个生产者可以写往一个主题的多个分区，一个消费者可以消费一个主题的多个分区。 建议使用最新版本的 Kafka，让消费者把偏移量提交到 Kafka 服务器上，消除对 Zookeeper 的依赖。 虽然多个 Kafka 集群可以共享一个 Zookeeper 群组，但如果有可能的话，不建议把 Zookeeper 共享给其他应用程序。Kafka 对 Zookeeper 的延迟和超时比较敏感，与 Zookeeper 群组之间的一个通信异常就可能导致 Kafka 服务器出现无法预测的行为。 第3章 Kafka生产者——向Kafka写入数据 客户端 除了内置的客户端外，Kafka 还提供了二进制连接协议，也就是说，我们直接向 Kafka 网络端口发送适当的字节序列，就可以实现从 Kafka 读取消息或 往 Kafka 写入消息。 生产者概览 发送消息的3种方式 发送并忘记（fire-and-forget） 同步发送 异步发送 KafkaProducer一般会发生两类错误 可重试错误 这类错误可以通过重发消息来解决，比如对于连接错误，可以通过再次建立连接来解决。 无法通过重试解决 比如“消息太大”异常。 异步发送消息 在大多数时候，我们并不需要等待响应——尽管 Kafka 会把目标主题、分区信息和消息的偏移量发送回来，但对于发送端的应用程序来说不是必需的。 但是，在遇到消息发送失败时，我们需要抛出异常、记录错误日志，或者把消息写入 “错误消息”文件以便日后分析。 为了在异步发送消息的同时能够对异常情况进行处理，生产者提供了回调支持。 序列化器 如果同一个公司的不同团队都需要往 Kafka 写入某一类数据，那么他们就需要使用相同的序列化器，如果序列化器发生改动，他们几乎要在同一时间修改代码。 我们不建议使用自定义序列化器，而是使用已有的序列化器和反序列化器，比如 Json、Avro、Thrift 或 Protobuf。 分区 ProducerRecord 对象包含了目标主题、键和值。Kafka 的消息是一个个的键值对，ProducerRecord 对象可以只包含目标主题和值，键可以设置为默认的 null，不过大多数应用程序会用到键。 键有两个用途：可以作为消息的附加信息，也可以用来决定消息该被写到主题的哪个分区。拥有相同键的消息将被写到同一个分区。 如果键值为 null，并且使用了默认的分区器，那么记录将被随机地发送到主题内各个可用的分区上。 分区器使用轮询（Round Robin）算法将消息均衡地分布到各个分区上。 如果键不为空，并且使用了默认的分区器，那么 Kafka 会对键进行散列（使用 Kafka 自己的散列算法，即使升级 Java 版本，散列值也不会发生变化），然后根据散列值把消息映射到特定的分区上。这里的关键之处在于，同一个键总是被映射到同一个分区上，所以在进行映射时，我们会使用主题所有的分区，而不仅仅是可用的分区。这也意味着，如果写入数据的分区是不可用的，那么就会发生错误。但这种情况很少发生。 只有在不改变主题分区数量的情况下，键与分区之间的映射才能保持不变。 如果要使用键来映射分区，那么最好在创建主题的时候就把分区规划好，而且永远不要增加新分区。 第4章：Kafka消费者——从Kafka读取数据 KafkaConsumer概念 应用程序使用 KafkaConsumer 向 Kafka 订阅主题，并从订阅的主题上接收消息。 消费者和消费者群组 Kafka 消费者从属于消费者群组。一个群组里的消费者订阅的是同一个主题，每个消费者接收主题一部分分区的消息。 如果群组里的消费者数量，超过了主题的分区数量，那么有一部分消费者就会被闲置，不会接收到任何消息。 往群组里增加消费者是横向伸缩消费能力的主要方式。Kafka 消费者经常会做一些高延迟的操作，比如把数据写到数据库或 HDFS，或者使用数据进行比较耗时的计算。在这些情况下，单个消费者无法跟上数据生成的速度，所以可以增加更多的消费者，让它们分担负载，每个消费者只处理部分分区的消息，这就是横向伸缩的主要手段。 我们有必要为主题创建大量的分区，在负载增长时可以加入更多的消费者。不过要注意，不要让消费者的数量超过主题分区的数量，多余的消费者只会被闲置。 对于多个应用程序需要从同一个主题读取数据的情况。在这些场景里，每个应用程序可以获取到所有的消息， 而不只是其中的一部分。只要保证每个应用程序有自己的消费者群组，就可以让它们获取到主题所有的消息。 不同于传统的消息系统，横向伸缩 Kafka 消费者和消费者群组并不会对性能造成负面影响。 消费者群组和分区再均衡 分区的所有权从一个消费者转移到另一个消费者，这样的行为被称为再均衡。 消费者通过向被指派为群组协调器的 broker（不同的群组可以有不同的协调器）发送心跳来维持它们和群组的从属关系以及它们对分区的所有权关系。只要消费者以正常的时间间隔发送心跳，就被认为是活跃的，说明它还在读取分区里的消息。消费者会在轮询消息（为了获取消息）或提交偏移量时发送心跳。如果消费者停止发送心跳的时间足够长，会话就会过期，群组协调器认为它已经死亡，就会触发一次再均衡。 提交和偏移量 消费者可以使用 Kafka 来追踪消息在分区里的位置（偏移量）。 我们把更新分区当前位置的操作叫作提交。 那么消费者是如何提交偏移量的呢？消费者往一个叫作 _consumer_offset 的特殊主题发送消息，消息里包含每个分区的偏移量。 如果消费者一直处于运行状态，那么偏移量就没有什么用处。不过，如果消费者发生崩溃或者有新的消费者加入群组，就会触发再均衡，完成再均衡之后，每个消费者可能分配到新的分区，而不是之前处理的那个。为了能够继续之前的工作，消费者需要读取每个分区最后一次提交的偏移量，然后从偏移量指定的地方继续处理。 如果提交的偏移量小于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息就会被重复处理。 如果提交的偏移量大于客户端处理的最后一个消息的偏移量，那么处于两个偏移量之间的消息将会丢失。 KafkaConsumer API 提供了很多种方式来提交偏移量 自动提交 提交当前偏移量 异步提交 提交特定的偏移量 再均衡监听器 在提交偏移量一节中提到过，消费者在退出和进行分区再均衡之前，会做一些清理工作。 从特定偏移量处开始处理记录 如何退出 在之前讨论轮询时就说过，不需要担心消费者会在一个无限循环里轮询消息，我们会告诉 消费者如何优雅地退出循环。 反序列化器 在之前的章节里提到过，生产者需要用序列化器把对象转换成字节数组再发送给 Kafka。 类似地，消费者需要用反序列化器把从 Kafka 接收到的字节数组转换成 Java 对象。 独立消费者——为什么以及怎样使用没有群组的消费者 你可能只需要一个消费者从一个主题的所有分区或者某个特定的分区读取数据。这个时候就不需要消费者群组和再均衡了，只需要把主题或者分区分配给消费者，然后开始读取消息并提交偏移量。 如果是这样的话，就不需要订阅主题，取而代之的是为自己分配分区。一个消费者可以订 阅主题（并加入消费者群组），或者为自己分配分区，但不能同时做这两件事情。 第5章 深入 Kafka 第6章 可靠的数据传递 第7章 构建数据管道 第8章 跨集群数据镜像 第9章 管理Kafka 主题操作 使用 kafka-topics.sh 工具可以执行主题的大部分操作，可以用它创建、修改、删除和查看集群里的主题。 要使用 kafka-topics.sh 工具的全部功能，需要通过 --zookeeper 参数提供 Zookeeper 的连接字符串。 创建主题 第10章 监控Kafka 第11章 流式处理 封底 应用程序会产生各种数据：日志消息、度量指标、用户活动记录、响应消息等，这些数据都可以通过Kafka进行移动。 Kafka是在流式平台上处理实时数据的利器。 ","link":"https://ninglg.com/post/kafka-definitive-guide-note/"},{"title":"使用Docker部署Go应用程序","content":"使用Docker部署Go应用程序的流程 1、go.mod 编写源码 首先编写Go程序代码，并使用go.mod进行依赖管理。 Go示例代码： package main import ( &quot;fmt&quot; &quot;log&quot; &quot;net/http&quot; ) func myHandler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, &quot;Hello world\\n&quot;) } func main() { http.HandleFunc(&quot;/&quot;, myHandler) log.Fatal(http.ListenAndServe(&quot;:8090&quot;, nil)) } go.mod示例内容： module test go 1.13 2、Dockerfile 编写部署文件 编写打包部署所需要的Dockerfile文件。示例如下： #因为golang镜像有点大，此处使用了大小体积只有5MB的alpine镜像 FROM alpine:latest #维护者信息（非必须） MAINTAINER xxx &quot;yyy@zzz.com&quot; #设置当前工作路径 WORKDIR / #把上文编译好的可执行文件添加到镜像里 ADD main / #暴露容器内部端口 EXPOSE 8090 #可执行程序入口 ENTRYPOINT [&quot;./main&quot;] 3、docker build 构建镜像 先根据镜像实际运行平台(alpine)进行源码编译： env GOOS=linux GOARCH=386 go build main.go 再打包编译结果： docker build -t main:v1 . 4、docker run 运行镜像 docker run --name docker-main -d -p 8090:8090 main:v1 ","link":"https://ninglg.com/post/use-docker-to-deploy-golang-app/"},{"title":"Go Mod使用注意事项","content":"go mod 系列命令 go mod init 生成go.mod文件 go mod download . 下载go.mod文件中指明的所有依赖 go mod tidy 整理现有的依赖 go mod graph 查看现有的依赖结构 go mod edit 编辑go.mod文件 go mod why 查看为什么需要依赖某个模块 GOPROXY export GOPROXY=https://goproxy.cn,direct 设置Go模块代理，GOPROXY允许以逗号分隔设置多个模块代理。 直到遇到direct，direct用于指示Go回到模块版本的源地址去抓取。 GOSUMDB GOSUMDB用于校验版本模块的数据未经篡改，其默认值是sum.golang.org，设置的模块代理goproxy.cn同样支持代理sum.golang.org。所以在设置了GOPROXY之后，无须过度关心这个问题。 也可以设置 export GOSUMDB=off ，来关闭校验功能。 GOPRIVATE go clean -modcache ","link":"https://ninglg.com/post/go-mod/"},{"title":"基于Map LBS的服务设计","content":"此篇记录基于Map LBS的一些服务设计。 Uber Uber作为世界上最大的的互联网在线约车服务商，曾经利用Golang来构建基于地理围栏的高性能查询服务。 提高服务性能 一般来说，提高服务的性能有两个方法： 通过横向扩展，增加服务的硬件资源。硬件的扩展还取决于服务的架构支持，不是所有架构都是可以通过横向增加硬件来提高性能。 还有一个就是通过优化或者重构提高服务的软件性能。Uber采取的方法就是使用Golang语言进行重构服务。 地理围栏 地理围栏是指地球表面上人类定义的地理区域（或几何学上的多边形）。 具体表现为向用户显示在给定位置提供哪些服务，定义具有特定要求的区域（例如机场）以及对许多人同时打车的地点实施动态定价等。 地理围栏查找需要占用大量CPU的多边形点算法。 ","link":"https://ninglg.com/post/map-lbs-design/"},{"title":"养娃笔记","content":"俗话说“老大照书养，老二当猪养”。总之，还是记录一下养娃历程中的点点滴滴。 0~6个月 一月睡，二月哭，三月认人，四月翻身，五月出牙，六月辅食。 提前准备婴儿床、婴儿车、婴儿使用衣物、婴儿沐浴和洗头用品等。 刚出生使用NB型纸尿裤，后面换为S码，然后换为M码。 准备小包奶粉以备不时之需。 喂奶后注意拍嗝。 办理各类住院报销手续，出生证，户口事宜。 按计划接种疫苗。 出生15天后开始吃鱼肝油。 洗澡，运动，语言能力锻炼。 洗浴用品。 抓握练习玩具，出牙时要提前准备婴儿咬胶。 声音、颜色玩具。 4~6个月婴儿开始接受辅食，要进行辅食工具准备。另外，注意更换十字形奶嘴。 婴儿辅食 在国际上主流的婴儿辅食添加指南中，对于小宝宝的辅食引入顺序是这样的： 首先是谷类食物，如婴儿营养米粉； 然后是动物性食物，如畜肉泥、鱼，禽、蛋羹等； 最后是蔬菜泥和水果泥。 注：最新科学结论，辅食添加没有严格的顺序性，可以综合添加并观察。 7~12个月 七月学坐，八月学爬，九月学用勺和碗。半岁用杯子，1岁戒奶瓶。 宝宝开始学习使用学饮杯或吸管杯。 可以开始尝试各种食物，包括鱼、肉、蛋。先尝试吃一点进行观察，没有问题的话就可以继续吃。 鱼类推荐三文鱼、海鲈鱼、鳕鱼、鲳鱼。另外，相比鱼类和贝类，甲壳类（虾和蟹）对宝宝也是很好的食物。 花菜、西蓝花容易引起宝宝胀气，建议8个月之后再添加。 水果类的在添加辅食初期可以煮熟吃果泥，但适应后还是应该生吃为好。 此阶段辅食应该适量添加植物油，植物油和脂肪能为宝宝提供能量和必需的脂肪酸。 如需额外补钙，可使用“朗迪碳酸钙D3颗粒”，每袋含钙500毫克*20袋。 认知教育 视觉刺激类：卡片、绘本、颜色启蒙、纸板书 1年~2年 ","link":"https://ninglg.com/post/baby-raising-note/"},{"title":"Prometheus指标收集聚合平台","content":"Prometheus是一个开源监控解决方案，用于收集和聚合指标作为时间序列数据。 安装、启动和访问 brew install prometheus prometheus --config.file=/usr/local/etc/prometheus.yml http://localhost:9090/ ","link":"https://ninglg.com/post/prometheus-intro/"},{"title":"Go数据可视化工具和数据管理后台","content":"介绍两个Go数据可视化工具和数据管理后台。 数据可视化工具 go-echarts 数据管理后台 GoAdmin ","link":"https://ninglg.com/post/golang-data-visualization-tool-admin-platform/"},{"title":"移动端跨平台开发方案介绍","content":"此篇简要介绍一下移动端的跨平台开发方案。 移动端跨平台开发是指可以将一套代码编译成iOS端App和Android端App。目前主要包括 Flutter、ReactNative 和 Weex 三套主流的解决方案。 ","link":"https://ninglg.com/post/mobile-app-crossplatform-development/"},{"title":"Go defer实现","content":"Go defer实现 // _defer结构体持有指向下一个要被执行的 defer 结构体的指针 type _defer struct { siz int32 // 包含参数和结果 started bool heap bool // openDefer indicates that this _defer is for a frame with open-coded // defers. We have only one defer record for the entire frame (which may // currently have 0, 1, or more defers active). openDefer bool sp uintptr // 延迟调用时的sp pc uintptr // 延迟调用时的pc fn *funcval // 下一个要被执行的延迟函数 _panic *_panic // 执行延迟调用时的panic信息 link *_defer // If openDefer is true, the fields below record values about the stack // frame and associated function that has the open-coded defer(s). sp // above will be the sp for the frame, and pc will be address of the // deferreturn call in the function. fd unsafe.Pointer // funcdata for the function associated with the frame varp uintptr // value of varp for the stack frame // framepc is the current pc associated with the stack frame. Together, // with sp above (which is the sp associated with the stack frame), // framepc/sp can be used as pc/sp pair to continue a stack trace via // gentraceback(). framepc uintptr } ","link":"https://ninglg.com/post/go-defer/"},{"title":"Filebeat日志采集工具","content":"Filebeat日志采集工具 Filebeat介绍 Filebeat是一个轻量级的日志采集工具。 常用的ELK日志采集方案中，大部分的做法都是将所有节点的日志内容通过filebeat送到kafka消息队列，然后使用logstash集群读取消息队列内容，根据配置文件进行过滤。最后将过滤之后的文件输送到elasticsearch中，通过kibana去展示。 为什么不直接用logstash呢？因为logstash是jvm跑的，资源消耗比较大。 启动及配置 Filebeat可以配置同时输出到es和logstash以及kafka。 启动Filebeat ./filebeat -e -c filebeat.yml 采集机制 当开启filebeat的时候，它会启动一个或多个探测器（prospectors）去检测指定的日志目录或文件。对于探测器找出的每一个日志文件，filebeat启动收割进程（harvester），每一个收割进程读取一个日志文件的新内容，并发送这些新的日志数据到处理程序（spooler），处理程序会集合这些事件，最后filebeat会发送集合的数据到指定的地点。 ","link":"https://ninglg.com/post/filebeat-intro/"},{"title":"HTTP2介绍","content":"HTTP2介绍 优势 HTTP/2 提供了连接多路复用、双向流、服务器推送、请求优先级、首部压缩等机制。 可以节省带宽、降低TCP连接次数、节省CPU，帮助移动设备延长电池寿命等。 ","link":"https://ninglg.com/post/http2-intro/"},{"title":"Go的一些常用开源组件列表","content":"Go的一些常用开源组件地址 优秀go组件合集 精选的优秀go组件合集 awesome-go Go脚本化常用包 输出对应编码颜色的包color 用于为执行时间过久的任务创建进度条的包progressbar 用于捕获源代码的文件名、行号、函数等信息的包，用于改正错误信息whereami 创建带有输入选项和相关文档的复杂脚本的包cobra Redis组件 类型安全的Go语言Redis客户端 go-redis 命令行 现代的Go命令行支持工具 cobra HTTP客户端 简单的HTTP请求客户端 gorequest 配置文件管理 配置读取和管理 viper 日志组件 日志组件 zap 系统监控工具箱 系统监控psutil工具 gopsutil 文件变更监控 跨平台的文件监控 fsnotify 可视化实时运行时统计 可视化实时运行时统计 statsviz 协程 协程池 ants 编解码 map转化为struct mapstructure 在相同的结构体或map之间赋值 mergo 解析任意的json格式go-simplejson 接口文档 自动生成接口文档 go-swagger 自动生成接口文档 [swaggo](go get -u github.com/swaggo/swag/cmd/swag) 可配合gin框架 权限管理 支持ACL/RBAC/ABAC多种权限管理 casbin 定时任务 定时任务管理cron 可视化 生成可视化Go调用图 go-callvis 平滑重启 可监测可升级的平滑重启组件 overseer 本地缓存 尽量存放变化不频繁的数据 + 设置合理的过期时间 + 如果QPS过高尽量异步set + 监控确保key不要过多 本地缓存组件 go-cache 本地缓存组件2 bigcache 本地缓存组件3 freecache 二维码 二维码 go-qrcode 数据校验 数据校验 govalidator 数据校验2 validator Go代码修改后的热重载调试（Hot Reload） 热重载调试 fresh 图形化界面开发 基于OpenGL和Material Design的跨平台GUI库 fyne 安全编码检查 安全编码检查工具 gosec 开源的分布式跟踪库 其中最受欢迎的库有Zipkin和Jaeger，它们都支持OpenTracing。 读写Excel Excel读写组件tealeg 限流熔断器 限流熔断器 sentinel-golang Metrics 服务指标度量 go-metrics WebSocket ws/wss gorilla/websocket Go App热编译重载 Air air Mock工具 GoMock mock gRPC grpc-gateway grpc-gateway 规则引擎 bilibili开源的规则引擎gengine 知名项目 云计算基础设施代表项目：docker、kubernetes、etcd、consul、cloudflare、CDN、云存储等 基础软件代表项目：tidb、influxdb、cockroachdb等 微服务代表项目：go-kit、micro、monzo bank 的 typhon、bilibili 等 互联网基础设施代表项目：以太坊、hyperledger、Dropbox、Hugo 等 其他 Github中文项目排行榜 后端架构师技术图谱 ","link":"https://ninglg.com/post/golang-open-source-components-list/"},{"title":"Kafka的高可用和高性能实现","content":"Kafka的高可用和高性能实现 Kafka高可用 1. 副本机制 副本机制会将一个broker下某个topic的一个partition放入到另外一个broker里，这个备份的分区和原分区都叫做副本（replica）。在所有的副本里，只能有一个leader，其余的副本都作为follower，同一时间内只有leader负责读写，follower不起任何作用。其他所有的follower会异步的拉取leader消息。当leader挂掉之后，为了保证高可用性，会从中选择一个副本作为leader。 Kafka高性能 1. 分区 Kafka将topic分区，每一个broker里面会保存topic的不同分区，这样就可以让一个消费者组同时消费不同的分区，提高吞吐。 2. 页缓存 Kafka将数据写入页缓存（内存）中而不直接操作磁盘，由操作系统决定什么时候把页缓存中数据刷到磁盘上。同时写入页缓存的数据是按照磁盘顺序去写入的，因此刷到磁盘上的速度也较快。当读操作发生时，先从页缓存中查询是否有所需信息，若没有才会调度磁盘。 3. 零拷贝——PageCache 结合 sendfile 方法 若页缓存中没有所需信息，需要去调度磁盘数据。一般网络io操作需要四个步骤 ： 硬盘 -&gt; 内核态 PageCache -&gt; 用户态程序读取 -&gt; 内核态socket写入 -&gt; 拷贝至网卡。通过Sendfile优化后，使用零拷贝可以将buffer从内核态和用户态间任意切换。PageCache仅会传递一个文件描述符给socket，就等效于直接从PageCache中拷贝至网卡，从而少了两步IO操作。 Leader的选举 1. Leader宕机 如果Leader宕机了该怎么办？很容易想到在Follower中重新选举⼀个Leader，但是选举哪个作为leader呢？Follower可能已经落后许多了，因此要选择的是“最新”的Follower：新的Leader必须拥有与原来Leader commit过的所有信息。 kafka动态维护了⼀组同步leader数据的副本（ISR），只有这个组的成员才有资格当选leader。kafka副本写⼊不被认为是已提交，直到所有的同步副本已经接收才认为是。这组ISR保存在zookeeper，正因为如此，在ISR中的任何副本都有资格当选leader。 2. 如果Replica都死了怎么办 只要⾄少有⼀个replica，就能保证数据不丢失，可是如果某个partition的所有replica都死了怎么办？有两种⽅案： （1）等待在ISR中的副本恢复，并选择该副本作为Leader； （2）选择第⼀个活过来的副本（不⼀定在 ISR中)，作为Leader 这里存在可⽤性和⼀致性的⽭盾：如果⼀定要等待副本恢复，等待的时间可能⽐较⻓，甚⾄可能永远不可⽤。如果是第⼆种，不能保证所有已经commit的消息不丢失，但有可⽤性。Kafka默认选⽤第⼆种⽅式，⽀持选择不能保证⼀致的副本。可以通过参数unclean.leader.election.enable禁⽤它。 ","link":"https://ninglg.com/post/kafka-high-availability-and-high-performance/"},{"title":"gRPC介绍","content":"gRPC介绍 介绍 gRPC是一个由Google开源的远程服务调用框架，具有多路复用和双向流式通信的特性。 gRPC本质上仍然遵循常规的Remote Procedure Call (RPC) 技术，但是在实现上使用了HTTP2.0、协议缓冲区等更现代化的技术方案，从而最大程度上确保服务端和客户端的互操作性及性能上的提升。 ","link":"https://ninglg.com/post/grpc-intro/"},{"title":"数据结构：R树","content":"R树是用来做空间数据存储的树状数据结构。 ","link":"https://ninglg.com/post/r-tree-intro/"},{"title":"Docker常用命令及中间件应用示例","content":"Docker常用命令及中间件应用示例 Docker 查看docker系统信息 docker info 查看docker版本信息 docker version 查看镜像/容器/数据卷所占的空间 docker system df 镜像 搜索镜像 按名称搜索 docker search redis 按条件搜索 docker search --filter &quot;is-official=true&quot; --filter &quot;stars=3&quot; 下载最新或指定版本的镜像 docker pull redis docker pull redis:5.0.5 docker pull mysql:latest docker pull grafana/grafana 列出本地镜像 docker images 或 docker image ls 批量获取镜像ID docker image ls -a -q 查看镜像详细信息 docker image inspect [镜像名称] 删除镜像或容器 docker image rm [xxxxxx] docker rmi [xxxxxx] 删除无用的虚悬镜像 docker image prune 删除一个或多个容器 docker rm [] 删除所有镜像 docker rmi $(docker images -q) 批量删除镜像 docker image rm $(docker image ls -a -q) 批量删除容器 docker container rm $(docker container ls -a -q) 删除untagged images，也就是id为None的镜像 docker rmi $(docker images | grep &quot;^&quot; | awk &quot;{print $3}&quot;) 容器 运行、启动和停止容器 docker run --name docker-redis --restart=always -d -p 6379:6379 redis docker run -itd --name docker-mysql --restart=always -d -p 3306:3306 -e MYSQL_ROOT_PASSWORD=123456 mysql:5.7 docker run --name docker-nginx --restart=always -d -p 8080:80 -v /Users/ninglg/nginx:/usr/share/nginx/html nginx docker run -d --name=docker-grafana --restart=always -p 3000:3000 grafana/grafana docker run --name docker-etcd --restart=always -d -p 2379:2379 -p 2380:2380 elcolio/etcd 启动容器 docker start [容器名/ID] 停止容器 docker stop [容器名/ID] 批量停止容器 docker container stop $(docker container ls -a -q) 强制停止容器 docker kill [容器名/ID] 后置设置更新容器自启动 docker update --restart=always [容器名/id] 设置挂载（如redis为例） -v /opt/data/redis:/data ##将主机中/opt/data/redis目录下的redis挂载到容器的/data -v /opt/data/redis/redis.conf:/etc/redis/redis.conf ##将主机中redis.conf配置文件挂载到容器的/etc/redis/redis.conf文件中 指定容器数据卷启动 (等于主机目录挂载到容器指定目录) docker run -it -v 主机目录:容器目录 镜像名 docker run -it -v /mydata:/mydata centos 查看运行中、历史创建的、所有的容器 docker ps docker ps -n 5 docker ps -a 访问容器 docker exec -it docker-redis redis-cli docker exec -it docker-mysql mysql -uroot -p123456 docker exec -it docker-nginx bash docker exec -it docker-etcd /bin/sh 获取容器ID或名字 docker container ls -a 批量获取容器ID docker container ls -a -q 查看容器详细信息 docker inspect [容器名称] 查看容器所属的ip地址： docker inspect docker-redis | grep IPAddress docker管理 数据卷管理 docker volume create 数据卷名称 #创建数据卷 docker volume rm 数据卷名称 #删除数据卷 docker volume inspect 数据卷名称 #查看数据卷 网络管理 docker network ls 查看网络信息 docker network create --subnet=网段 网络名称 docker network rm 网络名称 容器编排 docker-compose 创建一个docker-compose.yml文件 构建镜像 创建镜像 docker build 或 docker build -t docker-xxx:0.1 . env GOOS=linux GOARCH=386 go build main.go docker build -t main:v1 . docker run --name docker-main -d -p 8090:8090 main:v1 ","link":"https://ninglg.com/post/docker-commands-middleware-example/"},{"title":"节假日的英文表述","content":"此篇介绍一下各个节假日的英文表述方法。 节日 英文表述 元旦 New Year's Day 春节 Spring Festival 元宵节 Lantern Festival 清明节 Tomb-Sweeping Day 端午节 Dragon Boat Festival 中秋节 Mid-Autumn Festival 重阳节 Double Ninth Festival 国庆节 National Day 冬至节 Winter Solstice Festival 教师节 Teachers' Day ","link":"https://ninglg.com/post/holidays-in-english/"},{"title":"一些实用的Go工具命令","content":"一些实用的Go工具命令 命令 作用 gofmt -w -l -r &quot;panic(err) -&gt; log.Error(err)&quot; . 格式化并替换文本 go test -v 将 t.Log 的输出变成实时流式，而不是在整个测试结束之后输出 go mod why -m 分析特定的模块为什么会在 go.mod 文件中 Go语言自带工具集 bug start a bug report build compile packages and dependencies clean remove object files and cached files doc show documentation for package or symbol env print Go environment information fix update packages to use new APIs fmt gofmt (reformat) package sources generate generate Go files by processing source get add dependencies to current module and install them install compile and install packages and dependencies list list packages or modules mod module maintenance run compile and run Go program test test packages tool run specified go tool version print Go version vet report likely mistakes in packages go generate go generate常用于自动生成代码，它可以在代码编译之前根据源代码生成代码。 当运行go generate时，它将扫描与当前包相关的源代码文件，找出所有包含&quot;// go:generate&quot;的注释语句，提取并执行该注释后的命令，命令为可执行程序。 该过程类似于调用执行shell脚本。 添加特殊注释 //go:generate command argument... 执行generate命令 go generate [-run regexp] [-n] [-v] [-x] [build flags] [file.go... | packages] 注意事项 该特殊注释必须包含在.go源码文件中。 每个源码文件可以包含多个generate特殊注释。 go generate不会被类似go build，go get，go test等命令触发执行，必须由开发者显式使用。 命令执行是串行的，如果出错，后续命令不再执行。 特殊注释必须以“//go:generate”开头，双斜线之后没有空格。 执行命令必须是系统PATH（echo $PATH）下的可执行程序。 go generate 示例 package main import &quot;fmt&quot; //go:generate echo HelloWorld! //go:generate go run main.go //go:generate echo $GOARCH $GOOS $GOFILE $GOLINE $GOPACKAGE func main() { fmt.Println(&quot;go run main.go!&quot;) } 常用场景 为枚举常量实现String方法 //go:generate stringer -type=XXXXX(枚举的别名) 首先安装Go官方工具stringer： go install golang.org/x/tools/cmd/stringer 其它常用命令 go tool compile -S main.go 生成汇编代码 go build -gcflags -S main.go 禁止内联 //go:noinline func smallAllocation() *smallStruct { return &amp;smallStruct{} } 逃逸分析命令 go tool compile -S main.go //输出汇编内容，从中也可以看出逃逸的信息。用 go tool compile -help 可以查看所有可以传递给编译器的标识参数 go build -gcflags '-N -l -m' main.go //禁止优化、禁止内联、打印逃逸分析信息 GODEBUG GC垃圾回收分析命令 GODEBUG=gctrace=1 go run main.go 调度器观察参数 GODEBUG=schedtrace=100 go run main.go //在运行时每100毫秒发出一行调度器的摘要信息到标准err输出中 GODEBUG=scheddetail=1,schedtrace=100 go run main.go //在运行时每100毫秒发出一次详细的多行信息，信息内容包括调度程序、处理器、OS线程和goroutine的状态 说明如下： **GODEBUG=schedtrace=100 go run main.go** SCHED 0ms: gomaxprocs=16 idleprocs=14 threads=4 spinningthreads=1 idlethreads=0 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] # command-line-arguments SCHED 0ms: gomaxprocs=16 idleprocs=14 threads=3 spinningthreads=1 idlethreads=0 runqueue=0 [2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] SCHED 104ms: gomaxprocs=16 idleprocs=15 threads=20 spinningthreads=1 idlethreads=13 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] # command-line-arguments SCHED 0ms: gomaxprocs=16 idleprocs=14 threads=3 spinningthreads=1 idlethreads=0 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] SCHED 207ms: gomaxprocs=16 idleprocs=16 threads=20 spinningthreads=0 idlethreads=13 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] SCHED 316ms: gomaxprocs=16 idleprocs=16 threads=20 spinningthreads=0 idlethreads=13 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] SCHED 0ms: gomaxprocs=16 idleprocs=13 threads=5 spinningthreads=1 idlethreads=0 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] SCHED 416ms: gomaxprocs=16 idleprocs=15 threads=20 spinningthreads=1 idlethreads=13 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] SCHED 100ms: gomaxprocs=16 idleprocs=16 threads=5 spinningthreads=0 idlethreads=3 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] SCHED 526ms: gomaxprocs=16 idleprocs=16 threads=20 spinningthreads=0 idlethreads=13 runqueue=0 [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] 解释： sched：每一行都代表调度器的调试信息，后面的毫秒数是表示从启动到现在的时间，是由schedtrace值设置的。 gomaxprocs：当前的cpu核心数 idleprocs：空闲的处理器数量 threads：OS线程数量，后面的数字表示当前正在运行的线程数量 spinningthreads：自旋状态的OS线程数量。（调度器的设计者在考虑了“OS的资源利用率”和“频繁的线程抢占给OS带来的负载”之后，提出了自旋线程的概念。当自旋线程没有找到可供其调度执行的goroutine时，并不会销毁改线程，而是采取自旋的操作保存了下来。虽然看起来浪费了一些资源，但是考虑一下syscall的情景就可以知道，比起自旋操作，线程间频繁的抢占、创建和销毁操作带来的危害更大。） idlethreads：空闲的线程数量 runqueue：全局队列中的goroutine数量，后面的[0 ...]表示这16个P的本地队列正在运行的goroutine数量。 **GODEBUG=scheddetail=1,schedtrace=100 go run main.go** SCHED 0ms: gomaxprocs=16 idleprocs=14 threads=4 spinningthreads=1 idlethreads=0 runqueue=0 gcwaiting=0 nmidlelocked=0 stopwait=0 sysmonwait=0 P0: status=1 schedtick=0 syscalltick=0 m=0 runqsize=0 gfreecnt=0 timerslen=0 P1: status=1 schedtick=0 syscalltick=0 m=3 runqsize=0 gfreecnt=0 timerslen=0 P2: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P3: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P4: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P5: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P6: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P7: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P8: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P9: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P10: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P11: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P12: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P13: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P14: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 P15: status=0 schedtick=0 syscalltick=0 m=-1 runqsize=0 gfreecnt=0 timerslen=0 M3: p=1 curg=-1 mallocing=0 throwing=0 preemptoff= locks=2 dying=0 spinning=false blocked=false lockedg=-1 M2: p=-1 curg=-1 mallocing=0 throwing=0 preemptoff= locks=2 dying=0 spinning=false blocked=false lockedg=-1 M1: p=-1 curg=17 mallocing=0 throwing=0 preemptoff= locks=0 dying=0 spinning=false blocked=false lockedg=17 M0: p=0 curg=-1 mallocing=0 throwing=0 preemptoff= locks=1 dying=0 spinning=false blocked=false lockedg=1 G1: status=1() m=-1 lockedm=0 G17: status=6() m=1 lockedm=1 G2: status=1() m=-1 lockedm=-1 解释： G的运行状态共有 9 种，分别为： （1） （2） （3） （4） （5） （6） （7） （8） （9） ","link":"https://ninglg.com/post/useful-golang-commands/"},{"title":"MySQL开发规范","content":"此处列出互联网公司常用的MySQL DBA规范，仅供参考。 部署规范 1. DB集群的架构：一主多从，读写分离 2. 主库功能：承载DDL(CREATE、ALTER、DROP等)、DML (SELECT、UPDATE、INSERT、DELETE)、查询操作，并且通过Binlog将所有操作在从库上复现，从而实现主从数据一致 3. 线上从库功能：承载线上查询(select)操作，以减轻主库压力 4. 线下从库功能：供开发进行相关查询操作，以避免慢查询影响线上业务 5. 严禁在从库上进行增、删、改操作，以避免主从数据不一致，导致同步断开 6. 线上数据库严禁delete不加where条件 (delete from table)，如遇需要清除大表的需求，需要联系DBA同事进行处理 7. 一般来说禁止在线上数据库做压力测试 8. 禁止从测试、开发环境直连线上数据库 建表规范 1. 建表语句必须在sql审核平台(公司内部提供)审核通过，不然不予以创建 2. MySQL引擎默认使用InnoDB，使用其他引擎需要特别说明 3. 表名命名前缀要符合公司要求，字母小写，后面跟业务名称用 “_” 连接，长度不超过30个字符，且见名知意 4. 字符集使用utf8mb4，排序规则使用utf8mb4_general_ci 5. `id` int(11) NOT NULL AUTO_INCREMENT 作为第一个字段，且为主键，有自增属性 6. 各个类型字段均有NOT NULL属性，有默认值，不使用保留字，必须有中文说明 7. 时间类型字段的默认值遵循此类型的范围，推荐用timestamp 8. 尽可能不要使用text，blob类型，如果必须使用，不要设置not null类型 9. 不要在数据库中使用varbinary或blob存储图片及文件，mysql并不适合大量存储这类型文件 10. 表注释部分要说明此表的作用 11. 如果使用分表，表名内有明确的标识作为后缀 12. 不使用外键，触发器，函数，存储过程，事件 13. 单表建议控制在5000万以内 14. 普通索引命名规则: idx_索引名称 例:KEY `idx_school_name` (`school_name`) 15. 唯一索引命名规则: uniq_索引名称 例:UNIQUE KEY `uniq_serial` (`serial`) 16. 不要使用char类型，以varchar代替 17. 数据库名和表名根据操作系统不同是大小写敏感的，字段名是非敏感的，建议小写并用下划线分隔 18. 使用DECIMAL代替FLOAT和DOUBLE存储精确浮点数 19. 禁止在数据库中存储明文密码，需把密码加密后存储 20. 存储IP最好用int存储而非char(15) 索引规范 1. 单张表的索引数量不超过5个 2. 复合索引字段数不超过5个 3. 对⻓字符串使用前缀索引，前缀⻓度不超过8个字符 4. 对特殊字段，增加crc32或md5的伪列并建立索引 5. 尽量复用联合索引，避免冗余索引 6. 不在低基数列上建立索引，例如“性别” 7. UPDATE，DELETE语句的WHERE条件列必须使用索引 查询规范 1. 不使用%前导的查询，尽量优化负向查询，此类查询不能使用索引，例如like “%abc”, not in，!= ，not like, &lt;&gt; 2. SQL的返回结果尽量少，合理使用分⻚展示 3. 注意字段的类型，避免隐式转换即字符型字段的值需要加单引号，数值型不加 4. 避免使用大表的JOIN，将大SQL拆分成小SQL。OLTP（On-Line Transaction Processing，联机事务处理）类型SQL建议优化到0.05秒以内，OLAP（On-Line Analytical Processing，联机分析处理）类型在从库查询，查询最大时间为600秒 5. 避免在数据库中进行数学运算 6. 减少与数据库的交互次数，插入、更新或删除大量数据时，一次操作10000行数据以内，循环执行有一秒的间隔 7. 不在业务高峰期批量更新、批量删除 8. 禁止联库查询 9. 不要用select *，查询哪几个字段就select哪几个字段 10. sql中使用到OR的改写为用IN() (or的效率没有in的效率高) 11. in里面数字的个数建议控制在1000以内 12. 不使用负向查询，如not in/like，not in会把空和NULL也给查出来。 ","link":"https://ninglg.com/post/mysql-develop-guideline/"},{"title":"常见负载均衡算法介绍","content":"本篇介绍一下常见的负载均衡算法。 ","link":"https://ninglg.com/post/load-balancing-algorithm-intro/"},{"title":"常见限流算法介绍","content":"此篇介绍一下常见的几种限流算法。 问题背景 在突发流量增长的情况下，由于系统准备不足，很难通过短期扩容来应对 。此时，进行限流是最常用的手段，限流也是服务稳定性治理重要的手段之一。 限流的发生 限流可能发生在多个层面： 用户网络层：突发的流量场景如热点事件流量（秒杀事件、热门抢购，微博热搜），恶意刷流，竞对爬虫等。 内部应用层：上游服务的异常调用，脚本异常请求，失败重试策略造成流量突发。 实现限流的方案 常用的限流方法主要有三种：计数器算法（或类似滑动窗口），漏斗桶算法，令牌桶算法。 计数器算法 单机限流：使用全局内存计数 分布式系统限流：使用redis等公共存储计数，用incr可以保障原子性操作。 注意使用固定窗口还是滑动窗口优化的问题。 漏斗桶算法 Uber提供了基于漏斗桶的算法实现可以参考：https://github.com/uber-go/ratelimit redis4.0提供了限流模块，redis-cell。该模块使用漏斗算法，并提供原子限流指令。 漏斗桶更像是对流量进行整形Traffic Shaping，所有流量过来都要进行排队，依次出去，可用于做一些论坛博客发帖频率限制。 由于出口处理速率是匀速的，短时有大量突发请求，即使负载压力不大，请求仍需要在队列等待处理。 令牌桶算法 当访问量小时，令牌桶可以积累令牌到桶满，而当短时突发流量，积累的令牌能保障大量请求可以立刻拿到令牌，令牌用完了，请求会依赖于新令牌申请速度，这时会退化成类似漏斗桶算法。 具体实现上可以使用redis的list，启动任务向list匀速放置数据，当有请求时从list取数据，取到代表通过，否则被限流。这么实现有个弊端，就是需要不断操作list，浪费内存空间，实际上可以使用实时算法计算的方式来计算可用令牌数。 还有更多可实现细节如预热桶、一次性放入多个令牌、一次性取多个令牌。同时由于原子性问题，通过redis+lua脚本操作（lua实现令牌桶）会更好。 令牌桶既能够将所有请求平均分布到时间区间内，又能接受突发请求，因此是使用最广泛的限流算法。 部署方式 集中部署统一的限流中心 限流部署在接入层 服务中心与单机限流结合 限流配置 接口粒度 时间粒度 最大限流数 命中限流后的处理 限流后处理方式可以做服务降级（返回默认值、默认页面）、请求丢弃（拒绝请求）、请求排队（阻塞请求）、发送报警人工介入处理等。 也有直接结合服务降级熔断的如Sentinel、Hystrix。 ","link":"https://ninglg.com/post/rate-limit-algorithm-intro/"},{"title":"Redis集群方案介绍","content":"此篇简要介绍一下Redis的集群代理方案：Twemproxy。 背景 Redis单实例内存容量有限，为了提高系统承载能力，就必须使用到Redis集群 根据执行分片的位置，可以分为三种分片方式： 集群技术 1. 客户端分片 客户端分片：客户端使用一致性哈希等算法决定应当分布到哪个节点。 由业务方的程序代码设置路由规则，直接对多个Redis实例进行分布式访问 优点是可以灵活调整路由规则，另外性能比代理方式好一些（少了一个中间分发的环节） 缺点是Redis实例数量变化时需要手动调整分片，升级麻烦，可运维性较差 2. 代理分片 代理分片：将客户端的请求发送到代理上，由代理转发到正确的节点上。 通过增加一个对业务方使用透明的代理层，来执行分片工作 增加代理层虽然带来了一些多余的性能损耗，但是可以容忍 基于该机制的开源产品Twemproxy 3. 服务器分片：Redis Cluster 没有中心节点（和代理模式的重要不同之处） Redis Cluster将所有Key映射到多个Slot中，集群中每个Redis实例负责一部分，业务程序通过集成的Redis Cluster客户端进行操作。客户端可以向任一实例发出请求，如果所需数据不在该实例中，则该实例引导客户端自动去对应实例读写数据。 缺点是这是一个非常重的方案，Redis Cluster的成员管理（节点名称、IP、端口、状态、角色）等，都通过节点之间两两通讯，定期交换并更新，缺少了Redis单例的“简单、可依赖”的特点 1. Twemproxy Twemproxy是Twitter公司开发的，代理分片构建Redis集群的一个开源解决方案 优势 单线程工作，用C语言开发 直接支持大部分Redis指令，对于业务层可以透明使用 应用层不必关心连接失败,，由代理负责重连 代理后边的升级，前端不关心，解决了HA的问题 把Hash算法放到了代理上做，路由策略多样，支持HashTag, 通过HashTag可以自己设定将同一类型的key映射到同一个实例上去 减少与redis的直接连接数，保持与redis的长连接，可设置代理与后台每个redis连接的数目 自带一致性hash算法，能够将数据自动分片到后端多个redis实例上 支持redis pipelining request，将多个连接请求，组成reids pipelining统一向redis请求 高效，对连接的管理采用epoll机制，内部数据传输采用“Zero Copy”技术，以提高运行效率 高可用方案 因为Twemproxy本身是单点，所以需要用Keepalived做高可用方案 Keepalived是一种实现高可用的方案，它的功能主要包括两方面： 通过IP漂移，实现服务的高可用：服务器集群共享一个虚拟IP，同一时间只有一个服务器占有虚拟IP并对外提供服务，若该服务器不可用，则虚拟IP漂移（VIP自动切换的过程就称为IP漂移）至另一台服务器并对外提供服务 对LVS应用服务层的应用服务器集群进行状态监控：若应用服务器不可用，则keepalived将其从集群中摘除，若应用服务器恢复，则keepalived将其重新加入集群中 性能 经过一层代理后，官方给出的极限情况性能下降20% 2. Codis Codis是由豌豆荚于2014年11月开源的一种Redis集群解决方案。 组成 Codis是一个代理中间件，使用Go语言开发。其分为四个部分： 1. Codis Proxy (codis-proxy) 2. Codis Dashboard (codis-config) 3. Codis Redis (codis-server) 4. ZooKeeper/Etcd 优劣 Codis和Twemproxy最大的区别有两个： Codis支持动态水平扩展，对Client完全透明不影响服务的情况下可以完成增减redis实例的操作 Codis是用Go语言写的并支持多线程而Twemproxy用C并只用单线程 第2条又意味着：Codis在多核机器上的性能会好于Twemproxy，Codis的最坏响应时间可能会因为GC的STW而变大，不过Go1.5发布后会显著降低STW的时间；如果只用一个CPU的话Go语言的性能不如C，因此在一些短连接而非长连接的场景中，整个系统的瓶颈可能变成Accept新Tcp连接的速度，这时Codis的性能可能会差于Twemproxy。 虽然Redis是单线程的，但Codis Proxy是多线程的(严格来说是goroutine), 启动的线程数是CPU的核数，是可以充分利用起多核的性能的 使用注意事项 官方的建议是单个集合的总容量不要超过1M，否则在迁移的时候会有卡顿感 3. Redis Cluster 客户端分片、Redis Cluster属于无中心化的集群方案，Codis、Tweproxy属于中心化的集群方案。 采用中间加一层Proxy的中心化模式时，对Proxy的要求很高。因为Proxy一旦出现故障，那么操作这个Proxy的所有客户端都无法处理。要想实现Proxy的高可用，还需要另外的机制来实现，例如Keepalive。 另外，增加一层Proxy进行转发，必然会有一定的性能损耗。 除了客户端分片和上面提到的中心化的方案之外，还有比较好的解决方案么？Redis官方推出的Redis Cluster另辟蹊径，它没有采用中心化模式的Proxy方案，而是把请求转发逻辑一部分放在客户端，一部分放在了服务端，它们之间互相配合完成请求的处理。 Redis把请求转发的逻辑放在了Smart Client中，要想使用Redis Cluster，必须升级Client SDK，这个SDK中内置了请求转发的逻辑，所以业务开发人员同样不需要自己编写转发规则，Redis Cluster采用16384个槽位进行路由规则的转发。 Redis Cluster也提供了在线数据迁移、节点扩容缩容等功能，内部还内置了哨兵完成故障自动恢复功能，可见它是一个集成所有功能于一体的Cluster。因此它在部署时非常简单，不需要部署过多的组件，对于运维极其友好。 Redis Cluster在节点数据迁移、扩容缩容时，对于客户端的请求处理也做了相应的处理。当客户端访问的数据正好在迁移过程中时，服务端与客户端制定了一些协议，来告知客户端去正确的节点上访问，帮助客户端订正自己的路由规则。 虽然Redis Cluster提供了在线数据迁移的功能，但它的迁移性能并不高，迁移过程中遇到大key时还有可能长时间阻塞迁移的两个节点，这个功能相较于Codis来说，Codis数据迁移性能更好。 ","link":"https://ninglg.com/post/redis-cluster-solution/"},{"title":"Redis的内存使用量分析","content":"在大部分场景下，Redis都作为纯内存的NoSQL系统运行。所以，有必要了解其内存使用的组成和相应的分析方法。 内存使用量限制及数据淘汰策略 内存使用量限制 Redis的配置项maxmemory默认没有设定值，可以通过此项配置来限制单机最大使用的内存量。在实际使用中，如果超过了此值，则需要根据maxmemory-policy中设定的策略进行数据淘汰。maxmemory-policy的默认值是noeviction。 淘汰策略 规则名称 规则说明 volatile-lru 使用近似的LRU算法删除一个键（只对设置了生存时间的键） allkeys-lru 使用近似的LRU算法删除一个键 volatile-lfu 使用近似的LFU算法删除一个键（只对设置了生存时间的键） allkeys-lfu 使用近似的LFU算法删除一个键 volatile-random 随机删除一个键（只对设置了生存时间的键） allkeys-random 随机删除一个键 volatile-ttl 删除生存时间最近的一个键 noeviction 不删除键，只返回错误 LRU算法（Least Recently Used），最近最少使用算法。即默认删除最近最少使用的键。但是要注意：Redis中并不会准确的删除所有键中最近最少使用的键，而是随机抽取5个键，删除这5个键中最近最少使用的键。5这个数字也是可以设置的，对应位置是配置文件中的maxmemory-samples。 内存使用量分析 可以使用以下命令来查看Redis的内存使用情况： info 统计大key并处理 redis-cli --bigkeys 命令可以统计bigkey的分布 为了解决删除大键造成redis阻塞的问题， redis 4.0 引入了lazyfree的机制，它可以将删除键或数据库的操作放在后台线程里执行， 从而尽可能地避免服务器阻塞 如果set/zset元素个数较少（少于64个）或者是String类型，也会在主线程中直接删除而不走异步模式 info命令输出的数据可分为10个类别，分别是： server clients memory persistence stats replication cpu commandstats cluster keyspace 或直接用： info memory 条目 说明 used_memory 分配器分配的内存量，也就是实际存储数据的内存总量 used_memory_human 以可读格式返回 Redis 使用的内存总量 used_memory_rss 从操作系统的角度，Redis进程占用的总物理内存 used_memory_peak 内存分配器分配的最大内存，代表used_memory的历史峰值 used_memory_lua Lua引擎所消耗的内存 maxmemory_policy noeviction（达到最大内存占用后的清理策略） mem_fragmentation_ratio used_memory_rss /used_memory比值，表示内存碎片率 mem_allocator libc（Redis 所使用的内存分配器） 计算公式如下： used_memory = 自身内存+对象内存+缓冲内存+lua内存 used_rss = used_memory + 内存碎片 内存碎片率保持在1.0至1.5之间是最理想的状态。 假若碎片率超过了1.5，有效解决手段就是重启Redis服务器，释放内存回到操作系统。反之，若碎片率为0.9，说明物理内存已不够用，应增添硬件，或修改Redis最大内存限制maxmemory。 最大内存限制maxmemory的设置非常重要。 如果不设置maxmemory，Redis一直会为其分配内存，直至耗尽所有物理内存，直到操作系统进行虚拟内存交换。 内存集群 客户端分片 通过业务代码自己实现路由，性能较好但维护成本高。 代理分片 使用类似Twemproxy、Codis等中间件实现。 Codis在Twemproxy基础上优化并实现了预分片来达到Auto Rebalance。 RedisCluster 官方集群解决方案。方案较重，使用的案例较少。 ","link":"https://ninglg.com/post/redis-memory-usage-analysis/"},{"title":"BloomFilter（布隆过滤器）介绍","content":"BloomFilter（布隆过滤器）是一种可以高效地判断元素是否在某个集合中的算法。 应用场景 BloomFilter有非常多的应用场景，如检查单词是否拼写正确、网络爬虫的URL去重、黑名单检验、昵称不能重复的检测等等。 原理分析 布隆过滤器本质是一个位数组。其整体思路： 1、先初始化一个m位长度的位向量{1..m}，每一位均初始化为0； 2、使用k个相互独立的Hash函数，每个Hash函数将元素映射到{1..m}的范围内，并将对应的位置为1； 3、当查找某元素是否存在时，查找该元素所对应的k位是否全部为1，即可说明该元素是否存在。 使用优缺点 优点 1. 空间和时间效率高 对于少量数据来说，使用HashSet判断是很好的选择。但是对于海量数据来说，BloomFilter相比于其他数据结构在空间效率和时间效率方面都有着明显的优势。 缺点 1. 存在误报 BloomFilter 具有一定的误判率，有可能会将本来不存在的元素判定为存在。因此，对于那些需要“零错误”的应用场景，BloomFilter将不太适用。 2. 无法删除 BloomFilter 由于并不存储元素，而是用位的0、1来表示元素是否存在，并且很有可能一个位被多个元素同时使用，所以无法通过将某元素对应的位置为0来删除元素。 幸运的是，目前学术界和工业界都有很多方法扩展已解决以上问题。如可以使用Counting Bloom Filter (CBF)，CBF将基本BloomFilter的每一个Bit改为一个计数器，这样就可以实现删除字符串的功能了。另外还有Cuckoo（布谷鸟哈希） 也可以解决误报和无法删除的问题。 实际操作 可以通过 docker 直接在 redis 中体验布隆过滤器： docker run -d -p 6379:6379 --name bloomfilter redislabs/rebloom docker exec -it bloomfilter redis-cli redis 布隆过滤器主要就两个命令： bf.add 添加元素到布隆过滤器中：bf.add urls https://ninglg.com bf.exists 判断某个元素是否在过滤器中：bf.exists urls https://ninglg.com 上面说过布隆过滤器存在误判的情况，在 redis 中有两个值决定布隆过滤器的准确率： error_rate：允许布隆过滤器的错误率，这个值越低过滤器的位数组的大小越大，占用空间也就越大。 initial_size：布隆过滤器可以储存的元素个数，当实际存储的元素个数超过这个值之后，过滤器的准确率会下降。 redis 中有一个命令可以来设置这两个值： bf.reserve urls 0.01 100 复制代码三个参数的含义： 第一个值是过滤器的名字。 第二个值为 error_rate 的值。 第三个值为 initial_size 的值。 使用这个命令要注意一点：执行这个命令之前过滤器的名字应该不存在，如果执行之前就存在会报错：(error) ERR item exists。 ","link":"https://ninglg.com/post/bloomfilter/"},{"title":"微服务架构的维护","content":"此篇介绍一下微服务架构中经常遇到的一些维护方面的问题。 微服务带来的新问题 微服务架构虽然解决了一些单体应用的旧问题，但也引入了新的问题： 微服务架构将整个应用分散成多个服务，定位故障点变得困难； 服务数量变多，导致稳定性下降，并且其中一个服务故障可能导致整个系统挂掉； 服务数量变多，部署和管理的工作量变大； 开发方面：如何保证各个服务在持续开发的情况下仍然保持协同合作； 测试方面：服务拆分后，几乎所有功能都会涉及多个服务，测试变得更加复杂。 微服务的维护手段 监控：发现故障 全链路跟踪：定位故障 要实现链路跟踪，每次服务调用会在HTTP的HEADERS中记录至少记录四项数据： traceId：traceId标识一个用户请求的调用链路，具有相同traceId的调用属于同一条链路。 spanId：标识一次服务调用的ID，即链路跟踪的节点ID。 parentId：父节点的spanId。 requestTime &amp; responseTime：请求时间和响应时间。 关于链路跟踪的理论依据可详见Google的 Dapper。 日志：分析问题 网关：权限控制，服务治理 服务注册发现：动态扩容 熔断、服务降级、限流 测试粒度 微服务框架 Service Mesh Serverless、FaaS ","link":"https://ninglg.com/post/microservice-maintenance/"},{"title":"目标管理方法：KPI和OKR","content":"KPI 和 OKR 是两种在公司中常见的目标管理方法。 KPI KPI的概念 KPI（Key Performance Indicator），即关键绩效指标。是一种衡量员工表现，以及管理公司整体绩效的工具，和员工收入直接关联。 KPI的特点 KPI 理论上是必须严格按照 SMART （Specific、Measurable、Attainable、Relevant、Time－based）标准制订，要有百分比例，要可衡量等。 KPI之所以威力强大且广受欢迎，就是因为“你选择衡量什么，你就得到什么”。 KPI的问题 KPI从最大程度上提高了效率，却也是一把双刃剑。 有些事情值得去做，但在做出来一部分之前无法测量因此无法制订目标，没有激励机制导致创新驱动能力不足。 没有人对最终结果负责，每个人只对自己的过程负责，过于关注过程数字而忽视了最初的目标结果。 即使KPI达到了，也可能无法跟公司利益保持一致。 例如：KPI指标虽然完成了，但公司产品的NPS（Net Promoter Score）或DAU（Daily Active Users）却下降了。 OKR OKR的概念 OKR（Objectives and Key Results），目标与关键成果法。从概念上能看出，OKR本身是一种目标管理方法，用以评价员工是否称职，并不是绩效考核工具，一般不和工资挂钩。 OKR的起源 OKR最初由Intel公司发明，后在包括Google、LinkedIn、Facebook等国外公司广泛采用，逐渐引入到国内公司中。 OKR与KPI的主要区别 OKR和绩效考核分离，它把绩效考核交给 peer review（相当于国内公司的 360 度评价）来做。 OKR强调 Key Result 必须服从 Objective。你可以在做的过程中随意更改 Key Result，只要它们还是服务于原本的 Objective 就行。 OKR不以考核为目标，是让人更加聚焦重要领域。强调个人成长，放手让员工做事。相信并依靠员工的自主性和创造性去完成任务，使自由和方向达成一种平衡。 国外大厂绩效考核的核心是 impact，而测量的手段都是 peer review。OKR 就是让你在每个阶段开始之前想一想，有哪些事情从 impact 的角度来说是值得做的。 OKR要求员工走出“舒适区”，最好超出能力范围。 OKR的内容和成绩都是公开的，每名员工的介绍页都会显示他们的OKR记录。工程师的工作成果，用KPI的指标化显然是不能准确描述的。 ","link":"https://ninglg.com/post/kpi-vs-okr/"},{"title":"Go interface的实现","content":"此篇介绍一下Go interface的实现。 begin ","link":"https://ninglg.com/post/golang-interface-implementation/"},{"title":"谈谈长连接","content":"此篇简要介绍一下长连接相关的内容。 HTTP KeepAlive 在HTTP/1.0中，默认使用的是短连接。 从 HTTP/1.1起，默认使用长连接。使用长连接的HTTP协议，会在响应头中加入这行代码： Connection:keep-alive Keep-Alive不会永久保持连接。它有一个保持时间，可以在不同的服务器软件中设定这个时间。 实现长连接要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。长连接是指的TCP连接，而不是HTTP连接。 TCP连接的三次握手和四次挥手 TCP短链接 TCP长连接 ","link":"https://ninglg.com/post/persistent-connection-heartbeat-keepalive/"},{"title":"操作系统常见的页面置换算法","content":"此篇简要介绍下操作系统中常见的几种页面置换算法。 常见的有以下几种磁盘调度算法： FIFO 先进先出的算法 LRU 最近最少使用算法 OPT 最佳淘汰算法 LFR 最少访问页面算法 ","link":"https://ninglg.com/post/page-replacement-algorithms-in-operating-systems/"},{"title":"聊聊select、poll、epoll模型","content":"此篇简要介绍一下epoll模型的内容。 select / poll / epoll select、poll 和 epoll 三个都是 IO 多路复用的机制，可以监视多个描述符（fd）的读 / 写等事件。一旦某个描述符就绪（一般是读或者写事件发生了），就能够将发生的事件通知给关心的应用程序去处理该事件。 select 的缺点 每次调用 select，都需要把 fd 集合从用户态拷贝到内核态，这个开销在 fd 很多时会很大； 同时每次调用 select 都需要在内核遍历传递进来的所有 fd，这个开销在 fd 很多时也很大； select 支持的文件描述符数量只有 1024，非常小。 poll poll 和 select 原理一样，不过相比较 select 而言，poll 可以支持大于 1024 个文件描述符。 epoll 相比较 select 和 poll，epoll 的最大特点是： epoll 现在是线程安全的，而 select 和 poll 不是。 epoll 内部使用了 mmap 共享了用户和内核的部分空间，避免了数据的来回拷贝。 epoll 基于事件驱动，epoll_ctl 注册事件并注册 callback 回调函数，epoll_wait 只返回发生的事件，避免了像 select 和 poll 对事件的整个轮询操作。 ","link":"https://ninglg.com/post/select-poll-epoll-model/"},{"title":"死锁的问题","content":"此篇介绍一下有关死锁的内容。 什么是死锁 死锁是指多个进程因竞争资源而造成的一种僵持状态。若无外力作用，这些进程都将永远处于阻塞状态，不能再运行下去。 产生死锁的必要条件 互斥（Mutual exclusion）条件 一个资源每次只能被一个进程使用； 请求与保持（Hold and wait）条件 一个进程因请求资源而阻塞时，对已获得的资源保持不放； 不可剥夺（No preemption）条件 进程已获得的资源，在没使用完之前，不能强行剥夺； 环路等待（Circular wait）条件 多个进程之间形成一种互相循环等待资源的关系。 死锁的预防（Deadlock Prevention） 首先，互斥条件无法被破坏； 采用静态资源分配策略，破坏“部分分配”条件； 允许进程剥夺使用其他进程占有的资源，从而破坏“不可剥夺”条件； 采用资源有序分配法，破坏“环路”条件。 死锁的避免（Deadlock Avoidance） 避免死锁的著名算法：银行家算法 该算法需要检查申请者对资源的最大需求量，如果系统现存的各类资源可以满足申请者的需求，就满足申请者的需求。这样申请者就可很快完成其计算，然后释放它占用的资源，从而保证了系统中的所有进程都能完成，所以可避免死锁的发生。 ","link":"https://ninglg.com/post/deadlock-question/"},{"title":"Redis如何实现的高性能","content":"此篇主要介绍下Redis是如何实现的高性能。 我们知道，Redis是一个提供了众多数据结构和特性，并且可以达到10w+qps的高性能NoSQL数据库。那么，它是如何做到高性能的呢？ 开发语言 基于C语言实现，执行效率因素。 纯内存访问 Redis将所有数据放在内存中，除特殊场景外一般无需访问磁盘，减少了磁盘IO。 单线程 实现简单，避免了线程切换以及加锁释放锁带来的性能消耗。当然，单线程也有阻塞的缺点，需要避免执行耗时过长的命令。 除了Redis之外，Node.js和Nginx也都是单线程高性能服务的典范。 非阻塞多路I/O复用机制(multiplexing) Redis使用epoll作为I/O多路复用技术的实现，加上Redis自身的事件处理模型将epoll的read、write、close等都转换成事件，不在网络I/O上浪费过多的时间，从而实现对多个文件描述符（File Descriptor，FD）读写的监控，提高了性能。 多路复用函数库 Redis的I/O多路复用机制，还提供了select、epoll（Linux）、evport（Solaries）、kqueue（macOS/FreeBSD）等多路复用函数库，根据编译平台的不同可以选择不同的库。 除了select方式的时间复杂度为O(N)外，其它几种均为O(1)。 ","link":"https://ninglg.com/post/how-redis-implement-high-performance/"},{"title":"Vue.js 实践","content":"此篇记录一些使用 Vue.js 的内容。 ","link":"https://ninglg.com/post/vuejs-practice/"},{"title":"浅谈消息队列（Kafka、RabbitMQ、RocketMQ等）","content":"此篇简单聊一下消息队列方面的内容。 消息队列（message queue）是一个经常用到的中间件技术。 消息队列的作用 解耦应用 异步化消息 流量削峰填谷 最终一致性（最终一致性不是消息队列的必备特性，但确实可以依靠消息队列来做最终一致性的事情。） 广播 常见的消息队列组件 常见的消息队列组件主要有： 1. Kafka（Scala开发） 2. RocketMQ（Java开发，设计时参考了 Kafka，并做出了自己的一些改进） 3. RabbitMQ（erlang开发） 4. ActiveMQ（Java开发） 5. ZeroMQ（C开发） 优劣势综合对比 虽然消息队列组件众多，但最常见的还是Kafka和RocketMQ两种。它们的一些对比如下： 特性 Kafka RocketMQ RabbitMQ 开发语言 Scala Java Erlang 单机吞吐量 10万级，单机写入TPS约在百万条/秒，吞吐量三者最高 10万级 不到10万 时效性 ms级以内 ms级 可用性 非常高（分布式架构） 非常高（分布式架构） 功能特性 主要应用于日志采集/大数据实时计算领域，支持主要的MQ功能，不支持消息查询，支持按Offset进行消息回溯 功能完备，扩展性佳，经过参数优化配置消息可以做到0丢失，支持根据Message Id查询消息也支持根据消息内容查询消息，持按照时间来回溯消息精度达毫秒 基于AMQP协议实现，对数据一致性、稳定性和可靠性要求很高的场景，对性能和吞吐量的要求还在其次 缺点 单机队列load过多会导致发送消息响应时间变长，短轮询的方式决定了实时性取决于轮询间隔时间，消费失败不支持重试，支持消息顺序但是一台代理宕机后就会产生消息乱序 可能需要自己定制不同语言的client 其它特点 基于Pull的模式来处理消息消费，追求高吞吐量，一开始的目的就是用于日志收集和传输，适合产生大量数据的互联网服务的数据收集业务 天生为金融互联网领域而生，对于可靠性要求很高的场景，尤其是电商里面的订单扣款，以及业务削峰，在大量交易涌入时，后端可能无法及时处理的情况。目前在阿里集团被广泛应用于交易、充值、流计算、消息推送、日志流式处理、binlog分发等场景。 关于消息丢失的问题 Kafka如何配置不当会丢消息 消息落盘时机：消息落盘有异步刷新和同步刷新两种，明显异步刷新的可靠性要高很多。但在某些场景下追求性能而忽略可靠性，可以启用。 消息存储维护：在机器或存储环境发生变化时，可能丢失数据。 RocketMQ如何保证不丢消息 采用同步阻塞的发送方式，同步等待发送结果，利用同步发送+重试机制+多个master节点，尽可能减小消息丢失的可能性。 consumer端要保证消费消息的可靠性，主要通过At least Once+消费重试机制保证。 RabbitMQ RabbitMQ是使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP，SMTP，STOMP。它比较重量级，更适合企业级的开发。 Redis 使用Redis做队列有局限性，当数据大小超过了10K，Redis就慢的无法忍受。 Redis做队列没有ack机制保障。 Redis 的 list(列表) 数据结构常用来作为异步消息队列使用，使用 rpush/lpush 操作入队列，使用 lpop / rpop 来出队列。 如果redis的队列空了，客户端会陷入 pop 的死循环。不停地 pop 但没有数据，这就是浪费生命的空轮询。空轮询不但拉高了客户端的 CPU，redis 的 QPS 也会被拉高。解决这个问题的办法是使用 blpop/brpop。这两个指令的前缀字符b代表的是blocking，也就是“阻塞读”。阻塞读在队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立刻醒过来。消息的延迟几乎为零。用blpop/brpop替代前面的lpop/rpop。 ","link":"https://ninglg.com/post/talk-about-message-queue/"},{"title":"分布式中的一致性算法：Paxos和Raft","content":"此篇简要介绍一下分布式系统中的一致性算法：paxos和raft。 ","link":"https://ninglg.com/post/paxos-and-raft-consistency-algorithm-in-distributed-system/"},{"title":"Twitter的分布式ID生成算法SnowFlake","content":"此篇简要介绍下来自Twitter的分布式ID生成算法——SnowFlake。 一些传统ID生成方式的弊端 1. 内置随机ID函数 一些语言内置的随机ID生成函数，存在着生成的ID位数过长，ID无序导致入库性能较差等问题。 另外，如果是UUID的生成方式，则需基于机器MAC地址，有安全风险，且不是分布式的。 2. 数据库自增主键 严重依赖数据库，性能不高，可用性也有风险。 3. Redis的INCR方案 QPS测算在20W+左右，如果超过这个范围则不合适。 SnowFlake算法 SnowFlake是Twitter公司所采用的一种算法，目的是在分布式系统中生成全局唯一且趋势递增的ID。 第1位代表符号位，始终为0； 第2组代表时间戳，精确到毫秒； 第3组代表工作机器id，高5位是datacenterId，低5位是workerId； 第4组代表序列号，这个值在同一毫秒同一节点上从0开始不断累加； 理论上SnowFlake方案可达到的QPS约为409.6w/s。 SnowFlake的优缺点 优点 内存生成，不依赖外部DB，确保高性能高可用。 生成的ID呈趋势递增，在插入索引树时表现性能较好。 缺点 依赖于系统时钟的一致性。如果某台机器的系统时钟回拨，有可能造成ID冲突，或者ID乱序。 为了解决时钟问题，有些公司采用ZK去比较当前workerId也就是节点ID使用的时间是否有回拨，如果有回拨就进行休眠固定时间，看是否能赶上时间。如果能赶上的话，就继续生成ID。如果一直没有赶上达到某个值的话，就报错处理。 业务对ID号的需求 全局唯一性 这是ID生成的天然需求。 趋势/单调递增 为了保证系统（如DB）写入的性能。 信息安全 防止关键业务信息（如订单量）被竞对根据ID数量计算出来。 如果感兴趣，也可以看下美团点评的分布式ID生成系统（Leaf）的实现，其中使用了一些缓存策略，提高了性能和稳定性。 ","link":"https://ninglg.com/post/twitter-id-generation-snowflake/"},{"title":"服务雪崩、降级、限流与熔断","content":"此篇谈一谈关于服务的雪崩、降级、限流与熔断。 服务雪崩 在多个服务调用形成的一条链路中，如果某个下游服务响应过慢/不可用，导致上游服务逐级堵塞，最后整条链路都不可用的情况。 服务降级 下游的服务响应过慢时，下游服务主动停掉一些不太重要的业务逻辑，释放出资源，增加响应速度。 下游的服务不可用时，上游服务主动调用本地的一些降级逻辑，避免被拖垮，确保及时响应。 开关降级、限流降级、熔断降级 服务限流 限流模式主要是提前对各个类型的请求设置最高的QPS阈值，若高于设置的阈值则对该请求直接返回，不再调用后续资源。 服务熔断 当下游的服务因为某种原因突然变得响应过慢/不可用，上游服务为了保证自己整体服务的可用性，不再继续调用此下游服务，而是直接返回，从而快速释放资源。如果下游服务质量好转则恢复调用。 熔断一般是框架级的处理，多采用断路器模式。 包括熔断判断机制、熔断报警机制、熔断恢复机制 ","link":"https://ninglg.com/post/service-avalanche-degradation-current-limiting-and-dissolution/"},{"title":"Go程序的条件编译和交叉编译","content":"此篇介绍下Go程序的条件编译和交叉编译。 编译选项go tool go tool compile -S main.go 输出汇编内容 指令集 -gcflags 用于将标识参数传递给 Go 编译器，如下： -m 会打印出逃逸分析的优化策略，实际上最多总共可以用 4 个 -m，但是信息量较大，一般用 1 个就可以了。 -l 会禁用函数内联，在这里禁用掉 inline 能更好的观察逃逸情况，减少干扰。 为了避免编译器的优化，加上-gcflags '-l -N'选项，-gcflags是给编译器的选项，通过go tool compile可以看到选项列表，-l表示禁止内联，-N表示禁止优化。一般要看一些细节的时候，都需要把这两个选项带上。 $ go build -gcflags '-N -l -m' main.go 还通过反编译命令查看 $ go tool compile -S main.go 可以通过 go tool compile -help 查看所有允许传递给编译器的标识参数。 直接通过 go build -gcflags '-m -l' 就可以看到逃逸分析的过程和结果。 在一个函数上方增加一行 //go:noinline 编译指令，可以用来阻止编译器内联此函数。如果用 -gcflags='-l -N' 选项，则是在全局范围内禁止优化。 编译器对于内联操作的优化，是递归操作的，可以逐层往上层调用方进行内联。 Go二进制中注入编译信息 main.go package main import ( &quot;fmt&quot; ) var ( AppName string // 应用名称 AppVersion string // 应用版本 BuildVersion string // 编译版本 BuildTime string // 编译时间 GitRevision string // Git版本 GitBranch string // Git分支 GoVersion string // Golang信息 ) func main() { Version() // 业务代码入口 } // Version 版本信息 func Version() { fmt.Printf(&quot;App Name:\\t%s\\n&quot;, AppName) fmt.Printf(&quot;App Version:\\t%s\\n&quot;, AppVersion) fmt.Printf(&quot;Build version:\\t%s\\n&quot;, BuildVersion) fmt.Printf(&quot;Build time:\\t%s\\n&quot;, BuildTime) fmt.Printf(&quot;Git revision:\\t%s\\n&quot;, GitRevision) fmt.Printf(&quot;Git branch:\\t%s\\n&quot;, GitBranch) fmt.Printf(&quot;Golang Version: %s\\n&quot;, GoVersion) } 编译脚本build.sh #!/bin/bash set -e PROJECT_NAME=&quot;myprogram.com&quot; BINARY=&quot;myprogram&quot; OUTPUT_DIR=output GOOS=$(go env GOOS) APP_NAME=${PROJECT_NAME} APP_VERSION=$(git log -1 --oneline) BUILD_VERSION=$(git log -1 --oneline) BUILD_TIME=$(date &quot;+%FT%T%z&quot;) GIT_REVISION=$(git rev-parse --short HEAD) GIT_BRANCH=$(git name-rev --name-only HEAD) GO_VERSION=$(go version) CGO_ENABLED=0 go build -a -installsuffix cgo -v \\ -ldflags &quot;-s -X 'main.AppName=${APP_NAME}' \\ -X 'main.AppVersion=${APP_VERSION}' \\ -X 'main.BuildVersion=${BUILD_VERSION}' \\ -X 'main.BuildTime=${BUILD_TIME}' \\ -X 'main.GitRevision=${GIT_REVISION}' \\ -X 'main.GitBranch=${GIT_BRANCH}' \\ -X 'main.GoVersion=${GO_VERSION}'&quot; \\ -o ${OUTPUT_DIR}/${BINARY} main.go ","link":"https://ninglg.com/post/golang-conditional-compilation-and-cross-compilation/"},{"title":"微服务中的服务发现","content":"此篇文章介绍下关于服务发现的一些技术。 什么是服务发现 服务发现（Service Discovery）要解决的是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务如何才能找到对方并建立连接。 服务发现的特点 动态变化是微服务应用的一大特点。在动态环境下，必须有一种机制能让client知道如何访问其它的服务，这就是服务发现技术的工作。 服务发现会保存集群中所有微服务最新的信息，比如IP和端口，并对外提供API，提供服务查询功能。 Etcd、Consul、Eureka 和 ZooKeeper 是服务发现/注册的典型解决方案。 如何实现服务发现机制 要解决服务发现的问题，需要三方面的支持： 一个强一致性、高可用的服务存储目录 如基于Raft的Etcd服务。 一种注册服务和监控服务健康状态的机制 用户可以在Etcd中注册服务，并且对注册的服务设置key TTL，定时保持服务的心跳以达到监控健康状态的效果。 一种查找和连接服务的机制 通过在Etcd指定的主题下注册的服务也能在对应的主题下查找到。为了确保连接，可以在每个服务器上部署一个proxy模式的Etcd，这样就可以确保能访问Etcd集群的服务都能互相连接。 ","link":"https://ninglg.com/post/service-discovery-in-microservices/"},{"title":"工程项目最佳实践","content":"需求分析，架构设计，项目编码，评审测试，线上部署，后期维护。 Jenkins+Docker+Gitlab+Kubernetes 完成容器化微服务的自动化部署。 ","link":"https://ninglg.com/post/best-practice-for-engineering-project/"},{"title":"《Modern PHP》阅读笔记","content":"此篇记录一下阅读《Modern PHP》后的一些内容。 第1章 新时代的PHP 命名空间、性状、闭包和内置的操作码缓存 依赖管理程序Composer 多个PHP引擎：Zend Engine 和 HHVM（Facebook开发的HipHop Virtual Machine） Hack语言是建立在PHP之上的编程语言，引入了静态类型、新的数据结构和额外的接口，同时还向后兼容现有的动态类型PHP代码 HHVM是PHP和Hack的解释器，使用即时（Just In Time，JIT）编译器提升应用的性能，并减少内存用量 Zend Engine核心团队开发的PHP7性能与HHVM相当 第2章 特性 命名空间 &lt;?php namespace Company; 别名 &lt;?php use Company\\Component\\Response as Res; use func Namespace\\functionName; use constant Namespace\\CONST_NAME; functionName(); echo CONST_NAME; 性状（Trait） &lt;?php trait MyTrait { } &lt;?php class MyClass { use MyTrait; } 生成器（generator） &lt;?php function myGenerator() { yield 'value1'; yield 'value2'; yield 'value3'; } 闭包 &lt;?php $closure = function ($name) { return sprintf('Hello %s', $name); }; Zend OPcache 内置的HTTP服务器 php -S localhost:4000 php -S localhost:8000 -c app/config/php.ini 判断使用的是否为内置的服务器 &lt;?php if (php_sapi_name() === 'cli-server') { // PHP内置的Web服务器 } else { // 其他Web服务器 } 第3章 标准 PHP社区已从中心化的框架模型进化为分布式生态系统了 PHP-FIG制定了推荐规范 自动加载 在PHP标准出现之前，PHP组件和框架使用魔术方法__autoload()或最新的spl_autoload_register()方法实现各自持有的自动加载器。如今，使用共同的一个自动加载器标准，就能混合搭配多个PHP组件。 PSR PSR是PHP Standards Recommendation（PHP推荐标准）的简称 PHP-FIG发布了PSR-0 ~ PSR-4共5个推荐规范，其中PSR-0已废弃 标准 规范 备注 PSR-0 自动加载 已经废弃 PSR-1 基本的代码风格 PSR-2 严格的代码风格 PSR-3 日志记录器接口 PSR-4 自动加载 PSR-5 PHPDoc标准 草案阶段 PSR-6 Cache 草案阶段 PSR-7 HTTP消息接口 第4章 组件 Packagist是查找组件的地方，Composer是安装PHP组件的工具 Composer是PHP组件的依赖管理器 composer require vendor/package composer.json文件和composer.lock文件 第5章 良好实践 不要相信任何来自不受自己直接控制的数据源中的数据 哈希算法有很多种（例如MD5、SHA1、bcrypt和scrypt） 目前，经同行审查，最安全的哈希算法是bcrypt。与MD5和SHA1不同，bcrypt是故意设计的很慢。bcrypt算法会自动加盐，防止潜在的彩虹表攻击。 bcrypt算法永不过时，如果计算机的运算速度变快了，我们只需提高工作因子的值 设置默认时区 &lt;?php date_default_timezone_set('Asia/Shanghai'); 数据库 PDO扩展 数据库连接和DSN 事务：PDO扩展还支持事务 第6章 主机 共享服务器、虚拟私有服务器、专用服务器和平台即服务 第7章 配置 PHP-FPM（PHP FastCGI Process Manager） Nginx虚拟主机的设置在server{}块中 大多数情况下，HTTP流量从80端口进入，HTTPS流量从443端口进入 第8章 调优 memory_get_peak_usage() print_r(realpath_cache_size()) 第9章 部署 自动部署 让部署的结果可预知 让部署可逆 第10章 测试 单元测试 功能测试 测试驱动开发（Test-Driven Development，TDD） 行为驱动开发（Behavior-Driven Development，BDD） 单元测试框架：PHPUnit和PHPSpec 使用Travis CI持续测试 第11章 分析 Xdebug XHProf + XHGUI Blackfire分析器 第12章 HHVM和Hack 使用Supervisord监控HHVM HHVM通过FastCGI协议与Web服务器（例如nginx）通信 HHVM也可以运行Hack语言 Hack语言添加了PHP中没有的新数据结构和接口 若想把代码从PHP转到Hack，把&lt;?php改成&lt;?hh即可 第13章 社区 本地PHP用户组（PHP User Group，PUG） 附录A 安装PHP wget、phploc、phpmd和php-code-sniffer 附录B 本地开发环境 VirtualBox Vagrant ","link":"https://ninglg.com/post/modern-php-reading-notes/"},{"title":"《Go程序设计语言》阅读","content":"《Go程序设计语言》阅读要点记录 第1章 入门 找出重复行 func main() { counts := make(map[string]int) input := bufio.NewScanner(os.Stdin) for input.Scan() { counts[input.Text()]++ } // 忽略了input.Err()中可能的错误 for line, n := range counts { if n &gt; 1 { println(line, n) } } } （1）bufio.NewScanner可以读取输入，以行或者单词为单位隔开，这是处理以行为单位的输入内容的最简单方式； （2）每一次调用input.Scan()读取下一行，并且将结尾的换行符去掉； （3）通过调用input.Text()来获取读到的内容； （4）input.Scan()在读到新行的时候返回true，在没有更多内容的时候返回false； printf的部分格式 %x, %o, %b 十六进制、八进制、二进制整数 %v 内置格式的任何值 %T 任何值的类型 读取文件 data, err := ioutil.ReadFile(filename) ... ... for _, line := range strings.Split(string(data), &quot;\\n&quot;) { counts[line]++ } 产生随机数 rand.Seed(time.Now().UTC().UnixNano()) ... ... freq := rand.Float64() 系统异常退出 os.Exit(1) 获取url的内容 resp, err := http.Get(url) ... ... b, err := ioutil.ReadAll(resp.Body) resp.Body.Close() 计算消耗的时间 time.Since(start).Seconds() 一个Web服务器 package main import ( &quot;fmt&quot; &quot;net/http&quot; ) func main() { http.HandleFunc(&quot;/&quot;, handler) http.ListenAndServe(&quot;:8080&quot;, nil) } func handler(w http.ResponseWriter, r *http.Request) { fmt.Fprintf(w, &quot;Hello, %s&quot;, r.URL.Path) } r中包含很多信息，比如r.Method，r.URL，r.Proto，r.Host，r.Form等。 第2章 程序结构 第8章 goroutine和通道 Go有两种并发编程的风格 （1）CSP并发模式：goroutine+channel（如channel） （2）共享内存多线程的传统模型（如sync.Mutex） 当一个程序启动时，只有一个goroutine来调用main函数，称之为主goroutine。 main函数返回时，所有的goroutine都暴力的直接终结。 没有程序化的方法让一个goroutine来停止另一个，但是有办法和goroutine通信来要求它自己停止。 channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制。 channel是一个使用make创建的数据结构的引用，当复制或作为参数传递到一个函数时，复制的是引用，这样调用者和被调用者都引用同一份数据结构。 和其他引用一样，channel的零值是nil。 同种类型的channel可以使用==进行比较，channel也可以和nil进行比较。 发送、接收、关闭 通道主要有发送 和 接收 两个操作，两者统称为通信。 （1）发送 ch &lt;- data （2）接收 data = &lt;- ch 或 &lt;- ch （接收的结果不使用而直接丢弃也是允许的） channel的第3种操作：关闭。 （1）在已经关闭的channel上进行发送操作将导致宕机 （2）在已经关闭的channel上进行接收，将获取所有已经发送的值，直到channel为空 （3）当关闭的channel被读完后，所有后续的接收操作都仍可进行，只是会取到通道元素类型对应的零值 （4）可以使用ok语法来判断channel是否已关闭 data, ok := &lt;- ch if !ok { // 说明channel已关闭且读完 } （5）为了对（4）中的写法进行简化，可以用range语法循环对channel进行读取，range会不断从channel 接收值，直到它被关闭（close）。 （6）主动关闭channel不是一个必须的操作，channel是可以自动回收的。只有在需要通知接收方goroutine所有的数据都发送完毕的时候，发送方才需要主动关闭channel。 （7）GC是根据channel是否可以访问来决定是否回收它的，而不是根据它是否关闭。 （8）关闭一个已经关闭的channel会导致宕机，关闭一个空channel(nil)也会导致宕机。 （9）关闭channel还可以作为一个广播机制。 无缓冲通道和缓冲通道 ch = make(chan int) //无缓冲通道 ch = make(chan int, 0) //无缓冲通道 ch = make(chan int, 3) //容量为3的缓冲通道 无缓冲通道的发送和接收会强制同步化，又称为同步通道。 并发并不意味着事件一定同时发生，而是不能假设事件的先后顺序。 缓冲通道的缓冲区，可以将发送和接收goroutine进行解耦。 如果程序要知道通道的容量，可以使用内置的cap函数： fmt.Println(cap(ch)) 如果要获取当前通道内的元素个数，可以使用内置的len函数： fmt.Println(len(ch)) 因为在并发程序中这个信息会随着检索操作很快过时，所以它的价值很低，但是它在错误诊断和性能优化的时候很有用。 粗暴的将缓冲通道作为队列在单个goroutine中使用是个错误。如果没有另一个goroutine从通道进行接收，发送者（也许是整个程序）有被永久阻塞的风险。如果仅仅需要一个简单的队列，使用slice创建一个即可。 对于无缓冲的通道，如果因为没有goroutine接收时，会导致多个发送的goroutine被卡住，这叫做 ** goroutine泄露 **，这属于一个bug。不像回收变量，泄露的goroutine不会自动回收，所以确保goroutine在不再需要的时候可以自动结束。 单向通道 函数的channel形参有时会要求不能发送或不能接收，这样就可以避免在函数内部误用。 chan &lt;- int 是只能往里写入的int类型通道，&lt;- chan int是一个只能从中读取的int类型通道。 函数内违反单向通道使用原则的错误，会在编译时被检查出来。 由于close操作只能在发送方操作，所以试图关闭一个只能接收的单向通道会引起编译时报错。 在任何赋值操作中将双向通道转换为单向通道都是允许的，但是反过来是不行的。 并行循环 func test() { var wg sync.WaitGroup for f := range filenames { wg.Add(1) //worker go func(f string) { defer wg.Done() // do something }(f) } wg.Wait() // do other } #第9章 使用共享变量实现并发 ","link":"https://ninglg.com/post/the-go-programming-language/"},{"title":"简谈技术Leader和团队管理","content":" 管理的本质是通过团队拿结果，通过结果培养人。 技术Leader 从概率角度来说，要找到 “技术好 + 能管理 + 有业务视角 + 有影响力 + 足够精力 + 做事靠谱” 的技术Leader，本身就不是一件容易的事。每个管理者都有不同的管理风格。 向上承压 1. 扛得住事情，协调了外围，拿得出业绩。 2. 做正确的决策。 3. 可衡量，可体系化。 向下激励 1. 有同理心，事情能做成，能力有成长，物质可回报。 2. 希望团队同学主动找自己聊。 3. 健康的梯队建设计划。 4. 借事修人。 达成目标 1. 是否能让团队的每一个人更好。 2. 是能否让团队的每个人的影响力更大。 3. 团队的成员是否认同该管理者。 4. 是否能合理安排团队成员合适的工作，让团队的整体产出最佳。 5. 管理者本身对业务的理解和专业能力。 多思考，多沟通。找到合适的人，找到合适的事，指导团队成员提升，跟上下游保持信息同步。 承担 1. 做别人不敢做的决定 2. 承担别人不敢承担的责任 3. 搞定别人搞不定的资源 思维格局与综合资源 融资能力，管理能力，团队建设能力，市场营销能力，企业文化建设，人际交往能力，危机公关能力，市场动向能力，授权与监督能力，制度建设等 技术总监的核心任务 任务 详情 团队管理 人是管理的核心要务之一 核心产品的构架 技术的技能专区 协调解决突发问题 在团队没有完善的情况下，要为团队的短板积极补位 指明学习方向 保障技术团队的可持续发展及成长，保障技术团队不会被公司的运营节奏落下 定期解读公司的核心和理念 带动团队创新及公司创新 技术外联 创造合作顺畅的团队内外部环境 团队管理 技术团队管理核心就是给技术团队的个人和团队进行精准画像，让合适的人在合适的位置发挥最大的价值。 技术团队的容量：有多少能做什么事情的人，每天每周每月能够承接多少功能、需求等。 技术团队的效率：技术团队的产出多少，做事情的效率多高，饱和度怎么样等。 赫勒法则 当人们知道自己的工作成绩有人检查时会加倍努力。 因为人都有被尊重的需要，当你能满足他这种需要时，他会更愿意为你做事。 这种尊重的需要一般都是来自他人的肯定，在管理中有效的监督就是上级肯定下级的一种表现。 PDCA闭环 坚持PDCA闭环是任何工作都应坚持的原则。 把管理过程分为四个阶段Plan-Do-Check-Act： Plan（计划）-适度怀疑原则 Do(执行）-过程反馈原则 Check(检查）-责任到人原则 Act(处理）-优胜劣汰原则 精力管理 运动 饮食 睡眠 健康 情绪 技能提升 硬技能 架构设计，算法，存储，网络，操作系统，编程语言 软技能 产品思维，项目规划，团队管理，沟通能力，执行力 著名管理大师德鲁克有句话：“管理是要建立在信任的基础上的。”也就是说，要做好管理，就必须建立与团队成员间的信任，信任是所有管理工作的基础。 管理者要有胸怀： 1. 领导者是寂寞的 2. 胸怀是被冤枉撑大的 3. 心态开放，能倾听，擅于换位思考 工作要有结果： 1. 团队成员跟着干，能不能得到想要的东西 2. 通过不断带领大家拿到结果，慢慢就会变得相信变得看见 辅导要有方法： 1. 在日常工作中要教员工方法 2. 成员的成长是管理者的主要工作之一，只有成员成长了，我们的工作才能轻松，业绩才能做好 3. 无论多忙，都要留一部分时间用于辅导成员 什么是领导力？ 管理 管理是指在特定环境条件下，对组织所拥有的人力、物力、财力、信息等资源进行有效决策、计划、组织、领导、控制，以期高效地达到既定的组织目标的过程。简单概括一下：管理的核心，就是利用组织的资源把事干好，从而达到组织的目标。 管理和领导力的核心 管理的核心在于事，领导力的核心在于人。 领导者的价值观 领导者的一切行为都受其价值观的支配，好的领导者是言行一致的人，其所表现的对人的关注，并非由于其所处的位置，而是其价值观和信念使然。当一个领导者发自真心地表现出对人的重视，对把他人提升到更高的境界、获得更大的成就表现出浓厚的兴趣时，这个领导者一定是有人跟随的，并且是被心甘情愿跟随的，这样的领导者和其带领的团队所迸发的力量也是巨大的。 行为模式 离开舒适区，学会挑战自己，让自己所掌握的技能变得更为精深； 与同行保持交流，从中掌握不同的设计方案和不同的思考方式； 坚持阅读及与不同领域的人交流，以接纳更多的信息和观点； 创造需求，及时应用和实践自己掌握的知识，而不仅仅是让知识成为一种可阅读的信息流； 尝试训练自己从多个角度分析问题，或用不同的思维思考问题； 给学习和应用设定目标和里程碑。 管理2.0更大团队的挑战 通过文化和价值观来统一目标和前进方向 保障高效地交付产出 处理团队中的冲突和沟通问题 预期管理，出现问题及时汇报 判断一个人是否具有管理潜力 是否具有强烈的结果导向意识 是否有抓住重点的能力 是否拥有大格局和整体观 ","link":"https://ninglg.com/post/tech-leader-team-management/"},{"title":"Cookie、Session和Token","content":"本文介绍Cookie、Session和Token的应用。 首先HTTP本身是一个无状态协议，为了进行会话保持和管理，就需要借助一些特定的数据方案。 Cookie HTTP Cookie（也叫 Web Cookie或浏览器 Cookie）是服务器发送到用户浏览器并保存在本地的一小块数据，它会在浏览器下次向同一服务器再发起请求时被携带并发送到服务器上。 Cookie 保存在客户端（浏览器）。 Cookie 可设置为长时间保持。 单个 Cookie 保存的数据长度有限制。 Cookie只是实现session的其中一种方案。虽然是最常用的，但并不是唯一的方法。禁用cookie后还有其他方法存储，比如放在url中。 如果只用Cookie不用Session，那么账户信息全部保存在客户端，一旦被劫持，全部信息都会泄露。并且客户端数据量变大，网络传输的数据量也会变大。 Session Session 代表着服务器和客户端一次会话的过程。Session 对象存储特定用户会话所需的属性及配置信息。 Session 保存在服务器端。 Session 中可以保持一些常用变量信息，比如说 UserId 等。 Session 一般失效时间较短。 Session 可存储数据量远高于 Cookie。 用Session只需要在客户端保存一个id，实际上大量数据都是保存在服务端。 Session存储于服务器，可以理解为一个状态列表，拥有一个唯一识别符号SessionId，通常存放于Cookie中。服务器收到Cookie后解析出SessionId，再去Session列表中查找，才能找到相应Session。 为每个用户分配一个唯一的标识符，即SessionID。它的存放形式无非两种，一是经过url传递，二是保存在客户端的cookie里。当然，session也可以保存在数据库中，安全性高，不过效率会变低。 Token Token 机制多用于 App 客户端和服务器交互的模式，也可以用于 Web 端做用户状态管理。 Token 的认证方式类似于临时的证书签名, 并且是一种服务端无状态的认证方式, 非常适合于 REST API 的场景. 所谓无状态就是服务端并不会保存身份认证相关的数据。 Token在客户端一般存放于localStorage，cookie，或sessionStorage中。在服务器一般存于数据库中。 Token可以抵抗CSRF，Cookie+Session不行。 Cookie会被浏览器自动添加到请求头中。但Token不同，Token是开发者为了防范CSRF而特别设计的令牌，浏览器不会自动添加到headers里，攻击者也无法访问用户的Token，所以提交的表单无法通过服务器过滤，也就无法形成攻击。 Token类似一个令牌，无状态，用户信息都被加密到Token中，服务器收到Token后解密就可知道是哪个用户。需要开发者手动添加。 最简单的Token组成 uid(用户唯一的身份标识)、time(当前时间的时间戳)、sign(签名，由Token的前几位+盐以哈希算法压缩成一定长的十六进制字符串，可以防止恶意第三方拼接Token请求服务器)。还可以把不变的参数也放进Token，避免多次查库。 ","link":"https://ninglg.com/post/cookie-session-token/"},{"title":"HTTPS协议","content":"此篇记录一些HTTPS协议相关的内容。 HTTPS 基础 为了解决HTTP的安全性问题，HTTPS做了加密通信。在传输层增加了一层 SSL（Secure Sockets Layer 安全套接层）/ TLS (Transport Layer Security 安全层传输协议) 来加密 HTTP 的通信内容。 SSL指的是安全套接字层——一种通过加密和身份验证在网络浏览器和服务器之间传输数据时添加密钥的小型数据文件。 HTTPS 采用混合的加密机制，使用公开密钥加密用于传输对称密钥，之后使用对称密钥加密进行通信。 HTTPS 通过使用 证书（数字证书认证机构CA，Certificate Authority） 来对通信方进行认证。 进行 HTTPS 通信时，服务器会把证书发送给客户端，客户端取得其中的公开密钥之后，先进行验证，如果验证通过，就可以开始通信。 TLS 握手协议 握手协议是整个 TLS 协议簇中最最核心的协议，HTTPS 能保证安全也是因为它的功劳。 握手协议由多个子消息构成，服务端和客户端第一次完成一次握手需要 2-RTT。 握手协议的目的是为了双方协商出密码块，这个密码块会交给 TLS 记录层进行密钥加密。也就是说握手协议达成的“共识”(密码块)是整个 TLS 和 HTTPS 安全的基础。 HTTPS 配置项 Nginx使用配置项 ssl_certificate 进行证书配置。 HTTPS提供了端到端的安全加密。不仅提供数据机密性（加密），还提供数据完整性（不被篡改数据）保护、防重放（把捕获的报文再发一次无效）。 加密传输之后，有了HMAC保护，任何篡改页面的尝试，由于没有session key，无法计算出和篡改网页一致的HMAC，所以数据接收端的SSL/TLS会轻易地识别出网页已被篡改，然后丢弃。既然无法劫持，也就没有篡改的冲动了，所以HTTPS可以很好地对付网页劫持。 非对称加密 “非对称加密”的加密算法，特点是私钥加密后的密文，只要是公钥都可以解密。但是公钥加密后的密文，只有私钥可以解密。 私钥只有一个人有，而公钥可以发给所有的人。 加密算法协商 如何做到Web服务器针对每个客户端使用不同的对称加密算法？ 使用随机数来生成对称加密算法。这样就可以做到服务器和客户端每次交互都是新的加密算法、只有在交互的那一该才确定加密算法。这也是为什么HTTPS协议握手阶段会有这么多的随机数的原因。 公钥分发 服务器端将公钥发送给每一个客户端。 数字签名 解决同一机构颁发的不同证书被篡改问题。 客户端验证 客户端本地怎么验证证书呢？答案是证书本身就已经告诉客户端怎么验证证书的真伪。证书上写着如何根据证书的内容生成证书编号。客户端拿到证书后根据证书上的方法自己生成一个证书编号，如果生成的证书编号与证书上的证书编号相同，那么说明这个证书是真实的。同时，为避免证书编号本身又被调包，所以使用第三方的私钥进行加密。 证书颁发机构 现实中，浏览器和操作系统都会维护一个权威的第三方机构列表（包括它们的公钥）。因为客户端接收到的证书中会写有颁发机构，客户端就根据这个颁发机构的值在本地找相应的公钥。 HTTP 的端口号是 80，HTTPS 的端口号是 443。 ","link":"https://ninglg.com/post/https-protocol/"},{"title":"如何招聘到对的人","content":"招聘到对的人，是对一个团队来说非常重要的事情。 找到聪明的人 既有的经验固然重要，底层思维和学习能力才是基础 提供顶尖的使命和环境 让人做擅长并感兴趣的事 开放透明的文化 公司级的定期Q&amp;A 经验多、能力强与责任心高的人才是可遇不可求的，尤其是在公司本身还不具备吸引这些人的属性的时候。 ","link":"https://ninglg.com/post/how-to-recruit-the-right-person/"},{"title":"Go语言调度器MPG模型","content":"此篇简要介绍Go语言调度器的GMP模型内容。 并发和并行的概念 并发 逻辑上具有处理多个同时性任务的能力。 并行 物理上同一时刻执行多个并发任务。 支持高并发的模型 CSP 消息之间通过channel发送，发送者和接收者不必关心，松耦合。 Actor Actor是基本的处理单元，相互之间直接发送消息，需要知道彼此的地址。 MPG模型 M M即Machine或称为工作线程，所有M是有线程栈的。每个M都代表了1个内核线程，相当于内核线程在 Go 进程中的映射。OS调度器负责把内核线程分配到CPU的核上执行。 M必须和一个P关联才能运行G。 work stealing：当M绑定的P没有可运行的G时，它可以从其他运行的M那里偷取G。 线程想运行任务就得获取P，从P的本地队列获取G，P队列为空时，M也会尝试从全局队列拿一批G放到P的本地队列，或从其他P的本地队列偷一半放到自己P的本地队列。M运行G，G执行之后，M会从P获取下一个G，不断重复下去 P P即Processor是一个抽象的概念，并不是真正的物理CPU。它包含了运行goroutine的资源。 如果线程想运行goroutine，必须先获取P，P中还包含了可运行的G队列。 P需要和M进行绑定，构成一个执行单元。 P决定了同时可以并发任务的数量，可通过runtime.GOMAXPROCS限制同时执行用户级任务的操作系统线程。在Go1.5之后GOMAXPROCS被默认设置可用的核数，而之前则默认为1。所有的P都在程序启动时创建，并保存在数组中，最多有GOMAXPROCS个。 P 的个数是通过 runtime.GOMAXPROCS 设定（最大256），Go1.5版本之后默认为物理线程数。 在并发量大的时候会增加一些 P 和 M ，但不会太多，切换太频繁的话得不偿失。 P有两种队列：本地队列（Local Queue）和全局队列（Global Queue）。 本地队列： 当前P的队列，本地队列是Lock-Free，没有数据竞争问题，无需加锁处理，可以提升处理速度。同全局队列类似，存放的也是等待运行的G，存的数量有限。 全局队列：全局队列为了保证多个P之间任务的平衡。所有M共享P全局队列，为保证数据竞争问题，需要加锁处理。相比本地队列，处理速度要低。 一个 Prcessor 表示执行 Go 代码片段的所必需的上下文环境，可以理解为用户代码逻辑的处理器。 G G即Goroutine的缩写。 Go不同版本Goroutine默认栈大小不同。 在Go中，线程是运行Goroutine的实体，调度器的功能是把可运行的Goroutine分配到工作线程上。 MPG的调度过程 首先通过执行go func()来创建一个G对象，新建的G对象会被保存到P的本地队列或者是全局队列（注意这里的P指的是创建G的P）。P此时去唤醒或创建一个M来执行G。P继续执行它的执行序。M寻找是否有空闲的P，如果有则将该G对象移动到它本身。接下来M执行一个调度循环（调用G对象-&gt;执行-&gt;清理线程→继续找新的Goroutine执行）。 M执行过程中，随时会发生上下文切换。当发生上线文切换时，需要对执行现场进行保护，以便下次被调度执行时进行现场恢复。Go调度器M的栈保存在G对象上，只需要将M所需要的寄存器（SP、PC等）保存到G对象上就可以实现现场保护。当这些寄存器数据被保护起来，就随时可以做上下文切换了，在中断之前把现场保存起来。如果此时G任务还没有执行完，M可以将任务重新丢到P的任务队列，等待下一次被调度执行。当再次被调度执行时，M通过访问G的寄存器进行现场恢复（从上次中断位置继续执行）。 每一个 M 都会以一个内核线程绑定，M 和 P 之间也是一对一的关系，而 P 和 G 的关系则是一对多。在运行过程中，M 和 内核线程之间对应关系的不会变化，在 M 的生命周期内，它只会与一个内核线程绑定，而 M 和 P 以及 P 和 G 之间的关系都是动态可变的。 在实际的运行过程中，M 和 P 的组合才能够为 G 提供有效的运行环境，而多个可执行 G 将会顺序排成一个队列挂在某个 P 上面，等待调度和执行。 M 的创建一般是因为没有足够的 M 来和 P 组合以为 G 提供运行环境，在很多时候 M 的数量可能会比 P 要多。在单个 Go 进程中，P 的最大数量决定了程序的并发规模，且 P 的最大数量是由程序决定的。可以通过修改环境变量 GOMAXPROCS 和 调用函数 runtime.GOMAXPROCS 来设定 P 的最大值。 M 和 P 会适时的组合和断开，保证 P 中的待执行 G 队列能够得到及时运行。比如一个 G 如果因为网络 I/O 而阻塞了 M，那么 P 就会携带剩余的 G 投入到其它 M 的怀抱中。这个新的 M 可能是新创建的，也可能是从调度器空闲 M 列表中获取的，取决于此时的调度器空闲 M 列表中是否存在多余 M，从而避免 M 的过多创建。 一言蔽之，调度的本质就是 P 将 G 合理的分配给某个 M 的过程。 其它注意 本地队列有数量限制，即不允许超过 256 个，并且在新建G时，会优先选择P的本地队列。如果本地队列满了，则将P的本地队列中一半的G移动到全局队列，这可以理解为调度资源的共享和再平衡。 其中的steal行为是用来做什么的呢？当创建新的G或者G变成可运行状态时，它会被推送并加入到当前P的本地队列中。当P执行G完毕后，它开始“干活”，它会从本地队列中弹出G，同时检查当前本地队列是否为空。如果为空，则会随机的从其它P的 本地队列 中尝试窃取 一半 可运行的G到自己的名下。 ","link":"https://ninglg.com/post/golang-scheduler-machine-processor-goroutine-model/"},{"title":"有关分布式系统的几个理论","content":"此篇介绍几个跟分布式系统有关的理论。 FLP不可能原理 在网络可靠，存在节点失效（即便只有一个）的最小化异步模型系统中，不存在一个可以解决一致性问题的确定性算法。 CAP原理 一个分布式系统最多只能同时满足一致性（Consistency）、可用性（Availability）和分区容忍性（Partition tolerance）这三项中的两项。 一致性（Consistence) 对某个指定的客户端来说，读操作保证能够返回最新的写操作结果。 可用性（Availability） 非故障节点在合理的时间内返回合理的响应。 分区容忍性（Partition Tolerance） 当出现网络分区后，系统能够继续履行职责。 在分布式环境下，必须选择 P。因为网络原因可能出现故障，所以分区是一个必然现象。因此，分布式系统理论上不可能选择 CA 架构，只能选择 CP 或者 AP。 CAP理论说分布式系统中这3点无法同时满足，但一定不要理解错误了，不要认为我们在架构设计时，这个系统要么 CP 要么 AP。 要记住：CAP 关注的粒度是数据，系统中会包含多种类型的数据，有的必须选择 CP，有的必须选择 AP。 BASE理论 BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）。 基本可用（Basically Available） 分布式系统在出现故障时，允许损失部分可用性，保证核心可用。 软状态（Soft State） 允许系统存在中间状态，该中间状态不会影响系统整体可用性。 最终一致性（Eventual Consistency） 系统中所有数据副本经过一定时间后，最终能够达到一致状态。 BASE支持的是大型分布式系统，牺牲掉对一致性的约束（但实现最终一致性），来换取一定的可用性。 ACID原则 ACID原则指的是： Atomicity（原子性） Consistency（一致性） Isolation（隔离性） Durability（持久性） 用了四种特性的缩写。 ACID是传统数据库事务常用的设计理念，追求强一致性模型。 事务的隔离级别 读未提交（Read Uncommitted）：可能发生脏读、不可重复读、幻读 读已提交（Read Committed）：可能发生不可重复读、幻读 可重复读（Repeatable Read）：可能发生幻读 串行化（Serializable）：所有事务都是串行执行 ","link":"https://ninglg.com/post/theory-about-distributed-system/"},{"title":"Go语言垃圾回收机制(GC)","content":"此篇主要记录一下常见的GC算法以及Go语言采用的垃圾回收方式。 常见的GC算法 1. 引用计数（reference counting） 引用计数算法无法处理循环引用的问题。 2. 标记-清除（mark and sweep） 从根变量开始迭代所有被引用的对象，进行标记，最后对未被标记的变量进行清除。此算法会造成STW。为了优化这个问题，产生了三色标记算法： 1. 起初所有对象都是白色。 2. 从根出发扫描所有可达对象，标记为灰色，放入待处理队列。 3. 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色。 4. 重复步骤 3，直到灰色对象队列为空。此时白色对象即为垃圾，进行回收。 三色标记的一个明显好处是能够让用户程序和 mark 并发的进行。 3. 复制收集（Copy and Collection） 扫描时并不是对引用对象进行标记，而是开辟一块新的内存空间，将对象复制到新的空间中。一次扫描结束之后，所有存在于新空间的对象就是所有的非垃圾对象。 4. 分代收集（generation） 根据对象的存活周期不同将内存划分为新生代和老年代，存活周期短的为新生代，存活周期长的为老年代。这样就可以根据每块内存的特点采用最适当的收集算法。 对新生代进行高频小回收，然后将遗留下来的对象归为老年代，对所有对象进行低频大回收。 大多数分代回收算法都采用的复制收集方法，因为小回收中垃圾的比例较大。 这种方式存在一个问题：如果在某个新生代的对象中，存在老年代的对象对它的引用，它就不是垃圾了。那如何制止小回收对其回收呢？这里用到了一种叫做 写屏障（Write Barrier） 的方式。写屏障不仅用于分代收集，也用于其他GC算法中。在此算法的表现是，用一个记录集来记录从新生代到老年代的引用。 Go语言的垃圾回收 Go语言垃圾回收总体采用的是经典的mark and sweep算法。据官方说法，Go GC的基本特征是“非分代、非紧缩、写屏障、并发标记清理”。 Golang GC算法的里程碑 v1.1 STW v1.3 Mark STW, Sweep 并行 v1.5 三色标记法 v1.8 hybrid write barrier Go是一种使用了带有写屏障的、非分代的、并发标记清除的垃圾回收方式 GODEBUG=gctrace=1 go run main.go 如果在任何go run命令前面加上GODEBUG=gctrace=1，go就会打印关于垃圾回收操作的一些分析数据。 其它 在 “标记开始” 和 “标记结束” 两个阶段，都会出现STW，但在 “并发标记中” 阶段，不会出现STW。 可以通过设置GOGC变量来调整初始垃圾收集器的目标百分比值。其规则为，当新分配的数值与上一次收集后剩余的实时数值的比例达到设置的目标百分比时，就会触发GC。而GOGC的默认设置为GOGC=100，如果将其设置为GOGC=off，则可以完全禁用垃圾回收器。 一般来说，GOGC的值设置的越大，GC的频率越低，但每次GC所触发的堆内存也会越大。 在程序运行时，可以通过调用下述方法来动态调整GOGC的值： //runtime/debug debug.SetGCPercent 主动触发GC：可以通过runtime.GC方法来主动触发GC，也可以通过手动调用debug.FreeOSMemory方法来实现。 三色标记算法 三色标记算法（tricolor mark-and-sweep algorithm）是对传统 Mark-Sweep 算法的一个改进，它是一个支持写屏障的并发 GC 算法。其原理如下： step 1: 创建：白、灰、黑 三个集合。 step 2: 将所有对象都放入白色集合中。 step 3: 从根节点（全局变量+全局栈+当前活跃的goroutines中的栈）开始遍历其子对象，把遍历到的对象从白色集合放入灰色集合（备注：这里放入灰色集合的都是根节点的对象）。 step 4: 然后遍历灰色集合，将灰色对象引用的对象（备注：这里指的是灰色对象引用到的所有对象，包括灰色节点间接引用的那些对象）从白色集合放入灰色集合，然后将已经分析过的灰色对象放入黑色集合中。 step 5: 循环第4步，直到灰色中无任何对象。 step 6: 通过写屏障（write-barrier）检测对象有变化，重复以上操作（备注：因为 mark 和用户程序是并行的，所以在上一步执行的时候可能会有新的对象分配，写屏障是为了解决这个问题引入的）。 step 7: 收集所有白色对象（垃圾）。 GC的时机 每次内存分配时检查当前内存分配量是否已达到阈值（环境变量GOGC）：默认100%，即当内存扩大一倍时启用GC 定时触发：当最近2分钟未触发过GC时，会触发一次GC 通过runtime.GC()手动触发 GC的优化 分配的对象越多，GC性能就越差，所以需要减少对象分配的个数，比如使用 sync.Pool 进行对象复用。 注意：sync.Pool类似于缓存，其中的对象会被GC定期清理，不能存放像是数据库连接这样需要稳定存储的数据。 ","link":"https://ninglg.com/post/go-garbage-collection/"},{"title":"分布式锁","content":"此篇介绍一下分布式锁的相关内容。 当共享资源出现竞争时，为了防止出现并发问题，我们一般会采用锁机制来进行控制。在单机环境下，可以使用synchronized或Lock来实现；但是在分布式系统中，因为竞争的进程可能不在同一个节点上，所以需要一个让所有进程都能访问到的锁来实现，比如Redis、ZooKeeper等。 分布式锁 1. 基于数据库，如MySQL的实现 2. 基于缓存，如Redis的实现 Distributed locks with Redis 3. 基于ZooKeeper、etcd的实现 使用Zookeeper中的watch机制，当节点发生变化时，通知到监听者。 ","link":"https://ninglg.com/post/distributed-locks/"},{"title":"分布式事务","content":"分布式事务和分布式锁 分布式事务 强一致的分布式事务 XA协议、二阶段2PC（prepare、commit）、三阶段3PC提交。 XA协议 XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供。 X/Open DTP 模型（ 1994 ）包括应用程序（ AP ）、事务管理器（ TM ）、资源管理器（ RM ）、通信资源管理器（ CRM ）四部分。 2PC 二阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。 2PC面临的问题：同步阻塞问题，以及协调者故障后造成的数据部分一致问题。 Prepare + Commit/Cancel 3PC 三阶段提交（Three-phase commit），也叫三阶段提交协议（Three-phase commit protocol），是二阶段提交（2PC）的改进版本。 CanCommit + PreCommit + DoCommit/CancelCommit 如果因为协调者或网络问题，导致参与者迟迟不能收到来自协调者的commit或rollback请求，那么参与者将不会如两阶段提交中那样陷入阻塞，而是等待超时后继续commit。相对于两阶段提交虽然降低了同步阻塞，但仍然无法避免数据的不一致性。 柔性事务 根据BASE理论，达到最终一致性。 DNS 就是一个典型的最终一致性系统。 在工程实践上，为了保障系统的可用性，互联网系统大多将强一致性需求转换成最终一致性的需求，并通过系统执行幂等性的保证，保证数据的最终一致性。 最终一致性 TCC补偿机制（Try、Confirm/Cancel） 其核心思想是：针对每个操作，都要注册一个与其对应的确认和补偿（撤销）操作。 TCC施行步骤 Try 阶段主要是对业务系统做检测及资源预留。 Confirm 阶段主要是对业务系统做确认提交，Try阶段执行成功并开始执行Confirm阶段时，默认 Confirm阶段是不会出错的。 Cancel 阶段主要是在业务执行错误，需要回滚的状态下执行的业务取消，预留资源释放。 TCC与2PC协议比较： 位于业务服务层而非资源层 没有单独的准备(Prepare)阶段，Try操作兼备资源操作与准备能力 Try操作可以灵活选择业务资源的锁定粒度(以业务定粒度) 较高开发成本 本地消息表 类似于可靠消息方案。 消息生产方，需要额外建一个消息表，并记录消息发送状态。消息表和业务数据要在一个事务里提交，也就是说他们要在一个数据库里面。然后消息会经过MQ发送到消息的消费方。如果消息发送失败，会进行重试发送。 消息消费方，需要处理这个消息，并完成自己的业务逻辑。此时如果本地事务处理成功，表明已经处理成功了，如果处理失败，那么就会重试执行。如果是业务上面的失败，可以给生产方发送一个业务补偿消息，通知生产方进行回滚等操作。 生产方和消费方定时扫描本地消息表，把还没处理完成的消息或者失败的消息再发送一遍。 优点： 一种非常经典的实现，避免了分布式事务，实现了最终一致性。 缺点： 消息表会耦合到业务系统中，如果没有封装好的解决方案，会有很多杂活需要处理。 事务消息 通过使用RocketMQ，第一阶段发送Prepared消息时，会拿到消息的地址，第二阶段执行本地事务，第三阶段通过第一阶段拿到的地址去访问消息，并修改消息的状态。 其他 XA协议是一个基于数据库的分布式事务协议，其分为两部分：事务管理器和本地资源管理器。事务管理器作为一个全局的调度者，负责对各个本地资源管理器统一号令提交或者回滚。二阶提交协议（2PC）和三阶提交协议（3PC）就是根据此协议衍生出来而来。目前 Oracle、Mysql 等数据库均已实现了XA接口。 两段提交（2PC）就是进行两个阶段的提交：第一阶段，准备阶段(投票阶段) ；第二阶段，提交阶段（执行阶段）。 三段提交（3PC）是对两段提交（2PC）的一种升级优化，3PC在2PC的第一阶段和第二阶段中插入一个准备阶段。保证了在最后提交阶段之前，各参与者节点的状态都一致。同时在协调者和参与者中都引入超时机制，当参与者各种原因未收到协调者的commit请求后，会对本地事务进行commit，不会一直阻塞等待，解决了2PC的单点故障问题，但3PC 还是没能从根本上解决数据一致性的问题。 3PC 的三个阶段分别是CanCommit、PreCommit、DoCommit。 TCC与2PC的思想很类似，事务处理流程也很类似，但2PC 是应用于在DB层面，TCC则可以理解为在应用层面的2PC，是需要开发者编写业务逻辑来实现的。 TCC的核心思想是：&quot;针对每个操作都要注册一个与其对应的确认（Try）和补偿（Cancel）&quot;。 ","link":"https://ninglg.com/post/distributed-transaction/"},{"title":"Docker原理介绍","content":"此篇记录使用Docker的一些基本概念和操作。 虚拟机和容器 虚拟机 -&gt; 模拟整个计算机，容器 -&gt; 只提供操作系统级别的虚拟化。 Docker本质上就是一种管理容器的平台软件。Docker是对运行特定应用所需的全部程序（包括操作系统在内）的一种轻量级虚拟化。 Docker引擎由Docker客户端、Docker守护进程以及不同的Docker容器组成，这些容器为Docker镜像的实例。 Docker镜像可以通过Dockerfile创建，并且镜像还能够存储在Docker注册中心（registy）中。 Docker 架构 Docker 采用的是 Client/Server 架构。客户端向服务器发送请求，服务器负责构建、运行和分发容器。 客户端和服务器可以运行在一个 Host 上，客户端也可以通过 socket 或 REST API 与远程的服务器通信。 Docker 的核心组件 Docker 客户端：client Docker 服务器：Docker daemon Docker 镜像：Image Registry Docker 容器：Container Docker的三个基本概念 镜像（Image） 由一组文件系统（多层文件系统）联合组成。 镜像是静态的定义，类似于一个只读模板。 有好几种不同的方法可以创建Docker镜像，其中一种就是在一个名为Dockerfile的文件里包含一系列指令。 容器层记录对镜像的修改，所有镜像层都是只读的，不会被容器修改，所以镜像可以被多个容器共享。 只有当需要修改时才复制一份数据，这种特性被称作 Copy-on-Write。可见，容器层保存的是镜像变化的部分，不会对镜像本身进行任何修改。 容器（Container） 容器是镜像运行时的实体。 容器是一种轻量级、可移植、自包含的软件打包技术，使应用程序可以在几乎任何地方以相同的方式运行。容器使软件具备了超强的可移植能力。 容器可以被创建、启动、停止、删除、暂停等。 容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的 命名空间。 容器在运行时会为读写准备一个临时存储层，称为容器存储层。容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。 容器不应该向其存储层内写入任何数据，容器存储层要保持无状态化。所有的文件写入操作，都应该使用 数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。 仓库（Repository） 一个集中的存储、分发镜像的服务。 可以通过 &lt;仓库名&gt;:&lt;标签&gt; 的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以 latest 作为默认标签。 最常使用的 Registry 公开服务是官方的 Docker Hub（ https://hub.docker.com ）， 这也是默认的 Registry，并拥有大量的高质量的官方镜像。Docker Hub提供公开和私有的Docker镜像，但私有的Docker镜像需要付费才能使用。 Docker架构 Docker client客户端：Docker的客户端向Docker Daemon发起请求。 Docker Daemon守护进程：Docker是C/S架构的程序，Docker的客户端向守护进程发起请求，守护进程处理完成后返回结果。Docker客户端既可以在本地访问守护进程，也可以通过 socket 或 REST API 远程访问守护进程。 Docker Image镜像：Docker 容器运行时的只读模板。 Docker Container容器：Docker 容器和文件夹很类似，一个Docker容器包含了所有的某个应用运行所需要的环境。 Docker Registry仓库：Docker 仓库用来保存镜像，可以理解为代码控制中的代码仓库 Docker Network网络：Docker网络用来保证容器之间，以及容器的内外部通信。 安装 Docker Docker 分为 CE 和 EE 两大版本。CE 即社区版（免费），EE 即企业版，强调安全，付费使用。 Docker 命令 验证安装正确 docker version docker info 运行一个 Nginx 服务器 docker run -d -p 80:80 --name webserver nginx 服务运行后访问 http://localhost ，如果看到了 &quot;Welcome to nginx!&quot; 说明 Docker 安装成功。 要停止 Nginx 服务器并删除执行下面的命令： docker stop webserver docker rm webserver 从 Docker 镜像仓库获取镜像的命令是 docker pull。其命令格式为： docker pull [选项] [Docker Registry 地址[:端口号]/]仓库名[:标签] 具体的选项可以通过 docker pull --help 命令看到。 Docker 镜像仓库地址的格式一般是 &lt;域名/IP&gt;[:端口号]。默认地址是 Docker Hub。 仓库名是两段式名称，即 &lt;用户名&gt;/&lt;软件名&gt;。对于 Docker Hub，如果不给出用户名，则默认为 library，也就是官方镜像。 从下载过程中可以看到我们之前提及的分层存储的概念，镜像是由多层存储所构成。下载也是一层层的去下载，并非单一文件。 运行容器的命令 docker run 例如： docker run hello-world docker run -it ubuntu bash docker run -i -t centos 列出镜像 docker image ls docker image ls -a docker image ls xxxxx 查看镜像、容器、数据卷所占用的空间 docker system df 删除无用的虚悬镜像 docker image prune 删除本地镜像 docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] docker rmi IMAGE_NAME|IMAGE_ID 其它 -d 让容器在后台运行 -p 指定端口映射，格式为主机(宿主)端口:容器端口 --restart 重启模式，设置 always，每次启动 Docker 都会启动 Nginx 容器。 例如： docker run -d -p 80:80 nginx // 启动nginx容器，并映射到宿主机的80端口 访问 http://localhost 进行验证 docker ps -n 5 // 查看容器list及状态 docker stop [CONTAINER ID] // 停止nginx容器 Dockerfile Dockerfile的基本指令有十三个。下面介绍常用的几个： FROM 所有Dockerfile的第一个指令都必须是 FROM，用于指定一个构建镜像的基础源镜像，如果本地没有就会从公共库中拉取，没有指定镜像的标签会使用默认的latest标签，如果需要在一个Dockerfile中构建多个镜像，可以使用多次。 MAINTAINER 描述镜像的创建者，名称和邮箱。 RUN RUN命令是一个常用的命令，启动某个镜像。执行完成之后会成为一个新的镜像，通常用于运行安装任务从而向映像中添加额外的内容。 COPY 复制本机文件或目录，添加到指定的容器目录中。 WORKDIR 为RUN、CMD、ENTRYPOINT指令配置工作目录。可以使用多个WORKDIR指令，后续参数如果是相对路径，则会基于之前命令指定的路径。 ENTRYPOINT 在启动容器的时候提供一个默认的命令项。 docker安装redis 搜索镜像 docker search redis 加载redis镜像 docker pull redis 启动redis容器 docker run -p 6379:6379 -v $PWD/data:/data -d redis redis-server --appendonly yes --requirepass &quot;123456&quot; 查看运行的容器 docker ps 设置自启 docker update --restart=always [容器id] 进入redis镜像 docker exec -it 容器ID redis-cli 创建Docker映像 docker build -t docker-xxx:0.1 . 或者 docker build Docker远程访问 docker的远程访问一般占用2375端口。 Docker其它管理 Docker ps/top/stats 是原生的命令行监控工具。除了命令行，Docker 也提供了 stats API，用户可以通过 HTTP 请求获取容器的状态信息。 Docker logs 是原生的日志工具。另外还有 logspout 对日志提供了路由功能，它可以收集不同容器的日志并转发给其它工具进行后处理。 Docker可视化管理工具 1. UI For Docker docker pull uifd/ui-for-docker docker run -it -d --name docker-web -p 9500:9000 -v /var/run/docker.sock:/var/run/docker.sock docker.io/uifd/ui-for-docker 然后通过浏览器访问 http://127.0.0.1:9500 即可。 2. Portainer docker volume create portainer_data docker run -d -p 9500:9000 -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer 然后通过浏览器访问 http://127.0.0.1:9500 即可。 Docker实现原理 Docker的实现依赖Linux底层三大基础能力： 1、chroot &amp; pivot_root 模拟：模拟文件系统 2、namespace 隔离：隔离进程 3、CGroup 限制：限制资源访问量 ","link":"https://ninglg.com/post/docker-intro/"},{"title":"微服务设计","content":"此篇是早前《微服务设计》的读书笔记，在此记录一下。 微服务 微服务就是一些协同工作的小而自治的服务。 每个服务都很小，专注于做好一件事。 服务之间均通过网络调用进行通信，从而加强了服务之间的隔离性，避免紧耦合。 微服务的好处 技术异构性 弹性 扩展 简化部署 与组织结构相匹配 可组合性 对可替代性的优化 没有银弹！ 为了得到微服务的好处，需要在部署、测试和监控方面做很多的工作，还需要考虑如何扩展系统，并且保证它们的弹性，也还需要处理分布式事务或者与CAP相关的问题。 很多组织采用微服务是为了使团队的自治性最大化。 演进式架构师 愿景、同理心、合作 保证该系统适合开发人员在其上工作 从更高的层次出发，理解如何做权衡 治理和监督 如何建模服务 好服务的标准 高内聚 低耦合 集成 微服务之间通信方式的选择非常多样化 SOAP XML-RPC REST Protocol Buffers Thrift 本地调用和远程调用并不相同 RPC的核心想法是隐藏远程调用的复杂性。使用本地调用不会引起性能问题，但是RPC会花大量的时间对负荷进行封装和解封装，更别提网络通信所需要的时间。 需要注意的是，HTTP也可以用来实现RPC。比如SOAP就是基于HTTP进行路由的，但不幸的是它只用到HTTP很少的特性，而动词和HTTP的错误码都被忽略了。 通过HTTP我们可以发送任何格式，甚至是二进制的。 实现基于事件的异步协作方式 服务即状态机 使用语义化的版本管理 MAJOR.MINOR.PATCH 短期内同时使用两个版本的服务是合理的，尤其是当你做蓝绿部署或者金丝雀发布时 API组合 使用API入口（gateway）可以缓解移动设备与服务过多通信的问题，在这种模式下多个底层的调用会被聚合成为一个调用，当然它也有一定的局限性。 分解单块系统 最好考虑把哪部分代码抽取出去得到的收益最大，而不是为了抽取而抽取 想要抽取出来的接口应该尽量少的被其它组件所依赖 先分离数据库，再对服务进行分离 重试保证最终一致性 补偿事务 分布式事务，事务管理器 部署 真正理解CI的三个问题 每天签入代码到主干 有一组测试来验证修改 把修复CI当做第一优先级的事情来做 平台即服务 PaaS（Platform-as-a-Service） 传统的虚拟化技术 采用标准虚拟化的如AWS、VMWare、VSphere、Xen和KVM等。 基于轻量级容器的虚拟化（LXC） Docker 测试 单元测试 TDD：Test-Driven Development，测试驱动开发 Mock还是打桩 金丝雀发布 金丝雀发布是指通过将部分生产流量引流到新部署的系统，来验证系统是否按预期执行。 金丝雀发布与蓝/绿发布的不同之处在于，新旧版本共存的时间更长，而且经常会调整流量。 Netflix广泛采用金丝雀发布的方式，通过对比新版本与基线版本的分数，只有当新版本分数更高时，才会全面部署新版本到生产环境。 平均修复时间胜过平均故障间隔时间 平均故障间隔时间（MTBF，Mean Time Between Failures） 平均修复时间（MTTR，Mean Time To Repaire） 监控 监控小的服务，然后聚合起来看整体。 安全 单点登录SSO（Single Sign-On） HTTPS基本身份验证 客户端证书TLS（Transport Layer Security，安全传输层协议） API秘钥 不要实现自己的加密算法，不要发明自己的安全协议。 康威定律与系统设计 组织和架构应该一致，信奉这个理念的两个典范是Amazon和Netflix。 每条业务线团队，负责自己创建的服务的整个生命周期，包括构建、测试、发布和运维，甚至弃用。 规模化微服务 当微服务的数量比人还多时，有什么应对的模式吗？ 故障无处不在 除了使用流程和控制来试图阻止故障的发生外，更应该思考如何更加容易的在第一时间从故障中恢复过来。 功能降级 年度DiRT（Disaster Recovery Test，灾难恢复测试） 超时、断路器 幂等 CQRS（Command-Query Responsibility Segregation，命令查询职责分离）模式，是一个存储和查询信息的替代模型。 缓存 客户端、代理和服务器端缓存 HTTP缓存： cache-control expires etag（entity tags） CAP定理 在分布式系统中，需要有三方面进行权衡： 一致性（consistency） 可用性（availability） 分区容忍性（partition tolerance） 如果系统没有分区容忍性，就不能跨网络运行。换句话说，需要在本地运行一个单独的进程。所以，CA系统在分布式系统中根本是不存在的。选择AP还是CP，在现实中要视情况而定。 服务发现 动态服务注册 Zookeeper Consul 总结 围绕业务概念建模 接受自动化文化 隐藏内部实现细节 ","link":"https://ninglg.com/post/building-microservices/"},{"title":"钢铁侠","content":" 钢铁侠 天才科学家 亿万富豪 花花公子 慈善家 ","link":"https://ninglg.com/post/iron-man/"},{"title":"追求的目标","content":" Start an amazing career Increase the wealth of mankind To see an unknown landscape Reach the depth of thought ","link":"https://ninglg.com/post/goals-of-life/"},{"title":"为自由而探险","content":" sense of crisis，有危机意识 new skill，掌握新技能 curiosity，保持好奇心 man of action，提高行动力 ","link":"https://ninglg.com/post/expedition-for-freedom/"},{"title":"领域驱动设计（DDD）和微服务拆分","content":"领域驱动设计（DDD）和微服务拆分 DDD 全称 Domain-Driven Design（领域驱动设计），是一套应对复杂软件系统分析和设计的面向对象建模方法论。 高内聚，低耦合。 有 DDD 的指导，加上微服务的事件，才是完美的架构。（因为微服务的侧重点是治理，而不是拆分。） 聚合 聚合是一个或多个实体的集合，也可能包含值对象。 集合的父实体被称为聚合根（Aggregate Root）。 值对象 值对象与实体的区别在于值对象是不可变的，并且没有唯一的标识，仅由其属性的值所定义。 实体 实体是具有惟一标识符的潜在可变对象，在其域模型中有自己的生命周期，能够获得该实体完整状态转换历史。 例如，在电子商务领域，可以定义一个命名为 Order 的聚合，包含 Address（值对象）和 Consumer（实体）。 设计领域模型的一般步骤 根据需求划分出初步的领域和限界上下文，以及上下文之间的关系； 进一步分析每个上下文内部，识别出哪些是实体，哪些是值对象； 对实体、值对象进行关联和聚合，划分出聚合的范畴和聚合根； 为聚合根设计仓储，并思考实体或值对象的创建方式； 在工程中实践领域模型，并在实践中检验模型的合理性，倒推模型中不足的地方并重构。 模式举例 1. 贫血模型 Domain Object 包含了不依赖于持久化的领域逻辑，而那些依赖持久化的领域逻辑被分离到 Service 层。 2. 充血模型 将绝大多数业务逻辑放到 Domain 中，Service 是很薄的一层，封装少量业务逻辑，并且不和 DAO 打交道。 ","link":"https://ninglg.com/post/microservice-domain-driven-design/"},{"title":"在Mac上通过brew安装指定版本的MySQL","content":"安装指定版本的MySQL 为了避免出现以下错误： ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/tmp/mysql.sock' 可以通过以下步骤安装MySQL5.7版本： brew uninstall mysql@5.7 rm -rf /usr/local/var/mysql rm /usr/local/etc/my.cnf brew install mysql@5.7 brew link --force mysql@5.7 brew services start mysql@5.7 ","link":"https://ninglg.com/post/mac-brew-install-mysql-5.7/"},{"title":"Hive和HBase在大数据中的应用场景","content":"简单介绍Hive和HBase在大数据中的应用场景。 Hive Hive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能。 Hive本身不存储和计算数据，它完全依赖于HDFS和MapReduce，Hive中的表纯逻辑。hive需要用到hdfs存储文件，需要用到MapReduce计算框架。 hive可以认为是map-reduce的一个包装。hive的意义就是把好写的hive的sql转换为复杂难写的map-reduce程序。 HBase HBase是Hadoop的数据库，一个分布式、可扩展、大数据的存储。 HBase是物理表，不是逻辑表，提供一个超大的内存hash表，搜索引擎通过它来存储索引，方便查询操作。 HBase可以认为是hdfs的一个包装。他的本质是数据存储，是个NoSql数据库。HBase部署于hdfs之上，并且克服了hdfs在随机读写方面的缺点。 联系与区别 Hbase和Hive在大数据架构中处在不同位置，Hbase主要解决实时数据查询问题，Hive主要解决数据处理和计算问题，一般是配合使用。 在大数据架构中，Hive和HBase是协作关系。 数据流一般如下： （1）通过ETL工具将数据源抽取到HDFS存储。 （2）通过Hive清洗、处理和计算原始数据。 （3）HIve清洗处理后的结果，如果是面向海量数据随机查询场景的可存入Hbase。 （4）数据应用从HBase查询数据。 ","link":"https://ninglg.com/post/hive-hbase-in-bigdata/"},{"title":"Go语言的常用编解码器（序列化/反序列化）","content":"Go语言常用到的几种编解码器 编解码器 base64 gob json thrift msgpack protobuf gencode base64 示例代码如下： package main import ( &quot;encoding/base64&quot; &quot;fmt&quot; ) func main() { msg := &quot;Hello, 世界&quot; encoded := base64.StdEncoding.EncodeToString([]byte(msg)) fmt.Println(&quot;base64 encode: &quot;, encoded) decoded, err := base64.StdEncoding.DecodeString(encoded) if err != nil { fmt.Println(&quot;base64 decode error: &quot;, err) return } fmt.Println(&quot;base64 decode: &quot;, string(decoded)) } 输出结果如下： base64 encode: SGVsbG8sIOS4lueVjA== base64 decode: Hello, 世界 json 示例代码如下： package main import ( &quot;encoding/json&quot; &quot;fmt&quot; ) type Person struct { Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;` } func main() { p := Person{ Name: &quot;xiaoming&quot;, Age: 16, } ret, _ := json.Marshal(p) fmt.Println(string(ret)) pp := Person{} _ = json.Unmarshal(ret, &amp;pp) fmt.Printf(&quot;%+v&quot;, pp) } 输出结果如下： {&quot;name&quot;:&quot;xiaoming&quot;,&quot;age&quot;:16} {Name:xiaoming Age:16} gob（Go binary） 示例代码如下： package main import ( &quot;bytes&quot; &quot;encoding/gob&quot; &quot;fmt&quot; &quot;log&quot; ) type P struct { X, Y, Z int Name string } type Q struct { X, Y *int32 Name string } func main() { buf := new(bytes.Buffer) enc := gob.NewEncoder(buf) dec := gob.NewDecoder(buf) // Encode (send) the value. err := enc.Encode(P{3, 4, 5, &quot;Pythagoras&quot;}) if err != nil { log.Fatal(&quot;encode error:&quot;, err) } fmt.Println(buf.Bytes()) // Decode (receive) the value. var q Q err = dec.Decode(&amp;q) if err != nil { log.Fatal(&quot;decode error:&quot;, err) } fmt.Printf(&quot;%q: {%d,%d}\\n&quot;, q.Name, *q.X, *q.Y) } 输出结果如下： [42 255 129 3 1 1 1 80 1 255 130 0 1 4 1 1 88 1 4 0 1 1 89 1 4 0 1 1 90 1 4 0 1 4 78 97 109 101 1 12 0 0 0 21 255 130 1 6 1 8 1 10 1 10 80 121 116 104 97 103 111 114 97 115 0] &quot;Pythagoras&quot;: {3,4} msgpack 示例代码如下： package main import ( &quot;fmt&quot; &quot;github.com/vmihailenco/msgpack&quot; ) type Person struct { Name string Age int Gender string } func main() { p1 := Person{ Name: &quot;xiaoming&quot;, Age: 16, Gender: &quot;M&quot;, } // marshal b, err := msgpack.Marshal(p1) if err != nil { fmt.Printf(&quot;msgpack marshal failed, err:%v&quot;, err) return } // unmarshal var p2 Person err = msgpack.Unmarshal(b, &amp;p2) if err != nil { fmt.Printf(&quot;msgpack unmarshal failed, err:%v&quot;, err) return } fmt.Printf(&quot;p2:%#v\\n&quot;, p2) } 输出结果如下： p2:main.Person{Name:&quot;xiaoming&quot;, Age:16, Gender:&quot;M&quot;} protobuf #gencode andyleap/gencode 字符串格式化常用功能 格式化 功能 %v 按值的本来值输出 %+v 在 %v 基础上，对结构体字段名和值进行展开 %#v 输出 Go 语言语法格式的值 %T 输出 Go 语言语法格式的类型和值 %% 输出 % 本体 %b 整型以二进制方式显示 %o 整型以八进制方式显示 %d 整型以十进制方式显示 %x 整型以十六进制方式显示 %X 整型以十六进制、字母大写方式显示 %U Unicode 字符 %f 浮点数 %p 指针，十六进制方式显示 性能测试结果 由快到慢：gencode、msgpack、protobuf、json、xml ","link":"https://ninglg.com/post/golang-encoder-decoder/"},{"title":"减小Go代码编译后可执行程序的体积","content":"此篇介绍一下如何减小Go程序编译后生成的可执行程序的体积。 Golang默认编译出来的可执行文件，一般都比较大。此处介绍一些可以减小可执行文件体积的方法。 Golang编译参数调整 go build -ldflags=&quot;-s -w&quot; main.go -s：忽略符号表和调试信息 -w：忽略DWARFv3调试信息，不生成debug信息，使用该选项后将导致无法使用gdb进行调试 注：Go编译器生成的调试信息格式为DWARFv3，只要版本高于7.1的GDB都可以支持调试 go build -gcflags '-N -l' -N 禁止编译优化 -l 禁止内联，禁止内联也可以在一定程度上减小可执行程序大小 可以使用 go tool compile --help 查看 gcflags 各参数含义 UPX压缩 https://github.com/upx/upx upx是一个二进制压缩工具，可以用来压缩编译出来的二进制文件尺寸。 upx --brute bin upx --ultra-brute bin 可以使用不同的压缩参数，来进行不同程度的压缩。 ","link":"https://ninglg.com/post/reduce-golang-executable-program-size/"},{"title":"Protobuf 3介绍","content":"Protobuf 3介绍 syntax = &quot;proto3&quot;; import &quot;google/protobuf/wrappers.proto&quot;; package company; option go_package=&quot;./pb&quot;; service OrderManagement { rpc addOrder(Order) returns (google.protobuf.StringValue); rpc getOrder(google.protobuf.StringValue) returns (Order); rpc searchOrders(google.protobuf.StringValue) returns (stream Order); rpc updateOrders(stream Order) returns (google.protobuf.StringValue); rpc processOrders(stream google.protobuf.StringValue) returns (stream CombinedShipment); } message Order { string id = 1; repeated string items = 2; string description = 3; float price = 4; string destination = 5; } message CombinedShipment { string id = 1; string status = 2; repeated Order ordersList = 3; } ","link":"https://ninglg.com/post/protobuf-3/"},{"title":"扫码登陆系统设计","content":"此篇介绍一下常见的扫码登陆系统的设计思路。 ","link":"https://ninglg.com/post/scan-qrcode-login-system-desgin/"},{"title":"Go语言sync同步包使用","content":"Go语言sync包使用 sync同步包 工具 说明 Mutex 互斥锁 RWMutex 读写锁 WaitGroup 并发等待组 Map 并发安全字典 Cond 同步等待条件 Once 只执行一次 Pool 临时对象池 ","link":"https://ninglg.com/post/go-sync-usage/"},{"title":"Go结构体里的Tag标签","content":"Go结构体里的Tag标签 struct 的 Tag 示例 type Person struct { Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot;` Addr string `json:&quot;addr,omitempty&quot;` } 如何获取 Tag 的信息 获取 Tag 可以分为三个步骤： 获取字段 field 获取标签 tag 获取键值对 key:value 获取 Tag 的示例 // 三种方式可获取 field field := reflect.TypeOf(obj).FieldByName(&quot;Name&quot;) field := reflect.ValueOf(obj).Type().Field(i) // i 表示第几个字段 field := reflect.ValueOf(&amp;obj).Elem().Type().Field(i) // i 表示第几个字段 // 获取 Tag tag := field.Tag // 获取键值对 labelValue := tag.Get(&quot;label&quot;) labelValue,ok := tag.Lookup(&quot;label&quot;) 获取键值对，有 Get 和 Lookup 两种方法。但其实 Get 只是对 Lookup 函数的简单封装而已，当没有获取到对应 tag 的内容时，会返回空字符串。 空 Tag 和不设置 Tag 效果是一样的。 单元示例 func Print(obj interface{}) error { // 取 Value v := reflect.ValueOf(obj) // 解析字段 for i := 0; i &lt; v.NumField(); i++ { // 取tag field := v.Type().Field(i) tag := field.Tag // 解析label 和 default label := tag.Get(&quot;label&quot;) defaultValue := tag.Get(&quot;default&quot;) value := fmt.Sprintf(&quot;%v&quot;, v.Field(i)) if value == &quot;&quot; { // 如果没有指定值，则用默认值替代 value = defaultValue } fmt.Println(label + value) } return nil } ","link":"https://ninglg.com/post/go-struct-tag-label/"},{"title":"PostgreSQL 简介","content":"此篇简要介绍一下 PostgreSQL 的相关内容。 安装并启动 PostgreSQL brew install postgresql brew services start postgresql 或者也可以使用官方提供的安装方法 查看安装的版本 $ pg_ctl -V pg_ctl (PostgreSQL) 12.1 ","link":"https://ninglg.com/post/postgresql-intro/"},{"title":"Go字符串处理","content":"Go字符串处理 常用字符串处理函数 函数 作用 strings.TrimSpace(str) 去除字符串str两边的空格 strings.Trim(str, &quot;指定字符&quot;) 将字符串str两边的指定字符去除 strings.TrimLeft(str, &quot;指定字符&quot;) 将字符串左边的指定字符去除 strings.TrimRight(str, &quot;指定字符&quot;) 将字符串右边的指定字符去除 strings.HasPrefix(str, &quot;指定字符&quot;) 判断字符串是否以指定字符开头 strings.HasSuffix(str, &quot;指定字符&quot;) 判断字符串是否以指定字符结尾 strings.Compare(str1, str2) 比较两个字符串大小 strings.Index(str, &quot;子串&quot;) 返回子串出现的第一个位置 strings.LastIndex(str, &quot;子串&quot;) 返回子串出现的最后一个位置 strings.Count(&quot;abcabcabababc&quot;, &quot;abc&quot;) 统计子串在整体当中出现的次数 strings.Repeat(&quot;abc&quot;, 10) 将字符串重复指定的次数 strings.Replace(str, &quot;a&quot;, &quot;b&quot;, -1) 替换字符串中的部分子串 strings.Split(str, &quot;,&quot;) 分割字符串 strings.Join(slice, &quot;,&quot;) 字符串拼接 字符串长度 package main import ( &quot;fmt&quot; ) func main() { str := &quot;hello世界&quot; fmt.Println(len(str)) //输出11，一个汉字需要3个字节编码 fmt.Println(len([]rune(str))) //输出7，rune表示单个Unicode字符 } 字符串转整数或浮点数 strconv.ParseInt()，可以指定转换的进制，以及返回的bit位数 strconv.Atoi()，默认按10进制转换，返回int型 strconv.ParseFloat()，可指定返回的bit位数 整数或浮点数转字符串 strconv.FormatInt() strconv.Itoa() strconv.FormatFloat() 字符串和bool型转换 strconv.ParseBool() strconv.FormatBool() 字符串拼接的性能 字符串拼接常用的几种方式： （1）使用strings.Builder：建议使用 （2）使用bytes.Buffer：性能好，可读性差 （3）使用copy （4）使用append （5）使用+号：性能居中，可读性好 （6）使用strings.Repeat：适合合并大量重复的字符串 （7）使用string.Join：性能较好 （8）使用fmt.Sprintf：性能较差 ","link":"https://ninglg.com/post/golang-strings/"},{"title":"Go程序性能分析工具","content":"此篇介绍一下对Go程序进行性能分析的常用工具及用法。 常用命令和工具 pprof go tool [xxx] go test delve go race gdb 程序编译时的参数传递（gcflags和ldflags） gcflags go build -gcflags '-N -m -l' main.go //可使用go tool compile --help查看可用参数及含义。 比如-N禁用编译优化，-l禁止内联，-m打印编译优化策略（包括逃逸情况和函数是否内联，以及变量分配在堆或栈），-S是打印汇编。 如果只在编译特定包时需要传递参数，格式应遵守“包名=参数列表”，如go build -gcflags='log=-N -l' main.go 开启逃逸分析日志很简单，只要在编译的时候加上-gcflags '-m'，另外为了不让编译时自动内联函数，一般也会加-l参数，最终成为-gcflags '-m -l'。即执行如下命令： $ go build -gcflags '-m -l' main.go ldflags go build用 -ldflags 给go链接器传入参数，实际是给go tool link的参数，可以用go tool link --help查看可用的参数。 常用 -X 来指定版本号等编译时才决定的参数值。例如代码中定义var buildVer string，然后在编译时用go build -ldflags &quot;-X main.buildVer=1.0&quot; 来赋值。注意 -X 只能给string类型变量赋值。 传值会拷贝整个对象，而传指针只会拷贝指针地址，指向的对象是同一个。传指针可以减少值的拷贝，但是会导致内存分配逃逸到堆中，增加垃圾回收(GC)的负担。在对象频繁创建和删除的场景下，传递指针导致的 GC 开销可能会严重影响性能。 一般情况下，对于需要修改原对象值，或占用内存比较大的结构体，选择传指针。对于只读的占用内存较小的结构体，直接传值能够获得更好的性能。 go build -x 列出了go build触发的所有命令。 比如工具链、跨平台编译、传入外部编译器的flags、链接器等，可使用 -x 来查看所有的触发。 竞争检测 使用 go run -race main.go 或 go build -race main.go 来进行竞争检测。 GC日志和调度器事件 执行前添加系统环境变量 GODEBUG='gctrace=1' 来跟踪打印垃圾回收器信息 在代码中使用 runtime.ReadMemStats 来获取程序当前内存的使用情况 使用pprof工具 GODEBUG=gctrace=1 go run main.go //跟踪打印垃圾回收器信息。Go程序会每隔一段时间打印一些gc信息。 GODEBUG=schedtrace=1 go run main.go //参数 schedtrace=1 会按毫秒打印 Go 调度器的调度事件 字段解释 GODEBUG=gctrace=1 go run main.go gc 1 @0.006s 1%: 0.015+0.76+0.034 ms clock, 0.24+0.45/0.67/0.011+0.55 ms cpu, 4-&gt;4-&gt;0 MB, 5 MB goal, 16 P gc 1: 1 是垃圾回收的编号，逐步递增，一般从 1 开始 @0.006s: 自程序开始经历了多少时间 1%: 自程序启动花在 GC 上的 CPU 时间百分比, CPU 1%花在了 GC 上 0.015+0.76+0.034 ms clock: GC 各阶段的墙上时间(wall-clock)，各阶段包括STW sweep termination、concurrent mark and scan、STW mark termination 0.24+0.45/0.67/0.011+0.55 ms cpu: 各阶段的 CPU 时间。各阶段同上，其中 mark/scan 阶段又分成了assist time、background GC time和idle GC time阶段 4-&gt;4-&gt;0 MB: GC 开始时、GC 结束的 heap 大小、存活(live)的 heap 大小 5 MB goal:下一次垃圾回收的目标值 16 P: 使用的处理器的数量 程序中可以调用runtime.GC()进行强制垃圾回收。 Pprof Go语言内置了获取程序运行数据的工具，包括以下两个标准库 runtime/pprof：采集工具型应用运行数据进行分析 net/http/pprof：采集服务型应用运行时数据进行分析 工具型应用分析 CPU分析 f, err := os.Create(*cpuprofile) ... pprof.StartCPUProfile(f) defer pprof.StopCPUProfile() 内存分析 f, err := os.Create(*memprofile) pprof.WriteHeapProfile(f) f.Close() 使用net/http包时启用Pprof package main import ( &quot;log&quot; &quot;net/http&quot; _ &quot;net/http/pprof&quot; ) func main() { //... do something log.Println(http.ListenAndServe(&quot;localhost:8090&quot;, nil)) } 使用Gin框架时启用Pprof package main import ( &quot;github.com/gin-contrib/pprof&quot; &quot;github.com/gin-gonic/gin&quot; ) func main() { app := gin.Default() pprof.Register(app) app.Run(&quot;:8090&quot;) } 访问web页获取分析结果（http://127.0.0.1:8090/debug/pprof，适合http服务） /debug/pprof/ Types of profiles available: Count Profile 3 allocs 0 block //goroutine的阻塞信息 0 cmdline 4 goroutine //此项可排查是否创建了大量的 goroutine 3 heap //堆内存的分配信息 0 mutex //锁的信息 0 profile 7 threadcreate //线程信息 0 trace full goroutine stack dump //此项可排查是否有 goroutine 运行时间过长 Profile Descriptions: allocs: A sampling of all past memory allocations block: Stack traces that led to blocking on synchronization primitives cmdline: The command line invocation of the current program goroutine: Stack traces of all current goroutines heap: A sampling of memory allocations of live objects. You can specify the gc GET parameter to run GC before taking the heap sample. mutex: Stack traces of holders of contended mutexes profile: CPU profile. You can specify the duration in the seconds GET parameter. After you get the profile file, use the go tool pprof command to investigate the profile. threadcreate: Stack traces that led to the creation of new OS threads trace: A trace of execution of the current program. You can specify the duration in the seconds GET parameter. After you get the trace file, use the go tool trace command to investigate the trace. pprof 支持四种类型的分析 pprof开启后，每隔一段时间（10ms）就会收集当前的堆栈信息，获取各个函数占用的CPU以及内存资源，然后通过对这些采样数据进行分析，形成一个性能分析报告。 CPU Profile：CPU 分析，采样消耗 cpu 的调用，这个一般用来定位排查程序里耗费计算资源的地方 Memory Profile（Heap Profile）：内存分析，一般用来排查内存占用，内存泄露等问题。堆内存分配情况的记录。默认每分配512K字节时取样一次。 Block Profile：阻塞分析，报告导致阻塞的同步原语的情况，可以用来分析和查找锁的性能瓶颈。Goroutine阻塞事件的堆栈跟踪记录。默认每发生一次阻塞事件时取样一次。 Goroutine Profile ：报告goroutines的使用情况，有哪些goroutine，它们的调用关系是怎样的。活跃Goroutine的信息的记录，以及调用关系。仅在获取时取样一次。 Pprof可视化 在Mac上安装graphviz执行以下命令 brew install graphviz 以本地文件形式获取分析结果 先把信息 dump 到本地文件，然后用 go tool 去分析（生产环境通用的方式） 第三方工具：debugcharts 一个可以实时查看go程序内存、CPU、GC、协程等变化情况的可视化工具。启用方式跟pprof类似，都是先import引入，然后开启端口监听即可。 package main import ( _ &quot;github.com/mkevac/debugcharts&quot; &quot;log&quot; &quot;net/http&quot; ) func main() { //... do something log.Println(http.ListenAndServe(&quot;localhost:8090&quot;, nil)) } 然后在浏览器中打开查看： http://127.0.0.1:8090/debug/charts/ 第三方工具：prometheus prometheus是grafana的插件，支持go监控的可视化。 启用方式先引入包： _ &quot;github.com/prometheus/client_golang/prometheus/promhttp&quot; 然后增加路由： //prometheus http.Handle(&quot;/metrics&quot;, promhttp.Handler()) http.ListenAndServe(&quot;:8090&quot;, nil) 最后，通过访问 http://127.0.0.1:8090/metrics 查看采集到的指标数据。 ** 可以通过一个端口同时开启pprof + charts + prometheus ** go tool [xxx] 输入 go tool 查看内置的所有[xxx]工具命令 addr2line api asm buildid cgo compile：代码汇编 cover：生成代码覆盖率 dist doc fix link nm：查看符号表（等同于系统 nm 命令） objdump：反汇编工具，分析二进制文件（等同于系统 objdump 命令） oldlink pack pprof：性能和指标分析工具 test2json trace：采样一段时间，指标跟踪分析工具 vet go tool nm 查看符号表的命令 在断点的时候，如果不知道断点的函数符号，可以用这个命令进行查询（命令处理的是二进制程序文件）。 go tool nm ./main 输出的第一列是地址，第二列是类型，第三列是符号。 115aa00 T bufio.(*ReadWriter).Available 115aa20 T bufio.(*ReadWriter).Discard 115aa60 T bufio.(*ReadWriter).Flush 115aa80 T bufio.(*ReadWriter).Peek go tool compile 汇编某个文件 go tool compile -N -l -S main.go go tool objdump 反汇编二进制的工具 go tool objdump main.o go tool objdump -s DoFunc main.o //反汇编具体函数 go tool pprof 性能指标分析工具 命令行分析模式 go tool pprof http://localhost:8090/debug/pprof/heap?second=10 分析heap，进入命令行模式，输入 web 即可以web方式打开（前提是安装了graphviz）。或者继续输入命令： 在命令行输入top默认查看程序中占用内存前10位的函数 在命令行输入top 3可以查看程序中占用内存前3位的函数 同样，如果采集的是cpu使用top命令可以看占用cpu的函数 输入top后显示的最后一列为函数名称，其他各项内容意义如下： flat：当前函数占用CPU的耗时 flat%：当前函数占用CPU的耗时百分比 sum%：函数占用CPU的累积耗时百分比 cum：当前函数+调用的子函数 占用CPU总耗时 cum%：当前函数+调用的子函数 占用CPU总耗时百分比 可以在命令行输入 list+函数名 命令查看具体的函数分析 可以在命令行输入 pdf 生成可视化的pdf文件 可以在命令行输入 help 提供所有pprof支持的命令说明 web分析模式 go tool pprof -http=:1234 http://localhost:8090/debug/pprof/heap?second=10 会直接以web方式打开。或者： http://localhost:1234/ui/ 也可以直接打开，从中可以直接筛选查看火焰图（Flame Graph）。 -http 表示使用交互式web接口查看获取的性能信息，指定可用的端口即可。 debug/pprof/需要查看的指标（allocs,block,goroutine,heap等） 火焰图从上往下是方法的调用栈，长度代表使用的cpu时长。 其他的一些go tool pprof 分析命令 go tool pprof -http=:1234 http://localhost:8090/debug/pprof/goroutine?second=10 go tool pprof --seconds 10 http://localhost:8090/debug/pprof/goroutine 如果应用比较复杂，生成的调用图特别大，看起来很乱，有两个办法可以优化： 使用 web [funcName] 的方式，只打印和某个函数相关的内容 运行 go tool pprof 命令时加上 --nodefration 参数，可以忽略内存使用较少的函数，比如--nodefration=0.05表示如果调用的子函数使用的 CPU、memory 不超过 5%，就忽略它，不要显示在图片中 go test 单元测试 _test.go 结尾的文件认为是测试文件 本质上，golang 跑单测是先编译 *_test.go 文件，编译成二进制后，再运行这个二进制文件 go test . //直接在本目录中运行go test go test -run=TestPutAndGetKeyValue //指定运行函数 go test -v //提供详细的测试输出，打印测试名称、状态（通过或者失败）、耗时、测试用例的日志等 go test -race //测试时支持对竞争进行检测和报告 go test -coverprofile=c.out &amp;&amp; go tool cover -html=c.out //输出一个覆盖信息结果并可在浏览器上可视化观看 编译生成单元测试可执行文件 // 先编译出 .test 文件 $ go test -c // 指定跑某一个文件 $ ./raftexample.test -test.timeout=10m0s -test.v=true -test.run=TestPutAndGetKeyValue 统计代码覆盖率 加一个 -coverprofile 的参数，声明在跑单测的时候，记录代码覆盖率 go test -coverprofile=coverage.out 使用 go tool cover 命令分析，得出覆盖率报告 go tool cover -func=coverage.out Delve delve 当前是最友好的 golang 调试程序，ide 调试其实也是调用 dlv 而已，比如 goland 安装dlv： go get -u github.com/go-delve/delve/cmd/dlv 检查安装版本信息： dlv version 把程序加载进 Delve 调试器的两种方式（事先需要有go.mod） 加载源码进行调试 dlv debug 执行 dlv debug 进入命令行模式，此时同目录下会自动生成一个 __debug_bin 文件。这个文件是由源码编译生成的，并会自动加载进调试器。 Delve 期望的是从单个程序或项目中构建出单个二进制文件，如果目录中有多个源文件且每个文件都有自己的主函数， Delve 则可能抛出错误。此种情况下应该使用下面第二种方式，加载二进制文件进行调试。 加载二进制文件进行调试 dlv exec ./main 使用 dlv exec 命令将二进制文件加载进调试器。 在命令行模式下输入 help 查看可用命令。 常使用的一些命令： b main.main //在 main 函数处设置断点，等同于 break main.main b func.go:5 //使用 文件名:行号 的格式来设置断点，也可以直接用行号设置断点 bp //查看设置的断点，等同于 breakpoints clear [断点标号如2] //清除单个断点 clearall //清除所有断点 on //设置一段命令，当断点命中的时候 c //继续运行程序，运行到断点处中止，等同于 continue n //单步调试下一行源码，等同于 next。默认情况下，Delve不会更深入地调试函数调用。 s //单步调试下一个函数，等同于 step step-instruction //单步调试某个汇编指令 stack //打印当前堆栈的内容信息，可以看到0、1、2、3...等栈位置的函数 frame 0 //实现帧之间的跳转，可以使用 stack 输出的位置序号 args //打印出命令行传给函数的参数 disassemble //查看编译器生成的汇编语言指令 stepout //跳回到函数被调用的地方 print [var_name] //打印变量的值 whatis [var_name] //打印变量的类型 locals //打印函数内的所有局部变量 regs //打印寄存器的信息 x //等同于examinemem，这个是解析内存用的，和 gdb 的 x 命令一样 set //set赋值 vars //打印全局变量（包变量） whatis //打印类型信息 r //重新启动并调试执行程序，等同于restart call //整个程序执行 quit //退出调试器 协程相关 goroutine (alias: gr) //打印某个特定协程的信息 goroutines (alias: grs) //列举所有的协程 goroutines -t //展开所有协程详细信息 thread (alias: tr) //切换到某个线程 threads //打印所有的线程信息 栈相关 deferred //在 defer 函数上下文里执行命令 down //上堆栈 frame //跳到某个具体的堆栈 stack (alias: bt) //打印堆栈信息 up //下堆栈 其他命令 config //配置变更 disassemble (alias: disass) //反汇编 funcs //打印所有函数符号 libraries //打印所有加载的动态库 list (alias: ls | l) //显示源码 source //加载命令 sources //打印源码 types //打印所有类型信息 dlv的其它命令 dlv debug：使用dlv debug可以在main函数文件所在目录直接对main函数进行调试，也可以在根目录以指定包路径的方式对main函数进行调试 dlv exec：使用dlv exec可以对编译好的二进制进行调试 dlv test：使用dlv test可以对test包进行调试 dlv attach：使用dlv attach可以附加到一个已在运行的进程进行调试 dlv connect：使用dlv connect可以连接到调试服务器进行调试 dlv trace：使用dlv trace可以追踪程序 go race Go 语言提供了 race 检测（Go race detector）来进行竞争分析和发现 go run -race main.go 是运行时检测，并不是编译时。且使用 race 时存在明显的性能开销，因此不要在生产环境中使用这个。 GDB gdb当前只支持6个命令 3个 cmd 命令 info goroutines //打印所有的goroutines goroutine ${id} bt //打印一个goroutine的堆栈 iface //打印静态或者动态的接口类型 3个函数 len //打印string，slices，map，channels 这四种类型的长度 cap //打印slices，channels 这两种类型的cap dtype //强制转换接口到动态类型。 gdb 有一个功能是无法替代的，就是 gcore 的功能 GOGC 环境变量 Go垃圾回收提供了一个参数GOGC。 GOGC代表了占用中的内存增长比率，达到该比率时应当触发1次GC，该参数可以通过环境变量进行设置。。 GOGC参数取值范围为0~100，其默认值是100，单位是百分比。 假如当前heap占用内存为4MB，GOGC = 75，则 4*(1+75%)=7MB，即heap占用内存大小达到7MB时会触发1轮GC。 GOGC还有2个特殊值： “off” : 代表关闭GC 0 : 代表持续进行垃圾回收，只用于调试。 runtime.MemStats 通过runtime.MemStats可以实时的获取 Go 运行时的内存统计信息，这个数据结构包含很多的字段。 type MemStats struct { // 已分配的对象的字节数. // // 和HeapAlloc相同. Alloc uint64 // 分配的字节数累积之和. // // 所以对象释放的时候这个值不会减少. TotalAlloc uint64 // 从操作系统获得的内存总数. // // Sys是下面的XXXSys字段的数值的和, 是为堆、栈、其它内部数据保留的虚拟内存空间. // 注意虚拟内存空间和物理内存的区别. Sys uint64 // 运行时地址查找的次数，主要用在运行时内部调试上. Lookups uint64 // 堆对象分配的次数累积和. // 活动对象的数量等于`Mallocs - Frees`. Mallocs uint64 // 释放的对象数. Frees uint64 // 分配的堆对象的字节数. // // 包括所有可访问的对象以及还未被垃圾回收的不可访问的对象. // 所以这个值是变化的，分配对象时会增加，垃圾回收对象时会减少. HeapAlloc uint64 // 从操作系统获得的堆内存大小. // // 虚拟内存空间为堆保留的大小，包括还没有被使用的. // HeapSys 可被估算为堆已有的最大尺寸. HeapSys uint64 // HeapIdle是idle(未被使用的) span中的字节数. // // Idle span是指没有任何对象的span,这些span **可以**返还给操作系统，或者它们可以被重用, // 或者它们可以用做栈内存. // // HeapIdle 减去 HeapReleased 的值可以当作&quot;可以返回到操作系统但由运行时保留的内存量&quot;. // 以便在不向操作系统请求更多内存的情况下增加堆，也就是运行时的&quot;小金库&quot;. // // 如果这个差值明显比堆的大小大很多，说明最近在活动堆的上有一次尖峰. HeapIdle uint64 // 正在使用的span的字节大小. // // 正在使用的span是值它至少包含一个对象在其中. // HeapInuse 减去 HeapAlloc的值是为特殊大小保留的内存，但是当前还没有被使用. HeapInuse uint64 // HeapReleased 是返还给操作系统的物理内存的字节数. // // 它统计了从idle span中返还给操作系统，没有被重新获取的内存大小. HeapReleased uint64 // HeapObjects 实时统计的分配的堆对象的数量,类似HeapAlloc. HeapObjects uint64 // 栈span使用的字节数。 // 正在使用的栈span是指至少有一个栈在其中. // // 注意并没有idle的栈span,因为未使用的栈span会被返还给堆(HeapIdle). StackInuse uint64 // 从操作系统取得的栈内存大小. // 等于StackInuse 再加上为操作系统线程栈获得的内存. StackSys uint64 // 分配的mspan数据结构的字节数. MSpanInuse uint64 // 从操作系统为mspan获取的内存字节数. MSpanSys uint64 // 分配的mcache数据结构的字节数. MCacheInuse uint64 // 从操作系统为mcache获取的内存字节数. MCacheSys uint64 // 在profiling bucket hash tables中的内存字节数. BuckHashSys uint64 // 垃圾回收元数据使用的内存字节数. GCSys uint64 // Go 1.2 // off-heap的杂项内存字节数. OtherSys uint64 // Go 1.2 // 下一次垃圾回收的目标大小，保证 HeapAlloc ≤ NextGC. // 基于当前可访问的数据和GOGC的值计算而得. NextGC uint64 // 上一次垃圾回收的时间. LastGC uint64 // 自程序开始 STW 暂停的累积纳秒数. // STW的时候除了垃圾回收器之外所有的goroutine都会暂停. PauseTotalNs uint64 // 一个循环buffer，用来记录最近的256个GC STW的暂停时间. PauseNs [256]uint64 // 最近256个GC暂停截止的时间. PauseEnd [256]uint64 // Go 1.4 // GC的总次数. NumGC uint32 // 强制GC的次数. NumForcedGC uint32 // Go 1.8 // 自程序启动后由GC占用的CPU可用时间，数值在 0 到 1 之间. // 0代表GC没有消耗程序的CPU. GOMAXPROCS * 程序运行时间等于程序的CPU可用时间. GCCPUFraction float64 // Go 1.5 // 是否允许GC. EnableGC bool // 未使用. DebugGC bool // 按照大小进行的内存分配的统计,具体可以看Go内存分配的文章介绍. BySize [61]struct { // Size is the maximum byte size of an object in this // size class. Size uint32 // Mallocs is the cumulative count of heap objects // allocated in this size class. The cumulative bytes // of allocation is Size*Mallocs. The number of live // objects in this size class is Mallocs - Frees. Mallocs uint64 // Frees is the cumulative count of heap objects freed // in this size class. Frees uint64 } } runtime.SetGCPercent 可以通过设置runtime.SetGCPercent参数来调整GOGC垃圾回收的目标百分比。 当这次新分配的数据和上一次垃圾回收后存活数据之比达到这个数值之后就会触发一次垃圾回收。 GOGC的默认值是 100。设置GOGC=off会禁止垃圾回收。 ","link":"https://ninglg.com/post/golang-program-performance-analysis-tools/"},{"title":"Go并发编程实践","content":"此篇介绍一下Go语言的并发编程的一些相关知识。 常用概念 函数 作用 Goexit 退出当前执行的 goroutine，但是 defer 函数还会继续调用 Gosched 让出当前 goroutine 的执行权限，调度器安排其他等待的任务运行，并在下次某个时候从该位置恢复执行 NumCPU 返回 CPU 核数量 NumGoroutine 返回正在执行和排队的任务总数 GOMAXPROCS 用来设置可以运行的 CPU 核数，GOMAXPROCS的最大值是256 runtime.GOMAXPROCS(0) 核数的2倍 goroutine 在程序启动时，Go程序就会为main()函数创建一个默认的goroutine。在 Go 语言里只有一个主协程，其它都是它的子协程，子协程之间是平行关系。 主协程运行结束，其它协程就会立即消亡，不管它们是否已经开始运行。 在使用子协程时一定要注意保护好每个子协程，确保它们正常安全的运行。因为子协程的异常退出会将异常传播到主协程，直接会导致主协程也跟着挂掉，然后整个程序就崩溃了。 子协程崩溃时，主协程里剩余的语句没能运行就挂掉了，主协程在异常退出时会打印堆栈信息。从堆栈信息中可以了解到是哪行代码引发了程序崩溃。 为了保护子协程的安全，通常会在子协程的入口开头处增加 recover() 语句来恢复子协程内部发生的异常，阻断它传播到主协程导致程序崩溃。 go func() { defer func() { if err := recover(); err != nil { fmt.Println(&quot;recover success.&quot;) debug.PrintStack() } }() // do something } OS线程（操作系统线程）一般都有固定的栈内存（通常为2MB）,一个goroutine的栈在其生命周期开始时只有很小的栈（典型情况下2KB），goroutine的栈不是固定的，可以按需增大和缩小，goroutine的栈大小限制可以达到1GB，虽然极少会用到这个大。 在Go语言中一次创建十万左右的goroutine也是可以的。Go语言单机管理百万级的协程也可以。 一个goroutine必定对应一个函数，可以创建多个goroutine去执行相同的函数。 一个进程内部可以运行多个线程，而每个线程又可以运行很多协程。线程要负责对协程进行调度，保证每个协程都有机会得到执行。当一个协程睡眠时，它要将线程的运行权让给其它的协程来运行，而不能持续霸占这个线程。同一个线程内部最多只会有一个协程正在运行。 线程的调度是由操作系统负责的，调度算法运行在内核态，而协程的调用是由 Go 语言的运行时负责的，调度算法运行在用户态。 协程可以简化为三个状态，运行态、就绪态和休眠态。同一个线程中最多只会存在一个处于运行态的协程，就绪态的协程是指那些具备了运行能力但是还没有得到运行机会的协程，它们随时会被调度到运行态，休眠态的协程还不具备运行能力，它们是在等待某些条件的发生，比如 IO 操作的完成、睡眠时间的结束等。 操作系统对线程的调度是抢占式的，也就是说单个线程的死循环不会影响其它线程的执行，每个线程的连续运行受到时间片的限制。 Go 语言运行时对协程的调度并不是抢占式的。如果单个协程通过死循环霸占了线程的执行权，那这个线程就没有机会去运行其它协程了，你可以说这个线程假死了。不过一个进程内部往往有多个线程，假死了一个线程没事，全部假死了才会导致整个进程卡死。 每个线程都会包含多个就绪态的协程形成了一个就绪队列，如果这个线程因为某个别协程死循环导致假死，那这个队列上所有的就绪态协程是不是就没有机会得到运行了呢？Go 语言运行时调度器采用了 work-stealing 算法，当某个线程空闲时，也就是该线程上所有的协程都在休眠（或者一个协程都没有），它就会去其它线程的就绪队列上去偷一些协程来运行。也就是说这些线程会主动找活干，在正常情况下，运行时会尽量平均分配工作任务。 默认情况下，Go 运行时会将线程数会被设置为机器 CPU 逻辑核心数。同时它内置的 runtime 包提供了 GOMAXPROCS(n int) 函数允许用户动态调整线程数，注意这个函数名字是全大写，该函数会返回修改前的线程数，如果参数 n &lt;=0 ，就不会产生修改效果，等价于读操作。 // 读取默认的 线程数 fmt.Println(runtime.GOMAXPROCS(0)) // 设置 线程数 为 10 runtime.GOMAXPROCS(10) // 读取当前的 线程数 fmt.Println(runtime.GOMAXPROCS(0)) 获取当前的 协程 数量可以使用 runtime 包提供的 NumGoroutine() 方法。 goroutine和OS线程是多对多的关系，即m:n。 在 HTTP API 应用中，每一个 HTTP 请求，服务器都会单独开辟一个协程来处理。在这个请求处理过程中，要进行很多 IO 调用，比如访问数据库、访问缓存、调用外部系统等，协程会休眠，IO 处理完成后协程又会再次被调度运行。待请求的响应回复完毕后，链接断开，这个协程的寿命也就到此结束。 在消息推送系统中，客户端的链接寿命很长，大部分时间这个链接都是空闲状态，客户端会每隔几十秒周期性使用心跳来告知服务器你不要断开我。在服务器端，每一个来自客户端链接的维持都需要单独一个协程。因为消息推送系统维持的链接普遍很闲，单台服务器往往可以轻松撑起百万链接，这些维持链接的协程只有在推送消息或者心跳消息到来时才会变成就绪态被调度运行。 聊天系统也是长链接系统，它内部来往的消息要比消息推送系统频繁很多，限于 CPU 和 网卡的压力，它能撑住的连接数要比推送系统少很多。不过原理是类似的，都是一个链接由一个协程长期维持，连接断开协程也就消亡。 channel Go语言提供了channel在多个goroutine间进行通信。channel是可以让一个goroutine发送特定值到另一个goroutine的通信机制。 goroutine和channel是 Go 语言秉承的 CSP（Communicating Sequential Process）并发模式的重要实现基础。 单纯地将函数并发执行是没有意义的。函数与函数间需要交换数据才能体现并发执行函数的意义。 虽然可以使用共享内存进行数据交换，但是共享内存在不同的goroutine中容易发生竞态问题。为了保证数据交换的正确性，必须使用互斥量对内存进行加锁，这种做法势必造成性能问题。 channel是引用类型，channel类型的空值是nil。 声明的channel在使用make函数进行初始化之后才能使用。 channel有发送（send）、接收(receive）和关闭（close）三种操作。 只有在通知接收方goroutine所有的数据都发送完毕的时候才需要关闭通道。 channel是可以被垃圾回收机制回收的，它和关闭文件不一样，在结束操作之后关闭文件是必须要做的，但关闭channel不是必须的。 对一个关闭的通道再发送值就会导致panic。试图关闭一个已经关闭的通道也会导致宕机，就像关闭一个空通道一样。对一个关闭的通道进行接收会一直获取值直到通道为空。对一个关闭的并且没有值的通道执行接收操作会得到对应类型的零值。 关闭通道还可以作为一个广播机制。 无缓冲通道 无缓冲的通道属于一种阻塞的通道。 使用无缓冲通道进行通信将导致发送和接收的goroutine同步化。因此，无缓冲通道也被称为同步通道。 有缓冲的通道 只要通道的容量大于零，那么该通道就是有缓冲的通道，通道的容量表示通道中能存放元素的数量。 可以使用内置的len函数获取通道内元素的数量，使用cap函数获取通道的容量，虽然很少会这么做。 优雅的从通道循环取值 当通过通道发送有限的数据时，我们可以通过close函数关闭通道来告知从该通道接收值的goroutine停止等待。当通道被关闭时，往该通道发送值会引发panic，从该通道里接收的值一直都是类型零值。 有2种方式在接收值的时候判断通道是否被关闭：ok语法以及for range方式。最通常使用的是for range的方式。 单向通道 chan&lt;- int 是“只写通道”，只可以往里写入数据的通道。 &lt;-chan int 是“只读通道”，只可以从中读取数据的通道。 事实上 channel 只读或只写都没有意义，所谓的单向 channel 其实只是声明时用，用于在函数内防止滥用。 在函数传参及任何赋值操作中将双向通道转换为单向通道是可以的，但反过来是不可以的。 goroutine池（worker pool） 在实际工作中通常会使用可以指定启动的goroutine数量的——worker pool模式，来控制goroutine的数量，防止goroutine泄漏和暴涨。 package main import ( &quot;fmt&quot; &quot;time&quot; ) func worker(id int, jobs &lt;-chan int, results chan&lt;- int) { for j := range jobs { fmt.Printf(&quot;worker: %d start job: %d\\n&quot;, id, j) time.Sleep(time.Second) fmt.Printf(&quot;worker: %d end job: %d\\n&quot;, id, j) results &lt;- j * 2 } } func main() { jobs := make(chan int, 100) results := make(chan int, 100) //开启3个goroutine for w := 1; w &lt;= 3; w++ { go worker(w, jobs, results) } // 5个任务 for j := 1; j &lt;= 5; j++ { jobs &lt;- j } close(jobs) // 输出结果 for a := 1; a &lt;= 5; a++ { &lt;-results } } 输出： worker: 3 start job: 1 worker: 1 start job: 2 worker: 2 start job: 3 worker: 3 end job: 1 worker: 3 start job: 4 worker: 1 end job: 2 worker: 2 end job: 3 worker: 2 start job: 5 worker: 2 end job: 5 worker: 3 end job: 4 select多路复用 select可处理一个或多个channel的发送/接收操作。 如果多个case同时满足，select会随机选择一个。 对于没有case的select{}会一直等待，可用于阻塞main函数。 并发安全和锁 有时候在Go代码中可能会存在多个goroutine同时操作一个资源（临界区），这种情况就会导致竞态问题（数据竞态）。 互斥锁（sync.Mutex） Go语言中使用sync包的Mutex类型来实现互斥锁。 使用互斥锁能够保证同一时间有且只有一个goroutine进入临界区，其他的goroutine则在等待锁。 当互斥锁释放后，等待的goroutine才可以获取锁进入临界区，多个goroutine同时等待一个锁时，唤醒的策略是随机的。 读写锁（sync.RWMutex） 互斥锁是完全互斥的，但是有很多实际的场景下是读多写少的，当我们并发的去读取一个资源不涉及资源修改的时候是没有必要加锁的，这种场景下使用读写锁是更好的一种选择。 读写锁在Go语言中使用sync包中的RWMutex类型。 读写锁分为两种：读锁和写锁。当一个goroutine获取读锁之后，其他的goroutine如果是获取读锁会继续获得锁，如果是获取写锁就会等待；当一个goroutine获取写锁之后，其他的goroutine无论是获取读锁还是写锁都会等待。 读写锁非常适合读多写少的场景，如果读和写的操作差别不大，读写锁的优势就发挥不出来。 Lock写锁定，Unlock写解锁，RLock读锁定，RUnlock读解锁。 sync.WaitGroup 在代码中生硬的使用time.Sleep肯定是不合适的，Go语言中可以使用sync.WaitGroup来实现并发任务的同步。 sync.WaitGroup内部维护着一个计数器，计数器的值可以增加和减少。通过调用Wait()来等待并发任务执行完，当计数器值为0时，表示所有并发任务已经完成。 需要注意sync.WaitGroup是一个结构体，传递的时候要传递指针。 sync.Once 在编程的很多场景下需要确保某些操作在高并发的场景下只执行一次，例如只加载一次配置文件、只关闭一次通道等。 Go语言中的sync包中提供了一个针对只执行一次场景的解决方案：sync.Once。 sync.Once只有一个Do方法。 var loadConfig sync.Once func loadConfigFile() { // do load config file } loadConfig.Do(loadConfigFile) sync.Once其实内部包含一个互斥锁和一个布尔值，互斥锁保证布尔值和数据的安全，而布尔值用来记录初始化是否完成。这样设计就能保证初始化操作的时候是并发安全的并且初始化操作也不会被执行多次。 sync.Map Go语言中内置的map不是并发安全的。 Go语言的sync包中提供了一个开箱即用的并发安全版map——sync.Map。开箱即用表示不用像内置的map一样使用make函数初始化就能直接使用，同时sync.Map内置了诸如Store、Load、LoadOrStore、Delete、Range等操作方法。 原子操作 代码中的加锁操作因为涉及内核态的上下文切换会比较耗时、代价比较高。针对基本数据类型其实可以使用原子操作来保证并发安全，因为原子操作是Go语言提供的方法，它在用户态就可以完成，因此性能比加锁操作更好。 Go语言中原子操作由内置的标准库sync/atomic提供。 atomic包 atomic包提供了底层的原子级内存操作，对于同步算法的实现很有用。这些函数必须谨慎地保证正确使用。除了某些特殊的底层应用，使用通道或者sync包的函数/类型实现同步更好。 package main import ( &quot;fmt&quot; &quot;sync&quot; &quot;sync/atomic&quot; &quot;time&quot; ) type Counter interface { Inc() Load() int64 } // 普通版 type CommonCounter struct { counter int64 } func (c CommonCounter) Inc() { c.counter++ } func (c CommonCounter) Load() int64 { return c.counter } // 互斥锁版 type MutexCounter struct { counter int64 lock sync.Mutex } func (m *MutexCounter) Inc() { m.lock.Lock() defer m.lock.Unlock() m.counter++ } func (m *MutexCounter) Load() int64 { m.lock.Lock() defer m.lock.Unlock() return m.counter } // 原子操作版 type AtomicCounter struct { counter int64 } func (a *AtomicCounter) Inc() { atomic.AddInt64(&amp;a.counter, 1) } func (a *AtomicCounter) Load() int64 { return atomic.LoadInt64(&amp;a.counter) } func test(c Counter) { var wg sync.WaitGroup start := time.Now() for i := 0; i &lt; 1000; i++ { wg.Add(1) go func() { c.Inc() wg.Done() }() } wg.Wait() end := time.Now() fmt.Println(c.Load(), end.Sub(start)) } func main() { c1 := CommonCounter{} // 非并发安全 test(c1) c2 := MutexCounter{} // 使用互斥锁实现并发安全 test(&amp;c2) c3 := AtomicCounter{} // 并发安全且比互斥锁效率更高 test(&amp;c3) } 调度器运行时机 调度器会在GC、&quot;go&quot;声明、阻塞channel操作、阻塞系统调用和lock操作后运行。它也会在非内联函数调用后执行。 要想知道在for循环中调用的函数是否是内联的，可以在&quot;go build&quot;或&quot;go run&quot;时传入&quot;-m&quot; gc标识（如go build -gcflags -m）。 可以显式的唤起调度器，比如使用&quot;runtime&quot;包中的Gosched()函数。 ","link":"https://ninglg.com/post/golang-concurrent-programming-practices/"},{"title":"跨域问题","content":"介绍一下跨域相关的内容。 同源策略（same-origin policy） 浏览器有一种同源策略，是一种安全机制。 同源：域名、协议、端口三者都相同则为同源，否则认为是跨域。 （1）同一个域名下的不同uri，同源。 （2）http和https，不同源。 （3）端口号不同，不同源。 （4）域名和其ip，不同源。 （5）不同二级子域（如www和其它），不同源。 （6）不同域名，不同源。 简单来讲，同源策略就是浏览器为了保证用户信息的安全，防止恶意的网站窃取数据，禁止不同域之间的JS进行交互。 解决跨域问题的方式 跨域资源共享（CORS） CROS，全称是跨域资源共享 (Cross-origin resource sharing)，它的提出就是为了解决跨域请求的。 可以从nginx层进行支持跨域配置 location / { add_header Access-Control-Allow-Origin *; add_header Access-Control-Allow-Methods 'GET, POST, OPTIONS'; add_header Access-Control-Allow-Headers 'DNT,X-Mx-ReqToken,Keep-Alive,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Authorization'; if ($request_method = 'OPTIONS') { return 204; } } 预检请求（preflight request） 跨域资源共享(CORS)标准新增了一组 HTTP 首部字段，允许服务器声明哪些源站有权限访问哪些资源。另外，规范要求，对那些可能对服务器数据产生副作用的HTTP 请求方法（特别是 GET 以外的 HTTP 请求，或者搭配某些 MIME 类型的 POST 请求），浏览器必须首先使用 OPTIONS 方法发起一个预检请求（preflight request），从而获知服务端是否允许该跨域请求。服务器确认允许之后，才发起实际的 HTTP 请求。在预检请求的返回中，服务器端也可以通知客户端，是否需要携带身份凭证（包括 Cookies 和 HTTP 认证相关数据）。 Content-Type不属于以下MIME类型的，都属于预检请求： application/x-www-form-urlencodedmultipart/form-datatext/plain application/json的请求会在正式通信之前，增加一次&quot;预检&quot;请求，这次&quot;预检&quot;请求会带上头部信息 Access-Control-Request-Headers中的字段。 服务器回应时，返回的头部信息如果不包含Access-Control-Allow-Headers字段则表示不接受非默认的字段信息。 Go语言的Gin框架跨域中间件 package middlewares import ( &quot;github.com/gin-gonic/gin&quot; ) // 处理跨域请求,支持options访问 func Cors() gin.HandlerFunc { return func(c *gin.Context) { method := c.Request.Method c.Header(&quot;Content-Type&quot;, &quot;text/html;charset=utf-8&quot;) c.Header(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;) c.Header(&quot;Access-Control-Allow-Methods&quot;, &quot;POST,GET,OPTIONS,DELETE&quot;) c.Header(&quot;Access-Control-Expose-Headers&quot;, &quot;Content-Length, Access-Control-Allow-Origin, Access-Control-Allow-Headers, Content-Type&quot;) c.Header(&quot;Access-Control-Allow-Credentials&quot;, &quot;true&quot;) c.Header(&quot;Access-Control-Allow-Headers&quot;, &quot;Content-Type,Content-Length,Accept-Encoding,X-Requested-with, Origin&quot;) // 设置允许自定义请求头的字段 //放行所有OPTIONS方法 if method == &quot;OPTIONS&quot; { c.JSON(200, gin.H{}) c.Abort() } // 处理请求 c.Next() } } 然后在main函数中，注册中间件： // 加载自定义中间件 r.Use(middlewares.Cors()) //允许跨域 ","link":"https://ninglg.com/post/cross-origin-problem/"},{"title":"goroutine的并发控制channel/waitgroup/context","content":"介绍一下goroutine并发控制与通信的相关内容。 背景 一般来说，多个goroutine之间经常是需要同步与通信的。 目前实现多个goroutine间同步与通信的方式（控制并发的方式）大致有： 1. 全局共享变量 2. channel通信（CSP模型） 3. Context包 goroutine退出机制 当前goroutine的退出机制设计是：goroutine退出只能由本身控制，不允许从外部强制结束。 只有两种情况例外，那就是main函数结束或者程序崩溃结束运行。 所以要实现主进程控制子goroutine的开始和结束，必须借助其它工具来实现。 全局共享变量 此方式最简单，其实现步骤是： 1. 声明一个全局变量。 2. 所有子goroutine共享这个变量，并不断轮询这个变量检查是否有更新。 3. 在主进程中更新此全局变量。 4. 子goroutine检测到全局变量更新，然后执行相应的逻辑。 此方式的特点： 1. 优点：简单方便，通过一个变量就可以控制所有子 goroutine 的开始和结束。 2. 缺点：功能有限，不适合用于子 goroutine 间的通信，因为全局变量可以传递的信息很小。 3. 缺点：主进程无法等待所有子 goroutine 退出，因为这种方式只能是单向通知，只适用于非常简单的逻辑且并发量不太大的场景。 协程池 在日常大部分场景下，不需要使用协程池。因为Goroutine非常轻量，默认2kb，使用go func()很难成为性能瓶颈。当然一些极端情况下需要追求性能，可以使用协程池实现资源的复用，例如FastHttp使用协程池性能提高许多。 channel channel的线程安全 Channel是Go中的一个核心类型，可以把它看成一个管道，通过它并发核心单元就可以发送或者接收数据进行通信。 Channel也可以理解成是一个先进先出的队列，通过管道进行通信。 Go中发送一个数据到Channel和从Channel接收一个数据都是原子性的。 Go的设计思想就是：不要通过共享内存来通信，而是通过通信来共享内存。前者就是传统的加锁，后者就是Channel。 设计Channel的主要目的就是在多任务间传递数据的，当然要保证安全。 CSP CSP 是 Communicating Sequential Process 的简称，中文叫做通信顺序进程，是一种并发编程模型。 CSP 模型的关键是关注 channel，而不关注发送消息的实体。 Go 语言实现了 CSP 部分理论，goroutine 对应 CSP 中并发执行的实体，channel 也就对应着 CSP 中的 channel。 CSP 描述这样一种并发模型：多个 Process 使用一个 Channel 进行通信， 这个 Channel 连结的 Process 通常是匿名的，消息传递通常是同步的（有别于 Actor Model）。 waitgroup 借助标准库 sync 里的 Waitgroup，可以实现优雅等待所有子 goroutine 完全结束之后主进程才结束退出。这是一种控制并发的方式，可以实现对多 goroutine 的等待。 1. 创建一个 Waitgroup 的实例 wg。 2. 在每个 goroutine 启动的时候，调用 wg.Add(1) 进行注册。 3. 在每个 goroutine 完成任务后退出之前，调用 wg.Done() 进行注销。 4. 在等待所有 goroutine 的地方调用 wg.Wait() 阻塞进程，直到所有 goroutine 都完成任务调用，然后Wait()方法会返回。 Context Context上下文 1. 每个 Goroutine 在执行之前，都要先知道程序当前的执行状态，通常将这些执行状态封装在一个 Context 变量中，传递给要执行的 Goroutine。 2. 上下文几乎已经成为传递与请求同生存周期变量的标准方法。 3. 在网络编程下，当接收到一个网络请求 Request，在处理这个 Request 的 goroutine 中，可能需要在当前 gorutine 继续开启多个新的 Goroutine 来获取数据与逻辑处理（例如访问数据库、RPC 服务等）。即一个请求 Request，会需要多个 Goroutine 进行处理，这些 Goroutine 可能需要共享 Request 的一些信息。同时当 Request 被取消或者超时的时候，所有从这个 Request 创建的所有 Goroutine 也应该被结束。 Context的链式调用 可以使用 context.Background 方法来生成Context根节点，而后可以进行链式调用使用 context 包里的各类方法： func Background() Context func TODO() Context func WithCancel(parent Context) (ctx Context, cancel CancelFunc) func WithDeadline(parent Context, deadline time.Time) (Context, CancelFunc) func WithTimeout(parent Context, timeout time.Duration) (Context, CancelFunc) func WithValue(parent Context, key, val interface{}) Context Context使用规范 不要把 Context 放入一个结构体当中，而应该显式地传入函数。Context 变量需要作为第一个参数使用，一般命名为 ctx。 即使方法允许，也不要传入一个 nil 的 Context，如果你不确定你要用什么 Context 的时候传一个 context.TODO()。 使用 context 的 Value 相关方法只应该用于在程序和接口中传递的和请求相关的元数据，不要用它来传递一些可选的参数。 同样的 Context 可以用来传递到不同的 goroutine 中，Context 在多个 goroutine 中是并发安全的。 在context包内部已经实现好了两个空的Context，可以通过调用Background()和TODO()方法获取。一般是将它们作为Context的根，往下派生。 并发编程模型 在并发编程的模型选择上，有两个流派，一个是共享内存模型，一个是消息传递模型。 并发控制 控制并发有三种经典的方式： 通过channel通知进行并发控制 通过WaitGroup进行并发控制 通过Context进行并发控制 ","link":"https://ninglg.com/post/goroutine-concurrency-control/"},{"title":"延迟队列的实现","content":"介绍一下延迟队列的使用场景和简单实现。 使用场景 延迟队列在实际业务中有很多的使用场景：比如用户注册一定时间后，推送活动消息；订单下单一段时间后未付款，自动取消订单等。 和定时任务的区别 定时任务执行的周期是固定的，时间可以提前预知。延迟队列是当某个事件发生以后再延迟多久触发一定的操作，事件发生的时间不是固定的。 实现方式 Redis Zset实现 使用timestamp作为任务的score，每秒轮询score大于当前时间的key进行执行即可。 缺点是zset无法支持特别大的数据量。 RabbitMQ队列实现 RabbitMQ有两个特性，一个是Time-To-Live Extensions，另一个是Dead Letter Exchanges。 Time-To-Live Extensions允许我们为消息或者队列设置TTL（Time To Live），也就是过期时间，单位为毫秒。消息过期后成为Dead Letter。如果既配置了消息的TTL，又配置了队列的TTL，那么较小的那个值会生效。 Dead Letter Exchanges在RabbitMQ中，一共有三种消息的 “死亡” 形式： 消息被拒绝 消息因为设置了TTL而过期 队列达到最大长度 DLX同一般的 Exchange 没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性。当队列中有 DLX 消息时，RabbitMQ就会自动的将 DLX 消息重新发布到设置的 Exchange 中去，进而被路由到另一个队列，publish 可以监听这个队列中消息做相应的处理。 RabbitMQ本身是不支持延迟队列的，但利用它的特性组合起来可以变相的实现延迟队列的功能。 缺点是绑定了RabbitMQ，如果要替换MQ比较麻烦。 另一个缺点是配置麻烦，需要额外增加一个死信交换和一个死信队列的配置。 时间轮实现 时间轮是一个环形结构，可以想象成时钟，分为很多格子，一个格子代表一段时间（越短Timer精度越高），并用一个List保存在该格子上到期的所有任务。 同时一个指针随着时间流逝一格一格转动，并执行对应List中所有到期的任务。 ","link":"https://ninglg.com/post/delay-queue-intro/"},{"title":"登陆系统设计：账户、手机号、三方登陆","content":"此篇介绍一下登陆系统的概要设计。 ","link":"https://ninglg.com/post/login-system-design-account-phone-third-party/"},{"title":"一致性哈希算法","content":"介绍一下有关一致性哈希算法相关的知识。 ","link":"https://ninglg.com/post/consistent-hashing/"},{"title":"如何设计一个IM系统","content":"此篇介绍一下如何设计一个简单的IM系统。 websocket WebSocket协议是基于TCP的一种新的网络协议，它实现了浏览器与服务器全双工（full-duplex）通信——允许服务器主动发送信息给客户端。 虽然 WebSocket 握手用的是 http 请求，但是请求头和响应头里面都有特殊字段，当浏览器或者服务端收到后会做相应的协议转换，所以 http 请求的长连接和 WebSocket 的连接是有本质区别的。 WebSocket 支持双向通信，实时性更强；有更好的二进制支持；较少的控制开销；支持扩展协议或实现自定义的子协议。 建立和维持连接 使用Go开发 ","link":"https://ninglg.com/post/instant-message-system-design/"},{"title":"Git版本管理命令","content":"此篇介绍一下Git版本管理相关的命令。 操作 命令 删除远程分支 git push origin --delete branchName 创建新分支 git checkout -b dev 推送新分支到远程 git push origin dev 在master上合并dev分支的代码 git merge dev 新建tag git tag -a v2.1 -m &quot;add v2.1 tag&quot; 将新tag推送到远程 git push origin v2.1 将所有tag推送到远程 git push origin --tags 比较两个分支的修改差异 git diff branchA branchB（显示文件内容差异） 或者 git diff branchA branchB --stat（显示有差异的文件列表） 如何回退已经提交到远程的代码版本 首先，使用 git reflog 查看所有提交的commit记录，确认自己想要回退到哪一个版本的id 2. 使用 git reset --soft xxxxx // 版本回退，原来的修改仍在本地，等待继续修改或提交 或者 git reset --hard xxxxx // 版本和原来的修改都回退到以前 进行版本回退 提交到远程 git push --force ","link":"https://ninglg.com/post/git-version-control-command/"},{"title":"什么是IaaS、PaaS、SaaS","content":"此篇介绍一下三个概念：IaaS、PaaS、SaaS。 历史上传统的业务需要你自底向上考虑每一块细节，当今流行的云计算服务简化了这种模式。 按照服务类型，云计算被分为IaaS、PaaS、SaaS三种： IaaS Infrastructure as a Service，基础设施即服务 比如提供了服务器等基础环境，那么这就是IaaS模式。 PaaS Platform as a Service，平台即服务 如果除了服务器，还提供各种平台软件进行服务管理，那么这就是PaaS模式。 SaaS Software as a Service，软件即服务 如果除了服务器和平台软件之外，还直接提供了比如电商/论坛/社区等等直接应用型的软件，使得你的业务可以立即投入运营，那么这就是SaaS模式。 如图所示： 补充 BaaS：Backend as a Service（后端即服务） 服务商为客户(开发者)提供整合云后端的服务，如提供文件存储、数据存储、推送服务、身份验证服务等功能，以帮助开发者快速开发应用。 FaaS：Function as a service（函数即服务） 无服务器计算，当前使用最广泛的是AWS的Lambada。 ","link":"https://ninglg.com/post/what-is-iaas-paas-saas/"},{"title":"PHP7的升级","content":"此篇介绍一下PHP7的一些特性改变及性能升级。 新增 1. 空接合操作符 2. 结合比较运算符 3. 函数的返回类型声明，bool，int，string和float 4. 标量类型声明 5. 匿名类 6. 错误处理和64位支持 性能 PHP7性能是PHP5的两倍。主要优化点在于： 1. 变量存储字节减小，减少内存占用，提升变量操作速度 2. 改善数组结构，数组元素和hash映射表被分配在同一块内存里，降低了内存占用、提升了 cpu 缓存命中率 3. 改进了函数的调用机制，通过优化参数传递的环节，减少了一些指令，提高执行效率 ","link":"https://ninglg.com/post/php7-upgrade/"},{"title":"三十而立","content":"仍然充满好奇。 关注财务健康 关注身体健康 避免浪费时间在不合适的事和人身上 善待在乎的人，多花时间在家人身上 专注于几件事情 不要害怕风险，大胆做出选择 必须继续成长，让自己变得更好 习惯孤独 善待自己，尊重自己 不要拖延 ","link":"https://ninglg.com/post/thirty-years-old/"},{"title":"Elasticsearch使用介绍","content":"此篇介绍一下Elasticsearch的使用场景及常见方法。 ES简介 Elasticsearch是一个基于Lucene的分布式搜索和分析引擎，它使用RESTful web接口提供服务。 概念 Lucene 简单说就是一个jar包，里面封装了各种建立倒排索引，以及进行搜索的算法代码，引入lucene.jar即可使用。 索引（Index） 索引是具有相似特征的文档的集合。 索引由名称标识（必须全部为小写，不能以下划线开头，不能包含逗号）。 在一个Elasticsearch集群中，可以定义任意数量的索引。 如果业务端对查询性能要求很高的话，还是建议使用单索引，也就是宽表化处理的方式，这样也可以比较好的应对聚合的需求。 类型（Type） 在Elasticsearch 6.0.0 或更高版本中创建的索引只能包含一个映射类型。 类型将在Elasticsearch 7.0.0的API中弃用，并在8.0.0中完全删除。 从Elasticsearch 6.x开始，只能一个Type对应一个Index。 文档（Document） 文档是可以建立索引的基本信息单位，以json表示。 可以把文档理解为MySQL表中的行级数据。 在索引（Index）中可以存储大量文档。 文档中有几个不可或缺的属性，分别如下： _index：表示所在的index名。 _type：在6.x版本中只能指定一个类型，在6.4.0版本中默认为“doc”。 _id：文档的唯一标识，类似于MySQL数据库的主键id。 _source：文档数据以json形式保存在该字段内。 针对特定一个或者一类文档进行操作时，必须指定这些属性。 映射（Mapping） 模式映射（schema mapping）用于定义索引（Index）的元数据，指定要索引并存储文档的字段类型。 Elasticsearch在Mapping中存储有关字段的信息。 Mapping在文件中以json表示。 在实际的项目中，尽可能的自定义mapping，不要存储与搜索无关的数据。 字段（Field） Elasticsearch中的最小单元，相当于MySQL中的某个字段，类似于json里的一个键。 分片（Shards） 索引可能会存储大量数据，这些数据可能超过单个节点的硬件限制。 例如到了1TB可能就不再适合单个节点的磁盘，或者因为太慢无法满足来自单个节点的搜索请求。 每个分片（Shards）本身就是一个功能齐全且独立的Lucene“索引”，可以存储在Elasticsearch集群中的任何节点上，这就是分布式存储。 分片的好处： （1）当你查询的索引在多个分片上时，Elasticsearch会把查询发送给每个相关的分片，并将结果合并在一起。所以，多个分片可以加快查询，提高吞吐量。 （2）通过将分片放在不同节点，可以存储超过单节点容量的数据。 副本（Replica） 当集群的某个节点宕机，为防止数据丢失，Elasticsearch还提供了副本（Replica）的概念。 副本分片（Replica Shards）是一个分片的精确复制，每个分片可以有零个或多个副本。 许多相同的分片，其中的一个被自动选择来更改索引操作，这种称为主分片（primary shards），其余的称为副本分片（replica shards）。 在主分片丢失时，集群则将副本分片提升为新的主分片。 副本（Replica）的好处： （1）提高可用性。 （2）由于分片本身就是功能齐全且独立的索引，所以可以加快查询，提高吞吐量。 （3）增加副本分片，可以将数据存储到更多节点上，更好的处理并发请求。 节点（Node） 节点是一个运行着的Elasticsearch实例，或者就是个机器。 集群（Cluster）是一组具有相同cluster.name的节点集合，或者就是一组机器。它们协同工作，共享数据并提供故障转移和扩展功能，当然一个节点也可以组成一个集群。 在Elasticsearch集群中，节点分为Master、Data节点、Client节点等几种角色，任何一个节点都可以同时具备以上所有角色。 Master：主要管理集群信息、primary分片和replica分片信息、维护index信息。 Data：用来存储数据，维护倒排索引，提供数据检索等。 Client：只负责处理用户请求，实现请求转发，负载均衡等功能。 规划和技巧 可以在创建索引（Index）时定义主分片（Primary Shards）和副本分片（Replica Shards）的数量。 创建索引后，我们还可以动态更改副本数，但是要更改分片数就不那么轻松了。因此，预先规划正确的分片数量是最佳方法。 默认情况下，Elasticsearch中的每个索引分配有5个主分片和1个副本分片。这意味着如果集群中至少有两个节点，则索引将具有5个主分片和另外5个副本分片（1个完整副本），总计每个索引10个分片。 Elasticsearch中的分片其实就是Lucene索引。 主分片和副本分片需要分配在不同的节点上，一是为了更好的负载均衡，二是发生故障时可以保障高可用，所以集群最好有2个节点或以上。 一个索引默认有5个主分片，每个主分片默认有1个副本分片，即创建一个索引默认会有10个分片。 读远大于写的场景，可以减少主分片个数，增加副本数，提高吞吐率。写远大于读的场景，最大程度分配主分片个数，一个机器一个，并最大程度减少副本数。 一般将平均分片的大小控制在几GB到几十GB之间。对于基于时间的数据使用场景来说，通常将分片大小控制在20GB到40GB之间。 Elasticsearch推荐的最大JVM堆空间是30~32G，把分片容量限制为30GB，然后再对分片数量做合理估算。 特点 分布式存储，每个字段都可以被索引和搜索。 分布式的准实时分析搜索引擎。 可以扩展到上百台服务器，处理PB级结构化或非结构化数据。 跟一般数据库的区别 1. 通常的数据库侧重存储附带搜索，ES在存储之外侧重搜索。 2. 通常的数据库基于精确匹配，ES基于相关性匹配。 3. ES在搜索之外，还有分析。 4. 同MySQL一样，ES也提供了简单的聚合操作，avg，sum，min，max等。 5. 实时计算的一种常见方案，是数据产生后，通过消息队列（比如kafka）推给实时计算平台storm，计算后，再把数据存到ES。 6. 分析数据的能力，是建立在快速的查询上的。如果没有快速的查询能力，就谈不上分析。 实现 关系数据库，是将数据分成各个字段，存在数据库中，查询时再重新构造出对象；ES是文档存储，把对象直接放进去，查询时直接取出。 MySQL基于B+树索引，来实现快速检索；ES基于倒排索引，对于文档检索来说，倒排索引在性能和空间上更有优势。 ","link":"https://ninglg.com/post/elasticsearch-intro/"},{"title":"Redis数据类型使用场景一览","content":"本文对Redis的几种数据类型的应用场景做一下总结。 数据类型 Redis目前主要有以下几种数据类型： String（字符串） Hash（哈希） List（列表） Set（集合） Zset（Sorted Set，有序集合） Bitmaps（位图） Hyperloglogs（Hyperloglogs） Geospatial（地理空间） String（字符串） 用于缓存 计数 共享session 限速器 二进制数据（String类型是二进制安全的） 分布式锁 Hash（哈希） 单体需要大量KV信息组合的场景 List（列表） 消息队列 Set（集合） 全局去重 Zset（Sorted Set，有序集合） 排行榜 TopN问题 延时任务 范围查找 Bitmaps（位图） Hyperloglogs（Hyperloglogs） Geospatial（地理空间） redis-cli --bigkeys -i 0.1 检查大key，-i是休眠参数 ","link":"https://ninglg.com/post/redis-data-type-application-scene-summary/"},{"title":"App与服务器的通信接口设计","content":"此篇介绍一下App与服务器通信接口设计的一些知识。 安全设计 内部接口 可以使用OAuth1.0签名算法： 将密钥和所有参数组合成源串，根据签名算法生成签名值，发送请求时将签名一起发送给服务器进行验证。 开放外部接口 使用HTTPS HTTPS在HTTP的基础上添加了SSL安全协议，自动对数据进行压缩加密，在一定程度上可以防止监听、劫持、重发，安全性可以提高很多 增加验证token方式 用户用密码登录成功后，服务器返回token给客户端； 客户端将token保存在本地，发起后续的相关请求时，将token发回给服务器； 服务器检查token的有效性，有效则返回数据，若无效，分两种情况： （1）token错误，这时需要用户重新登录，获取正确的token （2）token过期，这时客户端需要再发起一次认证请求，获取新的token 增加appKey 给每个端分配一个appKey，比如Android、iOS、微信三端，每个端分别分配一个appKey和一个密钥。没有传appKey的请求将报错，传错了appKey的请求也将报错。这样，安全性方面又加多了一层防御，同时也方便对不同端做一些不同的处理策略。 手机号+短信验证码 数据格式 { code：0, message: &quot;success&quot;, data: { key1: value1, key2: value2, ... } } 不同错误需要返回不同的错误码。 错误信息一般有两种用途：一是客户端开发人员调试时看具体是什么错误；二是作为App错误提示直接展示给用户看。 版本设计 每个接口有各自的版本，一般为接口添加个version的参数 整个接口系统有统一的版本，一般在URL中添加版本号，比如http://api.domain.com/v2/xxx ","link":"https://ninglg.com/post/app-server-interface-design/"},{"title":"MySQL的备份、扩展、索引、事务隔离级别等关键问题","content":"此篇再谈一下MySQL相关的几个关键问题。 关键问题 性能优化、高可用性、强一致性、安全、备份、集群、横向扩展、纵向扩展、负载均衡、读写分离 分类 主题 内容 单Master 数据备份、数据还原、备份监控、数据文件远程存储 一主一从 性能优化、读写分离、负载均衡 一主n从 数据一致性、脑裂、雪崩、连接池管理 横向集群 库路由、分布式主键、扩缩容 纵向集群 表路由、跨表join、分布式事务 混合模式 单Master 备份机制主要有： 冷备 停机，直接copy物理文件，InnoDB引擎（frm文件、共享表空间文件、独立表空间文件、redo日志文件、my.conf） 热备 使用lbbackup或者XtraBackup工具，记录重做日志文件检查点的LSN，copy共享表空间文件以及独立表空间文件（不产生任何阻塞） 温备 mysqldump、mysqlbinlog 一主一从 性能优化 硬件优化、数据库配置优化、索引优化、表设计等 读写分离 编程实现：区别对待DML、DDL语句 中间件：MySQL Router、MySQL Proxy、Mycat等 负载均衡 编程实现：根据业务实现均衡算法 中间件：MySQL Router、DNS、LVS、L5等 一主n从 数据一致性 MySQL官方套件无法解决一致性 支持的组件：PhxSQL、全局事务控制 脑裂 解决思路是解决租约、Master选举方面的问题 支持的组件：ZooKeeper、PhxSQL 雪崩 解决思路是对连接池进行管控、拒绝无服务能力的请求 组件：Mycat、sql_relay 连接池管理 横向集群 表集群 无官方组件，自己编程实现，或使用现成中间件，如Mycat 跨库join 分布式事务 基于MySQL DB的两阶段提交协议、消息队列 纵向集群 库路由 跟路由表类似，需要通过编程来实现库路由，也可以用Mycat 分布式主键 扩/缩容 扩缩容对数据的搬迁是无法避免的问题，提前对业务数据的增长情况做预判非常必要 拆分 水平拆分 垂直拆分 分区：按时间拆分 索引 主键索引 ALTER TABLE table_name ADD PRIMARY KEY ( column ); 唯一索引 ALTER TABLE table_name ADD UNIQUE (column); 联合索引 ALTER TABLE table_name ADD INDEX index_name ( column1, column2, column3 ); 普通索引 ALTER TABLE table_name ADD INDEX index_name ( column ); 全文索引 ALTER TABLE table_name ADD FULLTEXT ( column ); 空间索引 空间索引是对空间数据类型的字段建立的索引，MySQL中的空间数据类型有4种：geometry、point、linstring和polygon。 ALTER TABLE table_name ADD spatial index spatidx(g); 事务隔离级别 脏读 不可重复读 幻读 Read uncommitted ✅ ✅ ✅ Read committed ❎ ✅ ✅ Repeatable read ❎ ❎ ✅ Serializable ❎ ❎ ❎ ✅ 表示可能发生 数据库并发事务中存在的问题 如果不考虑事务的隔离性，可能会发生以下几种问题： 1. 脏读 脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来访问该数据，就会造成两个事务得到的数据不一致。 2. 不可重复读 不可重复读是指在对于数据库中的某条数据，一个事务范围内多次查询返回不同的数据值(这里不同是指某一条或多条数据的内容前后不一致，但数据条数相同)，这是由于在查询间隔，该事务需要用到的数据被另一个事务修改并提交了。不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读取了其他事务提交的数据。需要注意的是在某些情况下不可重复读并不是问题。 3. 幻读 幻读是事务非独立执行时发生的一种现象。例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。幻读和不可重复读都是读取了另一条已经提交的事务(这点就脏读不同)，所不同的是不可重复读可能发生在update,delete操作中，而幻读发生在insert操作中。 用 explain 分析sql语句 使用explain关键字可以模拟优化器执行sql查询语句，从而得知MySQL 是如何处理sql语句。 +----+-------------+-------+------------+------+---------------+-----+---------+------+------+----------+-------+ | id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra | +----+-------------+-------+------------+------+---------------+-----+---------+------+------+----------+-------+ id select 查询的序列号，包含一组可以重复的数字，表示查询中执行sql语句的顺序。一般有三种情况： 第一种：id全部相同，sql的执行顺序是由上至下； 第二种：id全部不同，sql的执行顺序是根据id大的优先执行； 第三种：id既存在相同，又存在不同的。先根据id大的优先执行，再根据相同id从上至下的执行。 select_type select 查询的类型，主要是用于区别普通查询，联合查询，嵌套的复杂查询 simple：简单的select 查询，查询中不包含子查询或者union primary：查询中若包含任何复杂的子查询，最外层查询则被标记为primary subquery：在select或where 列表中包含了子查询 derived：在from列表中包含的子查询被标记为derived（衍生）MySQL会递归执行这些子查询，把结果放在临时表里。 union：若第二个select出现在union之后，则被标记为union，若union包含在from子句的子查询中，外层select将被标记为：derived union result：从union表获取结果的select partitions 表所使用的分区，如果要统计十年公司订单的金额，可以把数据分为十个区，每一年代表一个区。这样可以大大的提高查询效率。 type 这是一个非常重要的参数，连接类型，常见的有：all , index , range , ref , eq_ref , const , system , null 八个级别。 性能从最优到最差的排序：system &gt; const &gt; eq_ref &gt; ref &gt; range &gt; index &gt; all对java程序员来说，若保证查询至少达到range级别或者最好能达到ref则算是一个优秀而又负责的程序员。 all：（full table scan）全表扫描无疑是最差，若是百万千万级数据量，全表扫描会非常慢。 index：（full index scan）全索引文件扫描比all好很多，毕竟从索引树中找数据，比从全表中找数据要快。 range：只检索给定范围的行，使用索引来匹配行。范围缩小了，当然比全表扫描和全索引文件扫描要快。sql语句中一般会有between，in，&gt;，&lt; 等查询。 ref：非唯一性索引扫描，本质上也是一种索引访问，返回所有匹配某个单独值的行。比如查询公司所有属于研发团队的同事，匹配的结果是多个并非唯一值。 eq_ref：唯一性索引扫描，对于每个索引键，表中有一条记录与之匹配。比如查询公司的CEO，匹配的结果只可能是一条记录， const：表示通过索引一次就可以找到，const用于比较primary key 或者unique索引。因为只匹配一行数据，所以很快，若将主键至于where列表中，MySQL就能将该查询转换为一个常量。 system：表只有一条记录（等于系统表），这是const类型的特列，平时不会出现，了解即可 possible_keys：显示查询语句可能用到的索引(一个或多个或为null)，不一定被查询实际使用。仅供参考使用。 key：显示查询语句实际使用的索引。若为null，则表示没有使用索引。 key_len：显示索引中使用的字节数，可通过key_len计算查询中使用的索引长度。在不损失精确性的情况下索引长度越短越好。key_len 显示的值为索引字段的最可能长度，并非实际使用长度，即key_len是根据表定义计算而得，并不是通过表内检索出的。 ref：显示索引的哪一列或常量被用于查找索引列上的值。 rows：根据表统计信息及索引选用情况，大致估算出找到所需的记录所需要读取的行数，值越大越不好。 extra Using filesort： 说明MySQL会对数据使用一个外部的索引排序，而不是按照表内的索引顺序进行读取。MySQL中无法利用索引完成的排序操作称为“文件排序” 。出现这个就要立刻优化sql。 Using temporary： 使用了临时表保存中间结果，MySQL在对查询结果排序时使用临时表。常见于排序 order by 和 分组查询 group by。 出现这个更要立刻优化sql。 Using index： 表示相应的select 操作中使用了覆盖索引（Covering index），避免访问了表的数据行，效果不错！如果同时出现Using where，表明索引被用来执行索引键值的查找。如果没有同时出现Using where，表示索引用来读取数据而非执行查找动作。 覆盖索引（Covering Index） ：也叫索引覆盖，就是select 的数据列只用从索引中就能够取得，不必读取数据行，MySQL可以利用索引返回select 列表中的字段，而不必根据索引再次读取数据文件。 Using index condition： 在5.6版本后加入的新特性，优化器会在索引存在的情况下，通过符合RANGE范围的条数 和 总数的比例来选择是使用索引还是进行全表遍历。 Using where： 表明使用了where 过滤 Using join buffer： 表明使用了连接缓存 impossible where： where 语句的值总是false，不可用，不能用来获取任何元素 distinct： 优化distinct操作，在找到第一匹配的元组后即停止找同样值的动作。 filtered 一个百分比的值，和rows 列的值一起使用，可以估计出查询执行计划(QEP)中的前一个表的结果集，从而确定join操作的循环次数。小表驱动大表，减轻连接的次数。 通过explain的参数介绍，我们可以得知: 表的读取顺序(id) 数据读取操作的操作类型(type) 哪些索引被实际使用(key) 表之间的引用(ref) 每张表有多少行被优化器查询(rows) ","link":"https://ninglg.com/post/mysql-backup-extension-index-key-points/"},{"title":"HBase介绍","content":"此篇介绍一下HBase相关的内容。 安装 brew install hbase 启动 brew services start hbase 检查 jps 95425 Main 80529 89587 98501 Jps 98459 HMaster 注：jps（Java Virtual Machine Process Status Tool）是JDK 1.5提供的一个显示当前所有java进程pid的命令，简单实用，非常适合在linux/Unix平台上查看当前Java进程的一些简单情况。 命令行交互 hbase shell ","link":"https://ninglg.com/post/intro-to-hbase/"},{"title":"如何设计一个短网址服务","content":"此篇介绍一下设计一个短网址服务的思路。 服务需求 短网址服务可以将一个很长的网址替换为一个短的网址，从而方便用户的使用和转发等。 此类的服务有比如bit.ly，goo.gl等。 核心问题 短网址服务的核心问题是：如何为给定的URL生成一个较短且唯一的字符串。 设计思路 MD5、BASE64等编码方式 我们可以使用传统的MD5、BASE64等多种编码方式，将一个长的URL转换为一个相对较短的字符串。 但这样会存在一些问题： 需要实时编码，性能根据编码方式不同有不同的损耗 生成的短网址仍然长度不够短 预先生成短字符串+缓存池+KV存储 通过预先生成大量的短字符串，并通过缓存池进行预留，需要时直接使用，可大大加快短网址的生成速度。另外，对于原网址和短网址的对应关系，可以通过KV存储直接保存，保证查询时的高性能。 ","link":"https://ninglg.com/post/how-to-design-the-tinyurl-system/"},{"title":"技术系统容灾方案","content":"世事无常，为了保护技术系统能免于自然灾难带来的不可用损失，业内衍生出了多种容灾（或灾备，DR）方案。各家公司基本上都按照“同城双活——异地双活——两地三中心”这样的发展模式进行操作。 单活（即主备模式，Active-Standby） 传统的单活是一主一备，主负责业务处理，备只负责数据同步，备只有在主发生故障时才会启用，并不会承担线上流量。 双活（Active-Active） 主和备都有业务流量，两者同时对外提供服务，并且可以调节流量分担的比例（可以根据用户ID、地域或者其它业务属性来决定怎么分担流量）。 要实现业务双活，需要保证包括基础设施(如存储)、中间件(如MQ)、网络层、应用层等都能实现双活。 双活又分为同城双活（同城双中心）、异地双活。 多活 因为双活需要同步复制，所以双活的两个中心一般在同一个城市（或附近）进行搭建。如果距离太远，同步复制就会出现比较大的延迟，导致性能下降。 备份方式 热备：数据实时备份 冷备：数据周期性定时备份 两地三中心 两地三中心：是指“同城双中心”加上“异地灾备中心”的一种商用容灾备份解决方案，即在双活的基础上增加了一个异地备份的功能。 其中“两地”是指同城、异地，“三中心”是指生产中心、同城容灾中心、异地容灾中心。 同城：在同城或相近区域内（≤ 200km）建立两个数据中心。同城灾难备份一般用于防范火灾、建筑物破坏、供电故障、计算机系统及人为破坏引起的灾难。 异地：主备中心之间的距离较远（＞ 200km) ， 因此一般采用异步镜像，会有少量的数据丢失。异地灾难备份不仅可以防范火灾、建筑物破坏等可能遇到的风险隐患，还能够防范战争、地震、水灾等风险。 网络 数据中心的互联网络一般采用光纤。对于大于25km的光纤链路，还需要增加DWDM波分设备，用于提高带宽降低时延。DWDM对于数据传输的时延起着关键的作用。 双活距离一直都不是问题，主要还是看网络时延和误码率，以及应用对RTT时延要求和容忍度。 ","link":"https://ninglg.com/post/technical-system-disaster-recovery-plan/"},{"title":"分布式链路跟踪设计和实现","content":"此篇介绍一下分布式链路跟踪技术的常见设计和实现方式。 ","link":"https://ninglg.com/post/distributed-systems-tracing/"},{"title":"关于系统监控的一些事","content":"关于系统监控的一些事 系统监控要重点关注的几个指标： 处理器占用率（CPU Usage Percentage） 内存占用率（Mem Usage Percentage） 磁盘占用率 （Disk Usage Percentage） 磁盘IO 网络IO ","link":"https://ninglg.com/post/system-monitor-things/"},{"title":"MySQL的几种日志","content":"MySQL的几种日志 每一个操作在真正写入数据库之前，都会先写入日志。MySQL的日志主要包括 错误日志、查询日志、慢查询日志、事务日志、二进制日志 等几大类。 二进制日志binlog binlog记录写入性操作（不包含查询）信息 以二进制形式保存在磁盘中 binlog是由Server层进行记录的，使用任何存储引擎的MySQL数据库均会记录binlog日志 binlog是以追加的方式进行写入的 可以通过设置max_binlog_size参数来设置每个binlog文件的大小 binlog的三个主要使用场景：（1）主从复制（2）数据恢复（3）信息审计 对于InnoDB存储引擎来说，只有事务提交时才会记录binlog binlog的刷盘时机，通过sync_binlog参数来进行控制 binlog的日志三种格式：statement、row（默认）和mixed，通过binlog-format参数指定。statement格式会记录修改sql语句， row格式会记录行的数据内容变更，记两条，更新前和更新后都有。 事务日志redo log和undo log redo log redo log包含两部分，一个是内存中的日志缓冲（redo log buffer，临时的），另一个是磁盘上的日志文件（redo log file，持久的） mysql每执行一条DML语句，会先将记录写入redo log buffer，后续某个时间点再一次性将多个操作记录写到redo log file。这种先写日志再写磁盘的技术，就是MySQL里经常说到的WAL（Write-Ahead Logging）技术 redo log buffer写入redo log file实际上是先写入OS Buffer，然后再通过系统调用fsync()将其刷到redo log file中 mysql支持3种将redo log buffer写入redo log file的时机，可以通过innodb_flush_log_at_trx_commit参数进行配置 redo log实现上采用了大小固定，循环写入的方式，当写到结尾时，会回到开头循环写日志。在系统启动的时候，就已经为redo log分配了一块连续的存储空间，以顺序追加的方式记录redo log，通过顺序IO来改善性能。所有的事务共享redo log的存储空间，它们的redo Log按语句的执行顺序，依次交替的记录在一起。 只依靠binlog是没有crash-safe能力的，只有redo log也不行。因为redo log是InnoDB特有的，且日志上的记录落盘后会被覆盖掉。因此需要binlog和redo log二者同时记录，才能保证当数据库发生宕机重启时，数据不会丢失 如果数据库崩溃或者宕机，那么当系统重启进行恢复时，可以根据redo log中记录的日志，把数据库恢复到崩溃前的一个状态。未完成的事务可以继续提交，也可以选择回滚，这基于恢复的策略而定。 redo log是innodb独有的，binlog是所有引擎都可以使用的 redo log是循环写的，空间会用完，binlog是可以追加写的，不会覆盖之前的日志信息 binlog和redo log必须保持一致，不允许出现binlog有记录但redo log没有的情况，反之亦然 ##undo log 数据库事务的原子性保证，底层就是通过undo log实现的，主要用作回滚 undo log主要记录了数据的逻辑变化。比如一条INSERT语句，对应一条DELETE的undo log；对于每个UPDATE语句，对应一条相反的UPDATE的undo log。这样在发生错误时，就能回滚到事务之前的数据状态 undo log也是MVCC（多版本并发控制）实现的关键 Innodb通过force log at commit机制实现事务的持久性。即在事务提交的时候，必须先将该事务的所有事务日志写入到磁盘上的redo log file和undo log file中进行持久化。为了确保每次日志都能写入到事务日志文件中，在每次将log buffer中的日志写入日志文件的过程中都会调用一次操作系统的fsync操作（fsync函数同步内存中所有已修改的文件数据到储存设备） 单个事务的回滚，只会回滚当前事务做的操作，并不会影响到其他的事务做的操作。 redo log保证的是事务的持久性和一致性，而undo log则保证了事务的原子性 ","link":"https://ninglg.com/post/mysql-binlog-redolog-undolog/"},{"title":"Etcd介绍和使用","content":"Etcd介绍和使用 简介 Etcd 是 CoreOS 团队于2013年6月发起的开源项目。 Etcd 的目标是构建一个高可用的分布式键值（key-value）数据库。 Etcd 内部采用 Raft 协议作为一致性算法，Etcd 会保证所有的节点都会保存数据，并保证数据的一致性和正确性。 Etcd 基于 Go 语言实现。 Etcd 既支持 gRPC 交互，也提供了 HTTP API 进行交互。 Ectd 支持每秒 1w 写操作，数据来源于官方提供的 Benchmark 数据。 Etcd 支持 SSL/TLS。 Etcd 比较多的应用场景是用于服务发现，服务发现（Service Discovery）要解决的是分布式系统中最常见的问题之一，即在同一个分布式集群中的进程或服务如何才能找到对方并建立连接。 Etcd 目前默认使用 2379 端口提供 HTTP API 服务，2380 端口和 peer 通信。 虽然 Etcd 支持单点部署，但是在生产环境中推荐使用集群方式部署。 由于 Etcd 内部使用投票机制，一般 Etcd 节点数会选择 3、5、7等奇数，最少节点数量是3个。 服务发现 从本质上说，服务发现就是要了解集群中是否有进程在监听 UDP 或者 TCP 端口，并且通过名字就可以进行查找和链接。 用户可以在 Etcd 中注册服务，并且对注册的服务配置 Key TTL，定时保持服务的心跳以达到监控健康状态的效果。 安装 安装：brew install etcd 启动服务：brew services start etcd 检查服务状态：etcdctl endpoint health 查看版本信息：etcd --version etcd是 server 端，etcdctl 是客户端。 使用 查看版本信息 curl http://127.0.0.1:2379/version 添加key etcdctl put mykey &quot;this is myvalue&quot; 查询key etcdctl get mykey 删除key etcdctl del mykey 监控key的变化事件并得到通知 etcdctl watch mykey 使用Raft一致性协议 与Zookeeper的区别 Zookeeper 起源于 Hadoop 生态系统，etcd 的流行是因为它是 kubernetes 的后台支撑。 Zookeeper 使用 Zab 协议作为其一致性协议。 对于 CAP 模型，zookeeper 保障的是 CP。 Etcd 使用 Raft 算法实现的一致性，比 Zookeeper 的 Zab 算法更简单。 其他 在正常节点上查看集群状态 etcdctl endpoint status 摘除异常节点 etcdctl member remove $ID ","link":"https://ninglg.com/post/etcd-intro-and-usage/"},{"title":"分布式系统的几个评估指标","content":"此篇介绍一下对于分布式系统的几个评估指标。 1、正确 比如关于系统一致性、容错性的设计、返回数据的正确性、程序逻辑的正确性 2、性能 比如吞吐量QPS、响应时间RT(一般使用P99，而不应该使用平均响应时间) 3、稳定 比如99.99%的高可用（每个月4.5分钟不可用） 4、扩展 比如增加新数据或新节点的时间成本 ","link":"https://ninglg.com/post/evaluation-indicator-of-distributed-system/"},{"title":"数据聚合类业务系统架构设计","content":"此篇介绍一下数据聚合类业务系统的通用架构设计方法。 在业务中，常会遇到一些需要做数据聚合的服务，通俗的讲就是把多个系统的数据展示到统一的系统上。常见的比如聚合多个业务线的订单数据，做一个订单中心，或者聚合多个频道的推荐信息，做一个信息中心。 针对此类数据聚合的服务，一般如何架构呢？ 数据对接方式 在跟多个外部系统进行数据对接时，是Pull的方式好一些还是Post的方式好一些？ 根据实际业务的情况考虑，如果大部分数据都是需要聚合第三方数据再展示，那么比较推荐让第三方Post数据，本业务自身设计统一的数据规则接口。这种情况下，需要做好数据准确性验证，并保证自身服务的稳定性。 如果只有少部分数据来自第三方，那么也可以考虑Pull的方式。 相比较而言，Post时效性高，数据交互少。还可以在接入时使用MQ提高自身系统的吞吐能力，在读的时候用Cache抗高并发。只要在前期考虑好数据量级和存储选型，保证具有良好的扩展性即可。 完整方案 按业务隔离，不同的业务相互不影响 使用Post/Pull的方式来获取数据 使用Cache和MQ保障高性能 对数据进行聚合或分析进行对外展示 ","link":"https://ninglg.com/post/data-aggregation-business-system-architecture-design/"},{"title":"技术领导能力的四大支柱","content":"在公司环境中，对技术领导的能力有四个重点要求。 1. 业务理解和规划 首先，要有比较好的业务理解能力，这样才能对资源优先级做出判断，才能利用技术决策的手段去驱动业务，才能提升研发效能。 2. 专业技术和架构把控 要对世界的运转以及自己接触的业务保持好奇心，加之过硬的技术能力，才能发现业务问题，影响业务决策，用技术革新带来业务收益。 3. 项目管理和推动跟进 把项目支持好，才能推进业务发展。在这个前提下，再讲技术沉淀和技术红利。 4. 团队管理和人才培养 对团队中每个人的缺点提出改善意见，达到优化整个团队的作用。领导团队发展，持续提升团队战斗力和产出。 总之，最重要的是做一个出众的人。有想法，能搞事情，由好的技术带来好的业务结果。 ","link":"https://ninglg.com/post/four-key-points-of-tech-leader/"},{"title":"Elasticsearch开发规范","content":"Elasticsearch开发规范 ","link":"https://ninglg.com/post/elasticsearch-develop-guideline/"},{"title":"Kafka组件中的常用概念介绍","content":"此篇介绍一下Kafka组件中的常用概念和一些基础知识。 Apache Kafka是一个分布式的消息队列/流处理平台，最初由LinkedIn公司采用Scala开发，最初主要用作活动流（Activity Stream）和运营数据处理管道（Pipeline）的基础。 Kafka支持多生产者，多消费者。 Producer 生产者，即消息发送方。Producer产生的消息将会被发送到某个Topic。 多个生产者将数据发送到 Kafka 中，Kafka 将它们顺序存储。Kafka 只保证在一个 Partition 内的消息是有序的，而不保证全局有序的情况。 producer在写入数据的时候永远的找leader。 Broker 因为Kafka一般是集群形式的，其中每一个Kafka实例（或者说每台Kafka服务器节点）就是一个Broker，一个Broker上可以放多个Topic。 Topic, Partition 都是抽象的概念。每个 Partition 最终都需要存储在物理机器上，在 Kafka 中一般把这样的物理机器称为 Broker，可以是一台物理机，也可以是一个集群。 物理上，消息是存在 Broker 上的。存储时，每个 Partition 都可以有多个副本。它们会被“均匀”地存储在各个 Broker 中。 Topic 消息是根据Topic进行归类的，Topic的本质是一个目录，即将同一主题消息归类到同一个目录中。一个Topic可以理解为一个消息队列。 Partition Kafka 在概念上将一个 Topic 分成了多个 Partition，写入 Topic 的消息会被（平均）分配到其中一个 Partition。Partition 中会为消息保存一个 Partition 内唯一的 ID ，一般称为偏移量(Offset)。这样当性能/存储不足时 Kafka 就可以通过增加 Partition 实现横向扩展。 Kafka 是以 Partition 为单位存储消息的，Consumer 在消费时也是按 Partition 进行的。即 Kafka 会保证一个 Consumer 收到的消息中，来自同一个 Partition 的消息是有序的。而来自不同 Partition 的消息则不保证有序。 对于一个 Partition，它的多个复本存储一般存储在不同 Broker 中，在同一时刻会由 Zookeeper 选出一个主副本来负责所有的读写操作。 Partition在服务器上的具体表现形式就是一个一个的文件夹，每个partition的文件夹下面会有多组segment文件，每组segment文件又包含.index文件、.log文件、.timeindex文件。log文件就是实际存储message的地方，而index和timeindex文件为索引文件，用于检索消息。 Topic是逻辑上的概念，而Partition是物理上的概念。 Segment Segment 被译为段，将 Partition 进一步细分为若干个 Segment，每个 Segment 文件的大小相等。 消息Message 消息的结构重点的包含三部分：offset、消息大小、消息体。 每一条消息记录包含三个要素：键(Key)、值(Value)、时间戳(Timestamp)。 Offset Partition 中会为消息保存一个 Partition 内唯一的 ID ，一般称为偏移量(Offset)。这样 Consumer 可以根据 Offset 自由决定如何读取消息，例如读取更早的消息，重新消费等。 Kafka 0.9版本之前，comsumer默认将offset保存在Zookeeper中，从0.9版本开始，comsumer默认将offset保存在Kafka一个内置的topic中，该topic为__consumer_offsets。 Consumer 消费者，即消息接收方。Consumer消费的消息内容来自于某个topic。 一般有两种消费模型，不同模型下消费者的行为是不同的： 1. 队列模式（也叫点对点模式）。多个消费者共同消费一个队列，每条消息只发送给一个消费者。 2. 发布/订阅模式。多个消费者订阅主题，每个消息会发布给所有的消费者。 Consumer采用pull（拉）模式从broker中读取数据。 在实际的应用中，建议消费者组的consumer数量与partition的数量一致。 Consumer Group Kafka 引入了 Consumer Group（消费者组）的概念，Consumer Group 是以发布/订阅模式工作的。一个 Consumer Group 中可以有多个 Consumer（消费者），一个 Group 内的消费者以队列模式工作。 每个 Group 独立消费某个 Topic 的消息，互相不干扰。事实上，Kafka 会为每个 Group 保存一个偏移量，记录消费的位置。每个 Group 可以包含多个 Consumer，它们共同消费这个 Topic。 每个消费者组都有一个组id。 Zookeeper Zookeeper集群不属于Kafka内的组件，但Kafka依赖Zookeeper集群保存meta信息。 消息的删除 Partition 中的消息可以被（不同的 Consumer Group）多次消费，那 Partition中被消费的消息是何时删除的？ Partition 又是如何知道一个 Consumer Group 当前消费的位置呢？ 1. 无论消息是否被消费，除非消息到期 Partition 从不删除消息。例如设置保留时间为 2 天，则消息发布 2 天内任何 Group 都可以消费，2 天后消息自动被删除。 2. Partition 会为每个 Consumer Group 保存一个偏移量，记录 Group 消费到的位置。 基于时间或基于大小的消息删除策略。 需要注意的是，Kafka读取特定消息的时间复杂度是O(1)，所以删除过期的文件并不会提高Kafka的性能。 Consumer 和 Partition 数量的关系 1. 同一个 Consumer Group 内，一个 Partition 只能被一个 Consumer 消费。 2. 如果 Consumer 的数量大于 Partition 数量，则会有 Consumer 是空闲的。 3. 如果 Consumer 的数量小于 Partition 数量，则一个 Consumer 可能消费多个 Partition。 关于消息分发 消息是Kafka中最基本的数据单元，在Kafka中，一条消息由key、value两部分构成，在发送一条消息时，可以指定这个key，那么producer会根据key和partition机制来判断当前这条消息应该发送并存储到哪个partition中。 Replication 为了实现高可用，Kafka 需要对数据做冗余 (replication)。方案就是存储多份 Partition 在不同的 Broker 上，并为它们的数据进行同步。副本，为保证集群中的某个节点发生故障时，该节点上的partition数据不丢失，且kafka仍然能够继续工作，Kafka提供了副本机制，一个topic的每个分区都有若干个副本，一个leader和若干个follower。 leader 每个分区多个副本的“主”，生产者发送数据的对象，以及消费者消费数据的对象都是leader。 follower 每个分区多个副本的“从”，实时从leader中同步数据，保持和leader数据的同步。leader发生故障时，某个follower会成为新的leader。 Kafka 的各个 Broker 需要与 Zookeeper 进行通信，每个 Partition 的多个副本之间通过 Zookeeper 的 Leader 选举机制选出主副本。所有该 Partition 上的读写都通过这个主副本进行。 其它的冗余副本会从主副本上同步新的消息，就像其它的 Consumer 一样。 分区分配策略 一个consumer group中有多个consumer，一个topic有多个partition，所以必然会涉及到partition的分配问题，即确定一个partition由哪个consumer来消费。 Kafka有两种分配策略，一是roundrobin，另一种是range。 默认情况下，Kafka采用的是hash取模的分区算法（range）。 在订阅了多个topic的情况下，roundrobin策略将会优于range策略。 高可用 Kafka本身提供replica+isr（in-syncreplica set）的机制来保证数据高可用。 核心API Producer API，它允许应用程序向一个或多个 Topics 上发送消息记录。 Consumer API，允许应用程序订阅一个或多个 Topics 并处理为其生成的记录流。 Streams API，它允许应用程序作为流处理器，从一个或多个主题中消费输入流并为其生成输出流，有效的将输入流转换为输出流。 Connector API，它允许构建和运行将 Kafka 主题连接到现有应用程序或数据系统的可用生产者和消费者。例如，关系数据库的连接器可能会捕获对表的所有更改。 重平衡（Rebalance） 当新的消费者加入消费组，它会消费一个或多个分区，而这些分区之前是由其它消费者负责的。 当消费者离开消费组（比如重启、宕机等）时，它所消费的分区会分配给其他分区，这种现象称为重平衡（rebalance）。 重平衡是 Kafka 一个很重要的性质，这个性质保证了高可用和水平扩展。 需要注意的是，在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用。而且，将分区进行重平衡也会导致原来的消费者状态过期，从而导致消费者需要重新更新状态，这段期间也会降低消费性能。 指标 1. 千亿级日志量，PB级数据量。 2. 单个Topic最少可达几十万qps（几十万的写入），集群可达数百万qps。即使是普通的服务器，Kafka也能轻松支持每秒百万级的写入请求，超过了大部分的消息中间件。 3. 据了解，Kafka每秒可以生产约25万消息（50MB），每秒处理55万小（110MB）。 4. 可进行持久化操作。 5. Kafka速度的秘诀在于，它把所有的消息都变成一个批量的文件，并且进行合理的批量压缩，减少网络IO的损耗，通过MMAP提高I/O的速度。写入数据的时候，由于单个Partition（分区）是末尾添加的所以速度最优；读取数据的时候配合sendfile直接暴力输入。 ","link":"https://ninglg.com/post/concepts-of-kafka/"},{"title":"在Mac系统上使用Kafka环境","content":"此篇介绍一下如何在Mac系统上进行安装和使用Kafka环境。 环境安装 在Mac系统上安装最方便的还是使用brew工具命令： brew cask install java brew install zookeeper brew install kafka 安装后的目录 二进制文件和脚本文件在 /usr/local/bin 目录下 Kafka 配置文件在 /usr/local/etc/kafka 目录下 Zookeeper 配置文件在 /usr/local/etc/zookeeper 目录下 log.dirs(Kafka 的数据目录)被设置为 /usr/local/var/lib/kafka-logs 配置修改 修改 /usr/local/etc/kafka/server.properties 文件，将 #listeners=PLAINTEXT://:9092 修改为 listeners=PLAINTEXT://localhost:9092 功能验证 启动服务 brew services start zookeeper brew services start kafka 创建Topic kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic testkafka 2181是zookeeper使用的端口 查看Topic列表 kafka-topics --list --zookeeper localhost:2181 生产消息 $ kafka-console-producer --broker-list localhost:9092 --topic testkafka &gt;hello, kafka! 消费消息 直接消费 kafka-console-consumer --bootstrap-server localhost:9092 --topic testkafka --from-beginning 组(group)消费 kafka-console-consumer --bootstrap-server localhost:9092 --topic testkafka --group test-consumer1 --from-beginning 关闭服务 brew services stop kafka brew services stop zookeeper ","link":"https://ninglg.com/post/use-kafka-on-mac-system/"},{"title":"Go语言的单元测试","content":"此篇介绍一下Go语言的单元测试方法。 Go的单元测试分为两类：功能测试函数和性能测试函数。 ","link":"https://ninglg.com/post/go-unit-test/"},{"title":"Go语言的命令行参数os.Args和flag包","content":"此篇介绍一下Go语言的命令行参数的常用包：os.Args和flag。 os.Args package main import ( &quot;fmt&quot; &quot;os&quot; ) func main () { for idx, arg := range os.Args { fmt.Println(&quot;参数&quot;, idx, &quot;:&quot;, arg) } } 然后执行go build main.go生成可执行文件： ./main -v 1.0 bbb 222 得到输出： 参数 0 : ./main 参数 1 : -v 参数 2 : 1.0 参数 3 : bbb 参数 4 : 222 os.Args用法说明： 命令行的第一个参数默认是程序路径本身 os.Args的类型是[]string，也就是字符串切片 os.Args可以用for..range遍历 可以用len(os.Args)来获取全部参数的数量 如果不想要输出os.Args的第一个值，可以使用os.Args[1:] flag package main import ( &quot;fmt&quot; &quot;flag&quot; ) var b = flag.Bool(&quot;b&quot;, false, &quot;bool类型参数&quot;) var s = flag.String(&quot;s&quot;, &quot;&quot;, &quot;string类型参数&quot;) func main() { flag.Parse() fmt.Println(&quot;-b:&quot;, *b) fmt.Println(&quot;-s:&quot;, *s) fmt.Println(&quot;其他参数：&quot;, flag.Args()) } go run main.go -b: false -s: 其他参数： [] go run main.go -b -b: true -s: 其他参数： [] go run main.go -b -s test others -b: true -s: test 其他参数： [others] go run main.go -help Usage of /var/folders/6q/s3nht_hx0bn54d8nx031lfnr0000gn/T/go-build965629684/b001/exe/main: -b bool类型参数 -s string string类型参数 exit status 2 flag用法说明： 使用flag包，首先定义待解析的命令行参数，也就是以&quot;-&quot;开头的参数 -help不需要特别指定，可以自动处理 通过flag.Bool和flag.String，建立了2个指针b和s，分别指向bool类型和string类型的变量，要通过 *b 和 *s 使用变量值 flag.Bool和flag.String的参数有3个，分别是命令行参数名称，默认值，提示字符串 flag使用前，必须先用flag.Parse()解析 参数中没有能够按照预定义的参数解析的部分，可通过flag.Args()获取，这是一个字符串切片。需要注意的是，从第一个不能解析的参数开始，后面的所有参数都是无法解析的，即使后面的参数中含有预定义的参数 flag.PrintDefaults()可以打印出类似-help的效果 flag.NArg()代表命令行参数的个数 flag.Usage()代表用法说明 参数也可以这样绑定： flag.BoolVar(&amp;h, &quot;h&quot;, false, &quot;this help&quot;) 命令行语法主要有以下几种形式： -flag //只支持bool类型 -flag=x -flag x //只支持非bool类型 ","link":"https://ninglg.com/post/go-command-line-os-args-flag/"},{"title":"命令查询职责分离(CQRS)模式介绍","content":"此篇介绍一下CQRS模式的相关内容。 微服务交互方式 在微服务设计中，一个Service与另外一个Service进行交互通常有三种方式： 1. 命令（Commands） 2. 事件（Events） 3. 查询（Queries） Commands：命令是一个操作，是希望在另一个服务中执行某些操作的一个请求，命令期待有一个响应。 Events：事件既是一个事实也是一个触发器，事件表示发生了一些事情，类似于通知。 Queries：查询是一个查找某些信息的请求（request），查询不会使得系统状态发生改变。 从Service的角度来说，事件方式要比命令和查询方式更解耦一些。 命令查询职责分离(CQRS)模式 命令查询职责分离模式（Command Query Responsibility Segregation，CQRS），该模式从业务上分离了修改 (Command，增，删，改，会对系统状态进行修改)和查询（Query，查，不会对系统状态进行修改)的行为，使得逻辑更加清晰，从而便于对不同部分进行针对性的优化。 ","link":"https://ninglg.com/post/command-query-event-cqrs-intro/"},{"title":"MySQL开发技巧","content":"MySQL开发技巧 数值类型的范围 时间类型的范围 timestamp类型是当前时间到 Unix元年(1970 年 1 月 1 日 0 时 0 分 0 秒)的秒数，占用4个字节，以UTC的格式储存，它会自动检索当前时区并进行转换。datetime以8个字节储存，不会进行时区的检索。 对于timestamp来说，如果储存时的时区和检索时的时区不一样，那么拿出来的数据也不一样。对于datetime来说，存什么拿到的就是什么。 根据存储范围来选取，比如生产时间，保质期等时间建议选取datetime，因为datetime能存储的范围更广。 记录数据的插入时间和修改时间建议使用timestamp。 和时区相关的时间字段选用timestamp。 如果只是想表示年、日期、时间的还可以使用 year、 date、 time，它们分别占据 1、3、3 字节，而datetime就是它们的集合。 如果timestamp字段经常用于查询，还可以使用MySQL内置的函数FROM_UNIXTIME()、UNIX_TIMESTAMP()，将日期和时间戳数字来回转换，转换后可以用 INT UNSIGNED 存储时间，数字是连续的，占用空间更小，并且可以使用索引提升查询性能。 IP类型 IP值一般使用char或varchar进行存储，但是当进行查找和统计时，字符类型不是很高效。 MySQL数据库内置了两个IP相关的函数INET_ATON()、INET_NTOA()，可以实现 IP 地址和整数类型的转换。转换后使用可以INT UNSIGNED 来存储IP，转换后的数字是连续的，提高了查询性能，占用空间更小。 ","link":"https://ninglg.com/post/mysql-tips/"},{"title":"Thrift基本原理介绍","content":"此篇介绍一下Thrift通信协议的基本原理。 Thrift介绍 Thrift是一种接口描述语言和二进制通信协议，它被用来定义和创建跨语言的服务，并被当作一个远程过程调用（RPC）框架来使用。Thrift最初是由Facebook为“大规模跨语言服务开发”而创建的。 RPC Thrift 作为一种轻量级的跨语言 RPC 通信方案，支持多达 25 种编程语言。为了支持多种语言，Thrift 有一套自己的接口定义语言 IDL。可以通过代码生成器，生成各种编程语言的 Client 端和 Server 端的 SDK 代码，这样就保证了不同语言之间可以相互通信。 序列化 Thrift 支持多种序列化格式：如 Binary、Compact、JSON、Multiplexed 等。 支持多种通信方式：如 Socket、Framed、File、Memory、zlib 等。 服务端支持多种处理方式：如 Simple 、Thread Pool、Non-Blocking 等。 使用 通过定义一个以.thrift结尾的文件作为IDL（接口描述语言），内容包含接口的定义，然后通过生成代码的方式，来构建不同语言的RPC客户端和服务端。 通信协议层 通信协议层主要是定义数据传输的格式，对传输的数据进行序列化和反序列化。 传输层 传输层负责直接从网络中读取和写入数据，它定义了具体的网络传输协议；比如说TCP/IP传输等。 ","link":"https://ninglg.com/post/thrift-intro/"},{"title":"Go源码分析：map","content":"Go源码分析：map map使用要点 map的存储是将多个key/value对分散存储在buckets（桶）中，根据key的哈希结果决定放在哪一个桶。 map在声明之后如果直接赋值key和value会导致panic，但如果只是打印key的value等，会返回value的默认空值，不会报错。 map的两种初始化方法：（1）make形式（2）字面量形式（如空map则等同于make操作） make的第二个参数代表初始化创建map的长度。当长度数字为空时，代表默认长度为0。 key的类型必须是可比较的。 map的key有类型限制：slice/map/function不可作为key，value没有类型限制。切片、函数、map是不可比较的。 使用delete来移除一个元素，重复移除同一个元素，或者移除不存在的key，都不会报错。delete操作没有返回值。 map元素不是一个变量，不可以获取它的地址。无法获取map元素的地址一个原因是map的增长可能会导致已有元素被重新散列到新的存储位置，从而使得获取的地址无效。所以，也不能直接通过下标修改value成员。正确的做法是返回整个value，待修改后再设置回去，或者直接使用指针类型。 可以使用for...range结构来遍历map中的元素。 map中元素的迭代顺序是不固定（随机）的。 如果想按照某种顺序来遍历map中的元素，那必须显式的对key进行排序。 map的零值是nil。 从值为nil的map上进行查找/删除/len/range操作都是没问题的，但是不可以设置元素key/value，会导致panic。 要设置key/value，必须初始化map。 通过下标的方式访问map中的元素总是会有值。 可以通过ok语法判断一个key是否存在于map中。 map不可比较，唯一合法的比较就是和nil作比较。 len会返回map的键值对数量，map结构上不可以进行cap操作。 在迭代期间删除或新增键值是安全的，但并发map是不安全的，会存在数据竞争。设计时是从性能损失方面进行考虑，并没有加锁保障并发安全。 Go语言只支持并发的读取Map。Map被设计为不需要从多个goroutine安全访问，在实际情况下Map可能是某些已经同步的较大数据结构或计算的一部分。因此，要求所有Map操作都互斥将减慢大多数程序的速度，而只会增加少数程序的安全性。即这样设计的目的是为了大多数情况下的效率保证。 内容为空的map，与nil是不同的。如map[string]int{}这个内容为空，已初始化，等同于make操作。 Map在实践中极少成为性能的瓶颈，但是却容易写出并发冲突的程序。这要求进行合理的设计以及进行race检查。 ","link":"https://ninglg.com/post/map-intro/"},{"title":"Go源码分析：slice","content":"Go源码分析：slice 基础使用 make可以指定slice的初始len和cap。 在创建slice时，如果切片发生了逃逸或者非常大，运行时需要runtime.makeslice在堆中初始化切片；如果切片不会发生逃逸并且非常小，make会被直接转换成先创建数组再通过下标切片的生成方式（此时编译器会在栈上或者静态存储区创建数组）。 切片扩容 1、如果期望的容量大于当前容量的2倍，则直接使用期望容量； 2、如果当前切片的长度小于1024，就会将容量翻倍； 3、如果当前切片的长度大于1024，就会每次增加25%的容量，直到新容量大于期望容量； 4、在确定切片的大致容量之后，还需要根据切片中的元素大小进行对齐内存。 ","link":"https://ninglg.com/post/slice-intro/"},{"title":"Go语言核心要点","content":"记录一下Go语言的一些要点内容。 数据类型的默认值 数据类型 默认值 int 0 float64 0 string &quot;&quot; bool false pointer nil slice nil map nil func nil chan nil interface nil struct 成员变量各自类型的默认值 按照底层结构划分，值类型包括（所有基本数据类型、数组、结构体），引用类型包括（slice、map、channel、function、interface、指针）。 print Print：输出到控制台，不接受任何格式化操作 Println：输出到控制台并换行 Printf：打印出格式化的字符串，可以直接输出字符串类型的变量 Sprintf：格式化并返回一个字符串而不带任何输出 Fprintf：格式化并输出到 io.Writers 而不是 os.Stdout fmt包 格式符：%v 占位符可以打印任何 Go 的值，%T 可以打印出变量的类型 var e interface{} = 2.7182 fmt.Printf(&quot;e = %v (%T)\\n&quot;, e, e) // e = 2.7182 (float64) 打印指定宽度的数值 fmt.Printf(&quot;%10d\\n&quot;, 353) // will print &quot; 353&quot; 还可以通过将宽度指定为 * 来将宽度当作 Printf 的参数，例如： fmt.Printf(&quot;%*d\\n&quot;, 10, 353) // will print &quot; 353&quot; 当打印出数字列表而且希望它们能够靠右对齐时，这非常的有用。 如果在一个格式化的字符串中多次引用同一个变量，可以使用 %[n]，其中 n 是参数的索引位置（从 1 开始）。 %v 占位符将会打印出 Go 的值，如果此占位符以 + 作为前缀，将会打印出结构体的字段名，如果以 # 作为前缀，那么它会打印出结构体的字段名和类型。 匿名函数和闭包 在多返回值的函数中，并不是每一个返回值都必须赋值，没有被明确赋值的返回值将保持默认的空值。 在Go语言中，所有的函数也是值类型，可以作为参数传递。 Go语言支持常规的匿名函数和闭包。 匿名函数的执行方式是在函数体结束后以()调用。 闭包的本质不是一个包，而是一个函数，是一个持有外部环境变量的函数。 接口 接口和类型可以直接转换，甚至接口的定义都不用在类型定义之前。 方法 可以给内置类型（如int）增加新方法 如何选择方法的receiver类型 要修改实例状态，用*T 无须修改状态的小对象或固定值，建议用T 大对象建议用*T，以减少复制成本 引用类型、字符串、字典、函数等指针包装对象，直接用T 若包含Mutex等同步字段，用*T，避免因赋值造成锁操作无效 其他无法确定的情况都用*T 值传递和引用传递 传递类型 数据类型 值传递 基本类型+复合类型(数组、结构体、指针) 引用传递 slice、map、channel、interface 初始化顺序 全局变量（如果给全局变量赋值一个函数，则此函数先执行，优先于init函数） init函数 main函数 Golang中实现协程间通讯有两种方式 共享内存型：使用全局变量+Mutex锁来实现数据共享。 消息传递型：使用channel机制进行异步通讯。 反射 反射概念 Go没有像Java语言那样内置类型工厂，所以无法通过类型字符串创建对象实例。 Go反射的两个基本概念：Type和Value。 对所有接口进行反射，都可以得到一个包含Type和Value的信息结构。Type代表类型信息，Value代表实例本身的信息。 获取类型信息：reflect.TypeOf(x)。 Type和Value都包含了大量的方法，其中第一个有用的方法是kind，这个方法返回该类型的具体信息：Unit、Float64等。Value类型还包含了一系列类型方法，比如Int()，用于返回对应的值。 任意值通过 reflect.TypeOf() 获得反射对象信息后，如果它的类型是结构体，可以通过反射值对象（reflect.Type）的 NumField() 和 Field() 方法获得结构体成员的详细信息。 package main import ( &quot;fmt&quot; &quot;reflect&quot; _ &quot;github.com/go-sql-driver/mysql&quot; ) type Person struct { Name string `json:&quot;name&quot;` Age int `json:&quot;age&quot; test:&quot;tt&quot;` } func main() { p := Person{ Name: &quot;XiaoMing&quot;, Age: 16, } typ := reflect.TypeOf(p) for i := 0; i &lt; typ.NumField(); i++ { fmt.Println(typ.Field(i).Name, typ.Field(i).Tag) } fmt.Println(typ.Field(1).Tag.Get(&quot;test&quot;)) val := reflect.ValueOf(p) fmt.Println(val.Field(1)) } --------------------- Name json:&quot;name&quot; Age json:&quot;age&quot; test:&quot;tt&quot; tt 16 反射输出 输出变量的类型：fmt.Println(reflect.TypeOf(b).Kind()) Go并不能像Java那样通过类型字符串创建对象实例。 reflect.ValueOf(Data) reflect.ValueOf(Data).Elem() reflect.TypeOf(Data).Elem().NumField() reflect.ValueOf(Data).Elem().NumField() reflect.ValueOf(Data).Elem().Type() reflect.ValueOf(Data).Elem().Type().Name() ... 可变参数/将切片打散 可变参数 （1）这个 ...T 类型等价于 []T 类型。 （2）当 ...string 形参实际传入的实参为nil时，其本质类型也是[]string。 将切片打散 src := []int{1, 2, 3} dst := []int{4, 5} dst = append(src, dst...) fmt.Println(dst) 输出： [1 2 3 4 5] nil nil标志符用于表示interface、function、maps、slices和channels的“零值”。 string的零值是&quot;&quot;，而不是nil。 make make用于slice，map，和channel的初始化。 len和cap 在slice上可以使用len和cap。 可以在创建map时指定它的容量，但无法在map上使用cap()函数。 在channel上可以使用len和cap。 map 只要是任何定义了equal操作的类型都可以当做map的key，比如integers, floating point and complex numbers，strings，pointers，interfaces，channel，structs 和 arrays。 func、slice、map不能作为key，因为它们没有定义equal操作。 对于struct、interface和array来说，如果它们要作为key，必须它们包含的元素都可以作为key才行。 slice的元素是可以取址的，但map的元素是不可取址的，通过interface引用的变量也是不可取址的。 对于一个值为struct类型的map，那么无法更新其单个的struct值，因为map元素是无法取址的。有两种方法可以解决这个问题，一是使用临时的struct进行赋值，二是使用*struct作为值类型的map。 map类型的取值操作总有值返回，Go会返回元素对应数据类型的零值，比如nil、'' 、false 和 0。 单行与多行 在单行的Slice、Array和Map，如果没加末尾的逗号，将不会得到编译错误。 在多行的Slice、Array和Map语句中如果遗漏最后的逗号，会提示编译错误。 不定参数 从底层实现的机制上来说，不定参数本质上是将传入的参数转化成数组的切片。 既然传入的是一个数组的切片，那为什么要专门设置不定参数，而不是直接规定传入一个切片呢？其实这个关键字简化的并不是函数的设计方，而是函数的使用方，这样使用方就不必强制转换成切片了。 如果不定参数传入interface{}，这样就能使用不同类型的参数。可以用.(type)获取一个interface变量实际的类型，这样就实现了任意类型任意数量参数的传入。 log Go中原生的log.Fatal和log.Panic不仅仅是Log，当调用这些函数时，Go也将会终止应用。 并发安全 Go本身有很多特性来支持并发，但并不保证其所有数据类型都是并发安全的，确保数据集合以原子的方式更新是开发者的职责。 由于一个进程内创建的所有goroutine运行在同一个内存地址空间中，因此如果不同的goroutine不得不去访问共享的内存变量，访问前应该先获取相应的读写锁。 Go语言标准库中的sync包提供了完备的读写锁功能。 引用类型 Go 的引用类型包括 slice、map、channel、function、pointer 等，它们在进行赋值时拷贝的是指针值，但拷贝后指针指向的地址是相同的。 slice的源码在：src/runtime/slice.go，扩容处理在 growslice 函数中。 map的源码在：src/runtime/map.go，结构体主要是hmap。 channel的源码在：src/runtime/chan.go，结构体主要是hchan。 堆栈 Go中变量的位置是放在堆上还是栈上是由编译器决定的。如果想知道变量分配的位置，在&quot;go build&quot;或&quot;go run&quot;上传入&quot;-m&quot; gc标志（即go run -gcflags -m main.go）。 同步原语 goroutine和channel的同步原语，在库层面有： sync：提供基本的同步原语（比如Mutex、RWMutex、Locker）和 工具类（Once、WaitGroup、Cond、Pool、Map） sync/atomic：提供原子操作（基于硬件指令compare-and-swap） defer defer语句的含义是不管程序是否出现异常，均在函数退出时自动执行相关代码。 defer执行的3个时机： （1）含有defer的函数返回时 （2）含有defer的函数执行到末尾时 （3）defer所在的goroutine发生panic时 都会执行defer处理。 但当调用os.Exit()方法退出程序时，defer并不会被执行。 defer在匿名返回值和命名返回值函数中的不同表现 package main import &quot;fmt&quot; func main() { fmt.Println(returnValues()) fmt.Println(namedReturnValues()) } func returnValues() int { var result int defer func() { result++ fmt.Println(&quot;returnValues defer&quot;) }() return result } func namedReturnValues() (result int) { defer func() { result++ fmt.Println(&quot;namedReturnValues defer&quot;) }() return result } 输出结果为： returnValues defer 0 namedReturnValues defer 1 首先需要了解defer的执行逻辑，文档中说defer语句在方法返回“时”触发，也就是说return和defer是“同时”执行的。以匿名返回值方法举例，过程如下。 （1）将result赋值给返回值（可以理解成Go自动创建了一个返回值retValue，相当于执行retValue = result） （2）然后检查是否有defer，如果有则执行 （3）返回刚才创建的返回值（retValue） 在这种情况下，defer中的修改是对result执行的，而不是retValue，所以defer返回的依然是retValue。在命名返回值方法中，由于返回值在方法定义时已经被定义，所以没有创建retValue的过程，result就是retValue，defer对于result的修改也会被直接返回。 5. 当发生panic时，所在goroutine的所有defer会被执行，但是当调用 os.Exit() 方法退出程序时，defer并不会被执行。 Recover &amp; Panic recover要与defer联合使用，并且不跨协程，才能真正的拦截panic事件； 每执行一次panic语句，就会创建一个_panic结构体基础单元； defer的基础单元是_defer结构体； 通过查看_panic和link字段可以得知，defer同时挂载着panic信息； 从代码实现来看，panic会触发延迟调用（defer），当defer中存在recover时，才会执行recover。也就是说，在panic时，Go只会对在defer中的recover进行检测； 在Go语言中，有一些panic的情况是无法recover的，即recover并非是万能的。比如panic的fatalthrow方法、fatalpanic方法等，他们一般在并发写入map等处理时抛出，需要谨慎。recover只对用户态下的panic关键字有效。 panic只能触发当前goroutine的defer调用； 让Go Panic的十种方法 数组/切片索引越界 空指针调用 过早关闭HTTP响应体 除以零 向已关闭的通道发送消息 重复关闭通道 关闭未初始化的通道 未初始化map 跨协程的panic处理 sync计数为负值 Go在容器运行时要注意的细节 在容器化的环境中，Go程序所获取的CPU核数是错误的，它所获取的是宿主机的CPU核数。 即使容器和宿主机的CPU核数是共享的，但在集群中一般会针对每个Pod分配指定的核数，因此实际上我们需要的是Pod的核数，而不是宿主机的CPU核数； 如果获取核数错误，可能会导致Go程序的延迟加大，程序响应缓慢； 解决方法： （1）结合部署情况，主动设置正确的GOMAXPROCS核数 （2）通过cgroup信息，读取容器内的正确GOMAXPROCS核数 可以使用Uber公司推出的uber-go/automaxprocs开源库，它会在Go程序运行时根据cgroup的挂载信息来修改GOMAXPROCS核数，并基于一定规则选择一个最合适的数值。 Cgo Cgo的“hello world”示例 package main // #include &lt;stdio.h&gt; // #include &lt;stdlib.h&gt; /* void print(char *str) { printf(&quot;%s\\n&quot;, str); } */ import &quot;C&quot; import &quot;unsafe&quot; func main() { s := &quot;Hello Cgo&quot; cs := C.CString(s) C.print(cs) C.free(unsafe.Pointer(cs)) } 工程管理 Go命令行工具彻底消除了工程文件的概念，完全用目录结构和包名来推导工程结构和构建顺序。 问题追踪和调试 最常规的问题跟踪方法：打印日志、使用GDB进行逐步调试。 Go语言编译的二进制程序直接支持GDB调试。Go编译器生成的调试信息格式为DWARFv3，只要GDB版本高于7.1都支持。 Json Go语言的大部分数据类型都可以转化为有效的Json文本，但channel、complex和函数这几种类型除外。 sync.Once sync.Once可用于任何符合“exactly once”语义的场景，比如： 初始化 rpc/http client open/close 文件 close channel 线程池初始化 go version 查看Go二进制文件的版本信息 go version [Go二进制文件的绝对路径] 查看Go二进制文件的go mod信息 go version -m [Go二进制文件的绝对路径] 多个init的调用顺序 不同的package，如果存在相互依赖，则最先调用最早被依赖的package中的init()； 不同的package，如果不存在相互依赖，则按照main包中&quot;先import的后调用&quot;的顺序调用其包中的init()； 同一个package中，不同文件是按文件名字符串比较“从小到大”顺序调用各文件中的init()函数； 同一个package中，对同一个go文件的多个init()调用顺序是从上到下的； 逃逸分析 Go语言的堆栈分配可以通过compiler去分析，通过GC去管理； 逃逸分析是一种确定指针动态范围的方法，即分析在程序中的哪些地方可以访问到该指针，从而确定一个变量是放在堆上还是栈上； 如果在其它地方（非局部）被引用，那么此变量一定是被分配到堆上； 即使没有被引用，如果对象过大，则依然有可能被分配到堆上； 注意：Go语言是在编译阶段确立逃逸的，并不是在运行时； 是否被作用域之外引用是逃逸的重要原因之一； 如果是未确定类型，比如使用了 fmt.Println(str) 进行打印，因为 func Println(a ...interface{}) (n int, err error) 的形参是interface{}，这种在编译阶段无法确定具体类型，因此会造成逃逸，最终str变量会分配到堆上； 如果是泄露参数，比如一个指针参数传给函数之后，没有做任何引用之类的设计变量的动作，而是被直接原样返回，那这个变量实际上并没有逃逸，它仍然是被分配在栈上； 静态分配到栈上，一般会比动态分配到堆上性能要好； 底层分配到堆上还是栈上，一般来说对用户是透明的，无需过度关心； 每个Go版本的逃逸分析都可能有所不同，因为会不断优化； 处处使用指针传递不一定是最好的，建议合理使用； 竞态检测 竞争检测器已经完全集成到Go工具链中，仅仅添加-race标志到命令行就使用了检测器。 $ go test -race mypkg // 测试包 $ go run -race mysrc.go // 编译和运行程序 $ go build -race mycmd // 构建程序 $ go install -race mypkg // 安装程序 goroutine的栈空间 从栈空间上，goroutine的栈空间更加动态灵活。 每个OS的线程都有一个固定大小的栈内存，通常是2MB，栈内存用于保存在其他函数调用期间哪些正在执行或者临时暂停的函数的局部变量。这个固定的栈大小对于goroutine来说，可能是一种巨大的浪费。 作为对比goroutine在生命周期开始只有一个很小的栈，典型情况是2KB。在go程序中，一次创建十万左右的goroutine也不罕见（2KB*100,000=200MB），而且goroutine的栈不是固定大小，它可以按需增大和缩小，最大限制可以到1GB。 channel ","link":"https://ninglg.com/post/golang-key-points/"},{"title":"Nginx的四层负载均衡和七层负载均衡","content":"Nginx的四层负载均衡和七层负载均衡 四层负载 工作在OSI第4层，就是TCP层，可以根据 IP+端口 进行负载均衡。 此种Load Balance不理解应用协议（如HTTP/FTP/MySQL等等）。 七层负载 工作在OSI的最高层，第7层应用层，可以基于Http协议和URL内容进行负载均衡。 此时负载均衡能理解应用协议。 四层负载均衡本质是转发，而七层负载均衡本质是内容交换和代理。 在不需要进行状态保留和基于内容的路由的时候，完全可以启用四层负载均衡来获取更好的性能。 ","link":"https://ninglg.com/post/nginx-load-balance-4-level-7-level/"},{"title":"常用开发工具清单","content":"此篇列一下常用的开发工具清单。 工具 作用 wrk 一个现代化的HTTP压力测试工具 ","link":"https://ninglg.com/post/common-develop-toolbox/"},{"title":"Nginx限流功能介绍","content":"此篇介绍一下Nginx的限流功能。 Nginx限流方式 限制访问频率 限制并发连接数 一、限制访问频率 1. 正常流量限制访问频率 在nginx.conf配置文件中可以使用limit_req_zone命令及limit_req命令限制单个IP的请求处理频率。 limit_req_zone key zone rate key: 定义需要限流的对象 zone: 定义共享内存区来存储访问信息 rate: 用于设置最大访问速率 示例如： http { limit_req_zone $binary_remote_addr zone=myLimit:10m rate=3r/s; } server { location / { limit_req zone=myLimit; rewrite / http://www.test.com permanent; } } 2. 突发流量限制访问频率 上面的配置在一定程度上可以限制访问频率，但是也存在着一个问题：如果突发流量超出请求被拒绝处理，无法处理活动高峰时的突发流量，这时候应该如何处理呢？Nginx提供了burst参数结合nodelay参数可以解决流量突发的问题，即设置在超过请求数外能额外处理的请求数。示例如： http { limit_req_zone $binary_remote_addr zone=myLimit:10m rate=3r/s; } server { location / { limit_req zone=myLimit burst=5 nodelay; rewrite / http://www.test.com permanent; } } 可以看到上面添加了burst=5 nodelay。 如果没有添加nodelay参数，则可以理解为预先在内存中占用了5个请求的位置，如果有5个突发请求就会按照200ms/个去依次处理请求，也就是1s内把5个请求全部处理完毕。如果1s内有新的请求到达也不会立即进行处理，因为紧急程度更低。这样实际上就会将额外的5个突发请求以200ms/个去依次处理，保证了处理速率的稳定，所以在处理突发流量的时候也一样可以正常处理。 如果添加了nodelay参数则表示要立即处理这5个突发请求。 二、限制并发连接数 Nginx中的ngx_http_limit_conn_module模块提供了限制并发连接数的功能，可以使用limit_conn_zone指令以及limit_conn执行进行配置。接下来我们可以通过一个简单的例子来看下： http { limit_conn_zone $binary_remote_addr zone=myip:10m; limit_conn_zone $server_name zone=myServerName:10m; } server { location / { limit_conn myip 10; limit_conn myServerName 100; rewrite / http://www.test.com permanent; } } 上面配置了单个IP同时并发连接数最多只能10个连接，并且设置了整个虚拟服务器同时最大并发数最多只能100个链接。当然，只有当请求的header被服务器处理后，虚拟服务器的连接数才会计数。 Nginx是基于漏桶算法原理实现的，实际上限流一般都是基于漏桶算法和令牌桶算法实现的。接下来我们来看看关于这两个算法的介绍： 三、令牌桶算法 令牌桶算法是网络流量整形（Traffic Shaping）和速率限制（Rate Limit）中最常使用的一种算法。典型情况下，令牌桶算法用来控制发送到网络上的数据的数目，并允许突发数据的发送。 令牌桶算法的机制如下：存在一个大小固定的令牌桶，会以恒定的速率源源不断产生令牌。如果令牌消耗速率小于生产令牌的速度，令牌就会一直产生直至装满整个令牌桶。 四、漏桶算法 漏桶（Leaky Bucket）算法也是网络世界中流量整形或速率限制时经常使用的一种算法，它的主要目的是控制数据注入到网络的速率，平滑网络上的突发流量。 漏桶算法提供了一种机制，通过它，突发流量可以被整形以便为网络提供一个稳定的流量。突发流量会进入到一个漏桶，漏桶会按照我们定义的速率依次处理请求，如果水流过大也就是突发流量过大就会直接溢出，即多余的请求会被拒绝，所以漏桶算法能控制数据的传输速率。 令牌桶算法与漏桶算法的区别：两种算法都能够限制数据传输速率，但令牌桶还允许某种程度的突发传输。因为令牌桶算法只要令牌桶中存在令牌，就可以突发的传输对应的数据到目的地，所以更适合流量突发的情形下进行使用。 1. 漏桶是出，令牌是进 2. 令牌是允许伸缩的 ","link":"https://ninglg.com/post/nginx-rate-limit/"},{"title":"Redis开发规范","content":"此篇介绍一下Redis相关的开发规范。 存储 默认都使用redis db 0，一般无需select切换 禁止在redis中存储图片类型 性能 10w级别qps的性能系统 小数据集单个操作，耗时一般小于个位数ms 使用 SCAN 命令时应该批次使用，单次扫描key数量不应超过2万，间隔0.5s 时间复杂度为O(n)的命令需要注意N的数量 大Key问题避免 key的长度建议64个字符以内。 value的大小要控制在10KB以内。 hash、list、set、zset的元素个数一般不要超过5000个，元素数量过多可考虑拆分成多个key进行处理。 在Redis中，一个字符串最大512MB，一个二级数据结构（例如hash、list、set、zset）可以存储大约40亿个(2^32-1)个元素。但实际上中如果符合下面两种情况，一般就认为它是bigkey： （1）字符串类型：它的big体现在单个value值很大，一般认为超过10KB就是bigkey。 （2）非字符串类型：哈希、列表、集合、有序集合，它们的big体现在元素个数太多。 热点Key问题避免 拆分 批量处理 推荐使用批量操作提升操作效率 批量命令主要分为两类，原生命令和非原生命令： 原生命令包括：例如mget、mset、hmget、hmset、LPUSH key value集合等 非原生命令包括：Pipeline 批量数量建议不超过1000，要考虑数据大小，批量太多建议使用hscan、sscan、zscan遍历代替 数据过期 如果不需要长期存储，需要设定过期时间，固定时间+加一个随机数，防止集中过期 禁止在集合结构中只存不清，对于集合结构中数据增加频繁必须要有删除机制 禁止命令 禁止线上使用命令：KEYS、FLUSHDB、FLUSHALL、BGSAVE SAVE BGREWRITEAOF等 功能 Redis的事务功能较弱，不建议过多使用 monitor命令要控制使用时间，避免长时间使用 Redis集群版本在使用Lua上有特殊要求：所有key都应该由 KEYS 数组来传递，所有key必须在1个slot上 安全 使用密码访问授权，保障安全性 线上环境 Redis节点内存上限不能超过20G。 必须设置内存最大值，且必须可用内存不小于10%。 ","link":"https://ninglg.com/post/redis-develop-guideline/"},{"title":"Makefile介绍","content":"Makefile介绍 Make 是一个构建自动化工具，此命令会在当前目录下寻找 Makefile 文件。 如果文件存在，则会依据 Makefile 文件中的构建规则去完成构建。 规则 Makefile 由多条规则组成，每条规则都以一个 target（目标）开头，后跟一个 : 冒号，冒号后是这一个目标的 prerequisites（前置条件） ，紧接着新的一行，必须以一个 tab 作为开头，后面跟着完成目标所需要执行的一系列 command（命令）。 [target] ... : [prerequisites] ... &lt;tab&gt;[command] ... ... 描述 target：一个目标代表一条规则，可以是一个或多个文件名，也可以是某个操作的名字（标签），称为伪目标（phony）。 prerequisites：前置条件，这一项是可选参数。通常是多个文件名、伪目标。它的作用是影响 target 是否需要重新构建的标准。如果前置条件不存在或有过更新（文件的最后一次修改时间）则认为 target 需要重新构建。 command：构建这一个 target 的具体命令集。 示例 .PHONY: build clean tool lint help all: build build: go build -v . tool: go tool vet . |&amp; grep -v vendor; true gofmt -w . lint: golint ./... clean: rm -rf output go clean -i . help: @echo &quot;make: compile packages and dependencies&quot; @echo &quot;make tool: run specified go tool&quot; @echo &quot;make lint: golint ./...&quot; @echo &quot;make clean: remove objetct files and other useless files&quot; 解释 PHONY的作用是声明 build / clean / tool / lint / help 为伪目标。如果被声明为伪目标，在执行对应的命令时，make 就不会去检查是否存在 build / clean / tool / lint / help 其对应的结果文件，而是每次都会运行标签对应的命令。如果不声明，那么恰好存在对应的结果文件时，make 就会认为文件已存在，没有重新构建的必要了。 其它命令 make: make 就是 make all make build: 编译当前项目的包和依赖项 make tool: 运行指定的 Go 工具集 make lint: golint 检查一下 make clean: 删除对象文件和缓存文件 make help: help 回声 make 默认会打印每条命令，再执行。 如果不想打印命令，可以在对应命令前加上 @，可指定该命令不被打印到标准输出上。 ","link":"https://ninglg.com/post/makefile-intro/"},{"title":"redis事务的特点","content":"redis事务的特点 redis事务 redis事务包含了一组命令，这些命令的执行是一次性、顺序性的。 和数据库事务的区别 redis事务有：开始事务、命令入队、执行事务 三个阶段。 redis事务没有隔离级别的概念，并不会做内部的预查询。 redis事务不保证原子性，且没有回滚。 redis事务命令 watch key1 key2 #监视key1和key2，如果执行过程中被其它命令更改，则事务被打断。即乐观锁机制 multi #指定事务开始 exec #指定事务执行，且前面监控锁会被取消 discard #指定事务取消 unwatch #取消对key的监控 场景 discard会将前面的命令都取消。 事务在exec前，如果某个命令出错（比如命令不存在，而非语法错误），则所有命令都不会执行。 事务在exec前，如果某个命令有语法性错误（如incr了一个字符串），则其它命令照样执行。 事务在exec前，如果watch的某个key发生了变化，则事务中的命令都不会执行。 ","link":"https://ninglg.com/post/redis-transaction/"},{"title":"Mac使用技巧","content":"记录一下Mac使用的一些技巧。 快捷键 关闭软件 关闭（⌘ + W）：关闭当前的软件窗口（软件并没有真正退出进程），相当于点了左上角的。 退出（⌘ + Q）：真正退出软件。 强制退出（⌘ + option + esc）：强制退出某个软件，通常在软件无响应时使用。 截屏 command+shift+3：捕获整个屏幕，并保存为桌面文件 command+shift+4 ：自由选取范围截屏，并保存为桌面文件 command+shift+4+space：捕获窗口/菜单/桌面图标/菜单栏等截屏，并保存为桌面文件 command+shift+5：弹出新截图工具 鼠标取词翻译 把光标悬停在一个单词上，按下 command+control+D，这个单词的解释就会弹出来。 改变删除方向 delete是向前删除，fn+delete可以向后删除。 ","link":"https://ninglg.com/post/mac-usage-skill/"},{"title":"gitignore文件规则","content":"此篇介绍一下 .gitignore 文件的忽略书写规则。 在通常的代码开发和调试过程中，我们经常会生成一些日志文件、临时编译文件等，这些文件我们并不需要提交到代码仓库中，此时就需要使用 .gitignore 文件来进行忽略。 在代码仓库中创建名为 .gitignore 的文件，Git 将使用它来确定在提交之前要忽略哪些文件和目录。 应将 .gitignore 文件提交到仓库中，以便与其他用户共享忽略规则。 在 .gitingore 文件中，遵循相应的语法，在每一行指定一个忽略规则。 .gitignore 文件的注释用使用#号，*号表示匹配0个或多个任意字符。 以斜杠&quot;/&quot;开头表示目录。 以星号&quot;*&quot;通配多个字符，即匹配多个任意字符；使用两个星号&quot;**&quot; 表示匹配任意中间目录。 以问号&quot;?&quot;通配单个字符，即匹配一个任意字符。 以方括号&quot;[]&quot;包含单个字符的匹配列表，即匹配任何一个列在方括号中的字符。 以叹号&quot;!&quot;表示不忽略(跟踪)匹配到的文件或目录，即要忽略指定模式以外的文件或目录，可以在模式前加上惊叹号（!）取反。 空行不进行匹配，可以作为段落分隔符，增强可读性。 &quot;&quot;是作为转义符。 ","link":"https://ninglg.com/post/gitignore-file-rule/"},{"title":"MySQL连接数","content":"此篇介绍一下MySQL连接数相关的内容。 查看Mysql最大连接数设置 show variables like '%max_connections%'; +-----------------+-------+ | Variable_name | Value | +-----------------+-------+ | max_connections | 151 | +-----------------+-------+ 1 row in set (0.00 sec) 查看MySQL服务这次启动到现在，同一时刻并行连接数的最大值 show status like 'Max_used_connections'; +----------------------+-------+ | Variable_name | Value | +----------------------+-------+ | Max_used_connections | 1 | +----------------------+-------+ 1 row in set (0.00 sec) 修改最大连接数设置 sql命令修改，立即生效，服务器重启后失效 set global max_connections = 1000; 配置文件修改，永久生效 在 /etc/my.cnf 中添加 max_connections = 1000; 减少Sleep进程 查看当前的所有连接状态 show processlist; +----+------+-----------+------+---------+------+-------+------------------+ | Id | User | Host | db | Command | Time | State | Info | +----+------+-----------+------+---------+------+-------+------------------+ | 3 | root | localhost | NULL | Query | 0 | init | show processlist | +----+------+-----------+------+---------+------+-------+------------------+ 1 row in set (0.00 sec) 查看timeout设置 MySQL数据库有一个属性wait_timeout就是Sleep连接的最大存活时间，默认是28800s。 show global variables like '%wait_timeout'; +--------------------------+----------+ | Variable_name | Value | +--------------------------+----------+ | innodb_lock_wait_timeout | 50 | | lock_wait_timeout | 31536000 | | wait_timeout | 28800 | +--------------------------+----------+ 3 rows in set (0.00 sec) 修改timeout设置 set global wait_timeout=180; 这样可以解决报 “Too Many Connections” 的问题。 ","link":"https://ninglg.com/post/mysql-connections-intro/"},{"title":"1on1沟通应该怎么做","content":"此篇介绍一下如何进行有效的1on1沟通。 在职场中，上下级之间进行1on1沟通，就一些当前和长期问题进行讨论，可以增加信息透明，并获得相应的指导和帮助。 沟通，要逐渐的从关注事情的维度，转为关注人的维度。 沟通要主动 沟通绝不仅仅是Leader的事情，每个人都可以根据一定的频率，主动的跟上下级进行沟通。 沟通的内容 1on1沟通一般不太会重点说项目相关的内容，更多的是了解和希望解决面临的问题，或者提出一些有效的建议。了解上级有有什么指导和期望，了解下级有什么问题和诉求。 让对方思考 1on1沟通中，无论出于什么样的角色，都可以引发对方的思考，思考发现自己的成长问题，或思考如何给予对方帮助。 ","link":"https://ninglg.com/post/how-to-do-1on1-well/"},{"title":"定时任务调度器的设计","content":"此篇介绍一下如何简单实现定时任务调度器。 实现定时任务调度器，最关键的如何对任务的时间进行判断和调度。 顺序遍历 对所有任务进行顺序遍历，进行时间判断和调度，虽然简单，但明显不是时间最优的方法。 优先级队列 使用时间作为优先级，只需要查询时间最接近当前时间的队列数据即可。 优先级队列一般使用堆结构进行实现，时间复杂度LogN。 时间轮 时间轮是一个环形队列，按照时间的单位进行区分。比如每个单位是1s，然后一个单位里挂载一个链表，用来存储定时任务。 如果时间超过了一个环形队列的长度，那么可以使用多级时间轮进行优化。比如第一层的走一圈时，第二层的走一格，有点类似于水表的那种表示。 最终时间复杂度为O(1)。 ","link":"https://ninglg.com/post/how-to-implement-timing-task-scheduler/"},{"title":"Redis Key的过期","content":"此篇介绍一下跟Redis Key过期相关的内容。 DEL/SET/GETSET等命令会清除过期时间 INCR/LPUSH/HSET等命令不会清除过期时间 PERSIST命令会清除过期时间 使用RENAME命令，旧Key的过期时间将会转到新Key上 使用EXPIRE/PEXPIRE设置的过期时间为负数或者使用EXPIREAT/PEXPIREAT设置过期时间戳为过去的时间会导致key被删除 EXPIRE命令可以更新过期时间 批量删除key redis-cli --scan --pattern &quot;test*&quot; | xargs -L 1 redis-cli del ","link":"https://ninglg.com/post/redis-key-ttl-expire/"},{"title":"Nginx的负载均衡策略","content":"Nginx的负载均衡策略 负载均衡使用upstream 负载均衡用于从“upstream”模块定义的后端服务器列表中选取一台服务器接受用户的请求。 upstream负载均衡分配策略 （1）轮询 默认的均衡策略。 每个请求会按时间顺序逐一分配到不同的后端服务器。 （2）weight 权重方式，在轮询策略的基础上指定轮询的几率。 （3）ip_hash 指定负载均衡器按照基于客户端IP的分配方式。 这个方法确保了相同的客户端的请求一直发送到相同的服务器，以保证session会话。 每个访客都固定访问一个后端服务器，可以解决session不能跨服务器的问题。 （4）least_conn 把请求转发给连接数较少的后端服务器。 此策略适合请求处理时间长短不一造成服务器过载的情况。 第三方插件实现的负载均衡策略 （1）fair 按照服务器端的响应时间来分配请求，响应时间短的优先分配。 （2）url_hash 按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，要配合缓存命中来使用。 同一个资源多次请求，可能会到达不同的服务器上，导致不必要的多次下载，缓存命中率不高且可能造成资源时间的浪费。但是使用url_hash，可以使得同一个url（也就是同一个资源请求）到达同一台服务器，一旦缓存住了资源，再次收到请求，就可以从缓存中读取。 ","link":"https://ninglg.com/post/nginx-load-balance/"},{"title":"MySQL数据库的关键性能指标","content":"此篇介绍一下关于MySQL数据库的关键性能指标。 QPS 每秒处理的查询数，同时适用于InnoDB和MyISAM引擎。 TPS 每秒处理的事务数，适用innodb引擎。 Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。 TPS包括一条消息入和一条消息出，加上一次用户数据库访问。 IOPS 每秒磁盘进行的I/O操作次数。 IOPS（Input/Output Per Second）即每秒的输入输出量(或读写次数)，是衡量磁盘性能的主要指标之一。IOPS是指单位时间内系统能处理的I/O请求数量，一般以每秒处理的I/O请求数量为单位，I/O请求通常为读或写数据操作请求。 随机读写频繁的应用，如OLTP（Online Transaction Processing），IOPS是关键衡量指标。 另一个重要指标是数据吞吐量（Throughput），指单位时间内可以成功传输的数据数量。对于大量顺序读写的应用，如VOD（Video On Demand），则更关注吞吐量指标。 使用explain分析sql语句 结果字段 含义 id select查询的序列号，包含一组数字，表示查询中执行select子句或操作表的顺序 select_type 查询类型 table 正在访问哪个表 partitions 匹配的分区 type 访问的类型 possible_keys 显示可能应用在这张表中的索引，一个或多个，但不一定实际使用到 key 实际使用到的索引，如果为NULL，则没有使用索引 key_len 表示索引中使用的字节数，可通过该列计算查询中使用的索引的长度 ref 显示索引的哪一列被使用了，如果可能的话，是一个常数，哪些列或常量被用于查找索引列上的值 rows 根据表统计信息及索引选用情况，大致估算出找到所需的记录所需读取的行数 filtered 查询的表行占表的百分比 Extra 包含不适合在其它列中显示但十分重要的额外信息 查看索引的使用率 show status like 'handler_read%'; handler_read_key 越高说明索引使用的好，handler_read_rnt_next越高使用索引越低效。 ","link":"https://ninglg.com/post/mysql-qps-tps-iops/"},{"title":"rsync文件传输和同步工具","content":"此篇介绍一下rsync文件传输和同步工具。 rsync介绍 rsync命令即代表remote sync，是一个文件传输和同步备份工具。它可以将一个客户机和远程文件服务器之间的文件进行同步，也可以在本地系统中将数据从一个分区备份到另一个分区上。 如果rsync在备份过程中出现了数据传输中断，恢复后可以继续传输不一致的部分。 rsync可以执行完整备份或增量备份。 rsync特点 可以镜像保存整个目录树和文件系统； 可以很容易做到保持原来文件的权限、时间、软硬链接；无须特殊权限即可安装； 可以增量同步数据，文件传输效率高，因而同步时间短； 可以使用rcp、ssh等方式来传输文件，当然也可以通过直接的socket连接； 支持匿名传输，以方便进行网站镜象等； 加密传输数据，保证了数据的安全性； rsync使用 - 从本地同步文件到远程: rsync [本地文件路径] [远程主机]:[远程目录] - 从远程同步文件到本地: rsync [远程主机]:[远程文件] [本地文件路径] - 传输压缩文件 (保留属性) 并带有详细的传输进度信息: rsync -azvhP [本地文件路径] [远程主机]:[远程目录] - 从远程到本地传输一个目录及其子文件: rsync -r [远程主机]:[远程目录] [本地文件路径] - 从远程到本地传输一个目录的内容（不包括目录本身）: rsync -r [远程主机]:[远程目录/] [本地文件路径] - 从远程传输文件（仅传输更新的文件）: rsync -ru [远程主机]:[远程目录] [本地文件路径] - 通过SSH传输文件并且删除在远程主机上不存在的本地文件: rsync -e ssh --delete [远程主机]:[远程目录] [本地文件路径] - 通过SSH传输并显示全局进度: rsync -e ssh --info=progress2 [远程主机]:[远程文件] [本地文件路径] ","link":"https://ninglg.com/post/rsync-file-transfer-remote-local-host/"},{"title":"MySQL的锁机制","content":"介绍一下MySQL锁相关的内容。 共享锁和独占锁（Shared and Exclusive Locks） InnoDB 通过共享锁和独占锁两种方式实现了标准的行锁。 共享锁（S 锁）：允许事务获得锁后去读数据。 独占锁（X 锁）：允许事务获得锁后去更新或删除数据。 一个事务获取共享锁 S 后，允许其他事务获取 S 锁，此时两个事务都持有共享锁 S，但是不允许其他事务获取 X 锁。如果一个事务获取的独占锁（X），则不允许其他事务获取 S 或者 X 锁，必须等到该事务释放锁后才可以获取到。 意向锁（Intention Locks） InnoDB 支持行锁和表锁。意向锁是一种表级锁，用来指示接下来的一个事务将要获取的是什么类型的锁（共享还是独占）。 意向锁分为意向共享锁（IS）和意向独占锁（IX），依次表示接下来一个事务将会获得共享锁或者独占锁。 意向锁不需要显示的获取，而是在获取共享锁或者独占锁的时候会自动的获取。 意向锁不会锁住任何东西，除非有进行全表请求的操作，否则不会锁住任何数据。 意向锁存在的意义只是用来表示有事务正在锁某一行的数据，或者将要锁某一行的数据。 记录锁（record Locks） 锁住某一行，如果表存在索引，那么记录锁是锁在索引上的，如果表没有索引，那么 InnoDB 会创建一个隐藏的聚簇索引加锁。 所以在进行查询的时候尽量采用索引进行查询，这样可以降低锁的冲突。 间隙锁（Gap Locks） 间隙锁是一种记录行与记录行之间存在空隙或在第一行记录之前或最后一行记录之后产生的锁。 间隙锁可能占据的单行，多行或者是空记录。 通常的情况是我们采用范围查找的时候，比如在学生成绩管理系统中，如果此时有学生成绩 60，72，80，95，一个老师要查下成绩大于 72 的所有同学的信息，采用的语句是 select * from student where grade &gt; 72 for update，这个时候 InnoDB 锁住的不仅是 80，95，而是所有在 72-80，80-95，以及 95 以上的所有记录。为什么会这样呢？实际上是因为如果不锁住这些行，那么如果另一个事务在此时插入了一条分数大于 72 的记录，那会导致第一次的事务两次查询的结果不一样，出现了幻读。所以为了在满足事务隔离级别的情况下需要锁住所有满足条件的行。 产生幻读的原因是，行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。 因此，为了解决幻读问题，InnoDB只好引入新的锁，也就是间隙锁(Gap Lock)。 Next-Key Locks NK 是一种记录锁和间隙锁的组合锁。 NK 既锁住行也锁住间隙。 NK 采用的左开右闭的原则。 InnoDB 对于查询都是采用这种锁的。 MyISAM 和 InnoDB MyISAM中是不会产生死锁的，因为MyISAM总是一次性获得所需的全部锁，要么全部满足，要么全部等待;而在InnoDB中，锁是逐步获得的，这就造成了死锁的可能。 InnoDB引擎既支持行锁也支持表锁，那么什么时候会锁住整张表，什么时候或只锁住一行呢？只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁。 由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以即使是访问不同行的记录，如果使用相同的索引键，仍然是会出现锁冲突的。 当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行。另外，不论是使用主键索引、唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。 即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的。如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引。这种情况下InnoDB 将使用表锁，而不是行锁，因此，在分析锁冲突时,，别忘了检查 SQL 的执行计划，以确认是否真正使用了索引。 在MySQL中，行级锁并不是直接锁记录，而是锁索引。索引分为主键索引和非主键索引两种，如果一条sql语句操作了主键索引，MySQL就会锁定这条主键索引；如果一条语句操作了非主键索引，MySQL会先锁定该非主键索引，再锁定相关的主键索引。 在UPDATE、DELETE操作时，MySQL不仅锁定WHERE条件扫描过的所有索引记录，而且会锁定相邻的键值，即所谓的next-key locking。 当两个事务同时执行，一个锁住了主键索引，在等待其他相关索引，另一个锁定了非主键索引，在等待主键索引，这样就会发生死锁。 发生死锁后，InnoDB一般都可以检测到，并使一个事务释放锁回退，另一个获取锁完成事务。 ","link":"https://ninglg.com/post/mysql-lock/"},{"title":"有关Linux的一些内容","content":"有关Linux的一些内容。 用户态和内核态 系统调用 统调用组成了用户态跟内核态交互的基本接口。 为什么要区分用户态与内核态 在 CPU 的所有指令中，有一些指令是非常危险的，如果错用将导致整个系统崩溃。 CPU 将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通的应用程序只能使用那些不会造成灾难的指令。 Intel 的 CPU 将特权级别分为4个级别： RING0(特权级最高)、 RING1 、 RING2 、 RING3 。 处理器总处于以下状态中的一种 内核态，运行于进程上下文，内核代表进程运行于内核空间。 内核态，运行于中断上下文，内核代表硬件运行于内核空间。 用户态，运行于用户空间。 从用户态切换到内核态可以通过三种方式 系统调用 异常 外设中断 内存管理中的一些常见问题 未能释放已经不再使用的内存 - 内存泄漏 指向不可用的内存指针 - 野指针 指针所指向的对象已经被回收了，但是指向该对象的指针仍旧指向已经回收的内存地址 - 悬挂指针 分配或释放内存太快或者太慢 分配内存大小不合理，内存碎片问题 ","link":"https://ninglg.com/post/linux-about-tech/"},{"title":"nginx配置项说明","content":"此篇介绍一下 Nginx 服务的配置相关内容 规则 nginx命令 命令 含义 nginx -s stop/reload/quit 停止/重新加载配置文件/平滑停止Nginx服务 nginx -t 测试配置文件是否正确 nginx -v 显示 Nginx 版本信息 nginx -V 显示 Nginx 版本信息、编译器和配置参数的配置 proxy_pass 配置反向代理的路径。 需要注意的是如果 proxy_pass 的 url 最后为 /，则表示绝对路径，否则（不含变量下）表示相对路径，所有的路径都会被代理过去。 upstream 配置负载均衡，upstream 默认是以轮询的方式进行负载，另外还支持四种模式，分别是： weight：权重，指定轮询的概率，weight 与访问概率成正比 ip_hash：按照访问 IP 的 hash 结果值分配 fair：按后端服务器响应时间进行分配，响应时间越短优先级别越高 url_hash：按照访问 URL 的 hash 结果值分配 Location优先级 表达式 含义 ~ 执行一个正则匹配，区分大小写 ~* 执行一个正则匹配，不区分大小写 ^~ 普通字符匹配。使用前缀匹配。如果匹配成功，则不再匹配其他location。 = 进行普通字符精确匹配。也就是完全匹配 优先级和在nginx配置中location的顺序没有太大关系，而与location表达式的类型有关。相同类型的表达式，字符串长的会优先匹配。 1. 等号类型（=）的优先级最高。一旦匹配成功，则不再查找其他匹配项。 2. ^~类型表达式。一旦匹配成功，则不再查找其他匹配项。 3. 正则表达式类型（~、~*）的优先级次之。如果有多个location的正则能匹配的话，则使用正则表达式最长的那个。 4. 常规字符串匹配类型，按前缀匹配。 示例 user nobody; #配置用户或者组，默认为nobody nobody worker_processes 4; #允许生成的进程数，默认为1 worker_cpu_affinity 00000001 00000010 00000100 00001000; #为每个进程分配一个CPU worker_rlimit_nofile 102400; #为nginx工作进程改变打开最多文件描述符数目的限制。用来在不重启主进程的情况下增加限制。 error_log logs/error.log; error_log logs/error.log notice; error_log logs/error.log info; #指定日志路径，级别。这个设置可以放入全局块，http块，server块，级别依次为：debug|info|notice|warn|error|crit|alert|emerg pid logs/nginx.pid; #指定nginx进程运行文件存放地址 events { accept_mutex on; #设置网路连接序列化，防止惊群现象发生，默认为on multi_accept on; #设置一个进程是否同时接受多个网络连接，默认为off use epoll; #使用epoll（linux2.6的高性能方式）事件驱动模型，select|poll|kqueue|epoll|resig|/dev/poll|eventport worker_connections 102400; #最大连接数，默认为512 } http { include mime.types; #文件扩展名与文件类型映射表 default_type application/octet-stream; #默认文件类型，默认为text/plain lua_package_path &quot;/usr/local/lib/lua/?.lua;;&quot;; #lua库位置 charset utf-8; #字符集 server_names_hash_bucket_size 128; # 保存服务器名字的hash表 client_header_buffer_size 4k; #用来缓存请求头信息的，容量4K，如果header头信息请求超过了且没有配置client_header_buffer_size，nginx会直接返回400错误 large_client_header_buffers 4 32k; #如果large_buffer还是无法容纳，那么就会返回414（处理request_line）/400（处理request_header）错误 client_max_body_size 300m; #允许客户端请求的最大单文件字节数 tcp_nodelay on; #提高数据的实时响应性 client_body_buffer_size 512k; #缓冲区代理缓冲用户端请求的最大字节数（请求多） proxy_connect_timeout 5s; #nginx跟后端服务器连接超时时间（代理连接超时） proxy_read_timeout 60s; #连接成功后，后端服务器响应时间(代理接收超时) proxy_send_timeout 5s; #后端服务器数据回传时间(代理发送超时) proxy_buffer_size 16k; #设置代理服务器（nginx）保存用户头信息的缓冲区大小 proxy_buffers 4 64k; #该指令设置缓冲区的大小和数量,从被代理的后端服务器取得的响应内容,会放置到这里 proxy_busy_buffers_size 128k; #所有处在busy状态的buffer size加起来不能超过proxy_busy_buffers_size proxy_temp_file_write_size 128k; #如果response的内容很大的话，Nginx会接收并把他们写入到temp_file里去。busy的buffer传输完了会从temp_file里面接着读数据，直到传输完毕 gzip on; #NGINX可以压缩静态资源 gzip_min_length 1k; gzip_buffers 4 16k; gzip_http_version 1.1; gzip_comp_level 2; #压缩级别大小，最小1，最大9，值越小，压缩后比例越小，CPU处理更快; 值越大压缩后占用带宽越少。 gzip_types text/plain application/x-javascript text/css application/xml; #压缩类型:text js css xml 都会被压缩 gzip_vary on; #作用是在http响应中增加一行，目的是改变反向代理服务器的缓存策略 log_format main '$remote_addr - remoteuser[remote_user [remoteu​ser[time_local] &quot;$request&quot; ' '$status bodybytessent&quot;body_bytes_sent &quot;bodyb​ytess​ent&quot;http_referer&quot; ' '&quot;httpuseragent&quot;&quot;http_user_agent&quot; &quot;httpu​sera​gent&quot;&quot;http_x_forwarded_for&quot;'; access_log logs/access.log main; access_log off; #取消服务日志 日志格式 ip 远程用户 当地时间 请求URL 状态 发送的大小 响应的头 客户端使用的浏览器 页面响应的时间 log_format myFormat 'remoteaddr–remote_addr–remotea​ddr–remote_user [$time_local] $request $status $body_bytes_sent $http_referer $http_user_agent $request_time $http_x_forwarded_for'; #自定义格式 access_log logs/access.log myFormat; #combined为日志格式的默认值 sendfile on; #允许sendfile方式传输文件，默认为off，可以在http块，server块，location块 sendfile_max_chunk 100k; #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限 tcp_nopush on; tcp_nopush on; #防止网络阻塞 keepalive_timeout 0; keepalive_timeout 65; #连接超时时间，默认为75s，可以在http，server，location块 gzip on; 上游服务器 upstream mysvr { 负载均衡算法，默认为round-robin轮循 ip_hash; #每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session的问题,ip_hash不支持weight和backup server 192.168.5.91:7878 max_fails=2 fail_timeout=10s; server 192.168.5.92:7878 max_fails=2 fail_timeout=10s; server 192.168.5.91:7878 max_fails=2 fail_timeout=10s weight=1; server 192.168.5.92:7878 max_fails=2 fail_timeout=10s weight=2; server 192.168.5.90:7878 backup; #热备 } error_page 404 https://www.baidu.com; #错误页 server { keepalive_requests 120; #单连接请求上限次数 listen 9080; #监听端口 server_name localhost; #监听地址 127.0.0.1 charset koi8-r; access_log logs/host.access.log main; location ~*^.+$ { #请求的url过滤，正则匹配，为区分大小写，*为不区分大小写。 root path; #根目录 index vv.txt; #设置默认页 proxy_pass http://mysvr; #请求转向mysvr 定义的服务器列表 deny 127.0.0.1; #拒绝的ip allow 172.18.5.54; #允许的ip } location /test { proxy_next_upstream http_502 http_504 error timeout invalid_header; proxy_next_upstream_timeout 10s; proxy_next_upstream_tries 2; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; add_header upstream_addr $upstream_addr; proxy_pass http://mysvr; } nginx主页 location / { root html; index index.html index.htm; } 用lua脚本向reids存值 location /lua/set { default_type 'text/plain'; content_by_lua_file conf/lua/setKeyValue.lua; } 用lua脚本从reids取值 location /lua/get { default_type 'text/plain'; content_by_lua_file conf/lua/getKey.lua; } 静态资源代理 location ~ .*.(html|htm|gif|jpg|jpeg|bmp|png|ico|txt|js|css)$ { root /var/local/static; expires 30d; } error_page 404 /404.html; redirect server error pages to the static page /50x.html error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } ","link":"https://ninglg.com/post/nginx-setting/"},{"title":"常见HTTP状态码","content":"此篇介绍一下常见的HTTP状态码。 HTTP/1.1 协议中定义了5类状态码，状态码由3位数字组成，第一个数字定义了响应的类别。 1xx：提示信息 2xx：成功 3xx：重定向 4xx：客户端错误 5xx：服务器错误 状态码 含义 备注 1xx 临时响应 表示临时响应并需要请求者继续执行操作的状态代码 100 继续 客户端应继续其请求 2xx 成功 表示成功的处理了请求 200 请求成功 204 请求收到，但返回信息为空 3xx 重定向 表示要完成请求，需要进一步操作，通常是重定向 301 Moved Permanently 资源被永久转移 302 Moved Temporarily 资源被临时转移 304 Not Modified 告诉客户端使用缓存资源即可，因为服务器上的资源没有更新 403 Forbidden 服务器已经理解请求，但因授权问题无访问权限，拒绝执行 404 Not Found 资源不存在 405 Method Not Allowed 此请求方法不能被用于请求相应的资源，该响应必须返回一个Allow 头信息用以列出当前资源能够接受的请求方法的列表 408 Request Timeout 请求超时。客户端没有在服务器预备等待的时间内完成一个请求的发送，服务器想要将没有在使用的连接关闭。客户端可以随时再次提交这一请求而无需进行任何更改。一些服务器也会在空闲连接上发送此信息，即便是在客户端没有发送任何请求的情况下。 500 Internal Server Error 服务器内部错误 502 Bad Gateway 网关错误。可能是网关与upstream机器连接出现问题，或者从上游服务器接收到无效的响应 504 Gateway Timeout 充当网关或代理的服务器超时，未能及时从上游服务器（URI标识出的服务器，例如HTTP、FTP、LDAP）或者辅助服务器（例如DNS）收到响应 ","link":"https://ninglg.com/post/http-status-code/"},{"title":"网关介绍","content":"关于网关知识的一些介绍：高防、网关、负载均衡等。 网关Gateway 规则 基于策略的NAT规则（DNAT）及管理请求的访问控制（ACL） 服务器负载均衡（SLB） 反向代理（R-Proxy） WEB防火墙（WAF） 入侵检测与防御（IDP） 抗SYN洪水攻击 ","link":"https://ninglg.com/post/gateway-intro/"},{"title":"Nginx的状态页status详解","content":"此篇介绍一下Nginx服务的状态页status相关内容。 Nginx 内建了一个状态页，对于了解 Nginx 的状态以及监控 Nginx 非常有用。 启用状态页 修改Nginx配置文件/usr/local/etc/nginx/nginx.conf，增加 location /status { stub_status on; access_log off; } 重启Nginx服务使状态页生效 brew services restart nginx 状态页信息详解 访问 http://127.0.0.1:8080/status 看到 Active connections: 2 server accepts handled requests 5 5 8 Reading: 0 Writing: 1 Waiting: 1 条目 含义 active connections 活跃的连接数量 server accepts handled requests 共处理了5个连接 , 成功创建5次握手, 总共处理了8个请求 reading 读取客户端的连接数. writing 响应数据到客户端的数量 waiting 开启 keep-alive 的情况下,这个值等于 active – (reading+writing), 意思就是 Nginx 已经处理完正在等候下一次请求指令的存活连接 ","link":"https://ninglg.com/post/nginx-status-intro/"},{"title":"什么是线程安全","content":"此篇介绍一下线程安全的概念。 线程安全是多线程编程时的计算机程序代码中的一个概念。 当多个线程访问同一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替运行，也不需要进行额外的同步，或者在调用方进行任何其他的协调操作，调用这个对象的行为都可以获取正确的结果，那这个对象是线程安全的。 ","link":"https://ninglg.com/post/what-is-thread-safety/"},{"title":"Linux进程间的通信机制","content":"Linux进程间的通信机制 进程间的通信机制（IPC，InterProcess Communication）有以下几种： 1. 管道 Pipe 半双工，数据单向流动，进程间关系一般是父子进程。 无名管道pipe 命名管道（有名管道） named pipe：允许无亲缘关系的进程通信 2. 消息队列 Message Queue 3. 信号量 Semophore 计数器，常作为锁机制。 4. 共享内存 Shared Memory 共享内存是最快的进程间通信方式。 5. 套接字 Socket 6. 信号 Signal 用于通知接收进程某个事件已经发生。 ","link":"https://ninglg.com/post/linux-process-communication/"},{"title":"CPU上下文切换的概念","content":"此篇介绍一下有关CPU上下文切换的内容。 ","link":"https://ninglg.com/post/cpu-context-switch-intro/"},{"title":"数据结构：二叉树","content":"数据结构：二叉树 二叉树的特点 二叉树中每个节点最多有两棵子树，称为左子树、右子树； 左子树和右子树是有顺序的，有左右之分，次序不能随意颠倒； 即使某个节点只有一个子树，也要区分左右子树。 即：最多两棵树，还要分左右。 完全二叉树：只有底层没满，且按顺序排列在左边的二叉树。 满二叉树：所有节点都满了的二叉树 二叉搜索树：节点分大小，左边&gt;中间&gt;右边。 平衡二叉树：左右子树的高度差最大为1。 平衡二叉搜索树：集合二叉搜索树和平衡二叉树两者特点的树，比如AVL树。 二叉树的存储 type TreeNode struct { Val int Left *TreeNode Right *TreeNode } 树的遍历 前序遍历 前序遍历-递归 func preOrder(t *TreeNode) { if t == nil { return } fmt.Println(t.Val) preOrder(t.Left) preOrder(t.Right) } 前序遍历-非递归 中序遍历 中序遍历-递归 func inOrder(t *TreeNode) { if t == nil { return } inOrder(t.Left) fmt.Println(t.Val) inOrder(t.Right) } 中序遍历-非递归 // 使用栈来记录树上的节点，栈顶的节点即是当前访问的节点 后序遍历 后序遍历-递归 func postOrder(t *TreeNode) { if t == nil { return } postOrder(t.Left) postOrder(t.Right) fmt.Println(t.Val) } 后序遍历-非递归 DFS和BFS搜索 广度优先搜索（Breath First Search，BFS，又称层序遍历。一般采用队列进行遍历辅助。） func bfs(p *TreeNode) []int { res := make([]int, 0) if p == nil { return res } // BFS需要使用一个 **队列** 协助，此处用slice模拟队列 queue := []*TreeNode{p} for len(queue) &gt; 0 { //每一轮是不同层 length := len(queue) for length &gt; 0 { // 同层遍历 length-- if queue[0].Left != nil { queue = append(queue, queue[0].Left) } if queue[0].Right != nil { queue = append(queue, queue[0].Right) } res = append(res, queue[0].Val) queue = queue[1:] } } return res } 深度优先搜索（Depth First Search，DFS。一般采用栈进行遍历辅助，可用递归来实现栈。） func DFS(root *TreeNode) []int { if root == nil { return } var res []int res = append(res, root.Val) DFS(root.Left) DFS(root.Right) return res } 计算二叉树的节点个数 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func countNodes(root *TreeNode) int { if root == nil { return 0 } return countNodes(root.Left) + countNodes(root.Right) + 1 } 计算二叉树的深度 func maxDepth(root *TreeNode) int { if root == nil { return 0 } return 1 + max(maxDepth(root.Left), maxDepth(root.Right)) } func max(x,y int) int { if x &gt; y { return x } return y } 平衡二叉树 判断一棵二叉树是否是平衡二叉树 func isBalanced(root *TreeNode) bool { if root == nil { return true } leftHeight := height(root.Left) rightHeight := height(root.Right) if leftHeight-rightHeight &lt; -1 || leftHeight-rightHeight &gt; 1 { return false } return isBalanced(root.Left) &amp;&amp; isBalanced(root.Right) } func height(node *TreeNode) int { if node == nil { return 0 } return 1 + max(height(node.Left), height(node.Right)) } func max(a, b int) int { if a &gt; b { return a } return b } 合并两个二叉树 func mergeTrees(root1 *TreeNode, root2 *TreeNode) *TreeNode { if root1 == nil &amp;&amp; root2 == nil { return nil } else if root1 == nil { return root2 } else if root2 == nil { return root1 } else { root1.Val += root2.Val root1.Left = mergeTrees(root1.Left, root2.Left) root1.Right = mergeTrees(root1.Right, root2.Right) return root1 } } 反转二叉树 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func invertTree(root *TreeNode) *TreeNode { if root == nil { return nil } left := invertTree(root.Left) right := invertTree(root.Right) root.Left = right root.Right = left return root } 判断两棵二叉树是否相同 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func isSameTree(p *TreeNode, q *TreeNode) bool { if (p == nil) &amp;&amp; (q == nil) { return true } if (p == nil) || (q == nil) { return false } if p.Val != q.Val { return false } return isSameTree(p.Left, q.Left) &amp;&amp; isSameTree(p.Right, q.Right) } 打印二叉树的所有路径 输入：root = [1,2,3,null,5] 输出：[&quot;1-&gt;2-&gt;5&quot;,&quot;1-&gt;3&quot;] /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ var paths []string func binaryTreePaths(root *TreeNode) []string { paths = []string{} constructPaths(root, &quot;&quot;) return paths } func constructPaths(root *TreeNode, path string) { if root != nil { pathSB := path pathSB += strconv.Itoa(root.Val) if root.Left == nil &amp;&amp; root.Right == nil { paths = append(paths, pathSB) } else { pathSB += &quot;-&gt;&quot; constructPaths(root.Left, pathSB) constructPaths(root.Right, pathSB) } } } 计算二叉树的最小深度 最小深度是从根节点到最近叶子节点的最短路径上的节点数量。 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func minDepth(root *TreeNode) int { if root == nil { return 0 } if root.Left == nil { return minDepth(root.Right) + 1 } if root.Right == nil { return minDepth(root.Left) + 1 } return min(minDepth(root.Left), minDepth(root.Right)) + 1 } func min(a, b int) int { if a &lt; b { return a } return b } 二叉树的最近公共祖先 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func lowestCommonAncestor(root, p, q *TreeNode) *TreeNode { if root == nil { return nil } if root.Val == p.Val || root.Val == q.Val { return root } left := lowestCommonAncestor(root.Left, p, q) right := lowestCommonAncestor(root.Right, p, q) if left != nil &amp;&amp; right != nil { return root } if left == nil { return right } return left } 判断是否是轴对称的对称二叉树 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func isSymmetric(root *TreeNode) bool { if root == nil { return true } return compare(root.Left, root.Right) } func compare(node1 *TreeNode, node2 *TreeNode) bool { if node1 == nil &amp;&amp; node2 == nil { return true } if node1 == nil || node2 == nil { return false } if node1.Val != node2.Val { return false } return compare(node1.Left, node2.Right) &amp;&amp; compare(node1.Right, node2.Left) } 二分搜索树（BST，Binary Search Tree） 二分搜索树也是一种二叉树，但二分搜索树种每个节点的值都要大于其左子树所有节点的值，小于其右子树所有节点的值； 每一棵子树也是二分搜索树。 验证是否是二叉搜索树 /** * Definition for a binary tree node. * type TreeNode struct { * Val int * Left *TreeNode * Right *TreeNode * } */ func isValidBST(root *TreeNode) bool { if root == nil{ return true } var stack []*TreeNode cur := root var prev *TreeNode for len(stack)&gt;0 || cur!=nil{ if cur!=nil{ stack = append(stack,cur) cur = cur.Left }else{ cur = stack[len(stack)-1] stack = stack[:len(stack)-1] if prev!=nil &amp;&amp;prev.Val &gt;= cur.Val{ return false } prev = cur cur = cur.Right } } return true } 平衡二叉树（AVL树、红黑树） 线段树 Trie树（又称字典树或前缀树） ","link":"https://ninglg.com/post/binary-tree-intro/"},{"title":"sed命令使用","content":"介绍一下sed命令的常见用法。 sed使用示例 sed -n '1,4 p' file.txt -n：是--quiet或者--silent的意思，表明忽略执行过程的输出，只输出结果 -i：使用此参数后，所有改动将在原文件上执行，输出将覆盖原文件 1,4 表示找到文件中1,2,3,4行的内容。 5 选择第5行。 2,5 选择2到5行，共4行。 1~2 选择奇数行。 2~2 选择偶数行。 2,+3 和2,5的效果是一样的，共4行。 2,$ 从第二行到文件结尾。 替换模式 sed -i 's/Search_String/Replacement_String/g' Input_File //原地全局替换 sed 's/unix/linux/' sed-test.txt //仅替换第1个出现的 sed 's/unix/linux/2' sed-test.txt //替换第2个出现的 sed 's/unix/linux/2g' sed-test.txt //替换从第2个开始出现的所有 sed '3 s/unix/linux/' sed-test.txt //仅替换第三行的 sed '1,3 s/unix/linux/' sed-test.txt //在第一行到第三行进行查找替换 sed '$ s/Linux/Unix/' sed-test.txt //只在最后一行进行替换 sed 's/unix/linux/gI' sed-test.txt //不区分大小写的替换 sed 's/[0-9]/number/g' sed-test.txt //替换掉所有数字 sed -n 's/Unix/Linux/p' sed-test.txt //显示仅更改的行 sed -e 's/linuxunix/LINUXUNIX/g' -e 's/CentOS/RHEL8/g' sed-test.txt //同时运行多个sed命令 ","link":"https://ninglg.com/post/sed-command-usage/"},{"title":"数据结构：链表","content":"数据结构：单链表 链表的结构定义 单链表 /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ 从尾到头打印链表 使用递归的方法 func reversePrint(head *ListNode) []int { if head == nil { return nil } return appendData(head) } func appendData(head *ListNode) []int { if head.Next != nil{ list := appendData(head.Next) list = append(list, head.Val) return list } return []int{head.Val} } 使用栈进行辅助的方法 import &quot;container/list&quot; func reversePrint(head *ListNode) []int { if head == nil { return nil } res := list.New() for head != nil { res.PushFront(head.Val) head = head.Next } ret := []int{} for e := res.Front(); e != nil; e = e.Next() { ret = append(ret, e.Value.(int)) } return ret } 反转单链表 /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func reverseList(head *ListNode) *ListNode { if head == nil || head.Next == nil { return head } var prev *ListNode cur := head for cur != nil { cur.Next, prev, cur = prev, cur, cur.Next } return prev } 合并两个有序链表 /** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func mergeTwoLists(list1 *ListNode, list2 *ListNode) *ListNode { if list1 == nil { return list2 } if list2 == nil { return list1 } if list1.Val &gt; list2.Val { list2.Next = mergeTwoLists(list1, list2.Next) return list2 } else { list1.Next = mergeTwoLists(list1.Next, list2) return list1 } } ","link":"https://ninglg.com/post/linked-list-intro/"},{"title":"IP、端口和通信检查","content":"检查IP和端口是否通信 检查IP地址 ping [ip] 检查端口 telnet [ip] [port] nc -v [ip] [port] 常用网络端口 端口号的范围是从 0 到 65535，分为三个子范围： 1. 知名端口 0 ~ 1023 在Linux系统上，只有以root身份运行的特权程序才可以使用1024以下的端口。 2. 注册端口 1024 ~ 49151 3. 动态端口 49152 ~ 65535 常用端口号 端口号 服务 21 FTP 22 SSH 23 Telnet 25 SMTP 53 DNS 67,68 DHCP 80 HTTP 110 POP3 111 Portmap 137 NetBIOS 143 IMAP 161,162 SNMP 443 HTTPS 587 SMTP 993 IMAPS ","link":"https://ninglg.com/post/check-ip-port-signal/"},{"title":"浏览器的一次网络请求流程","content":"介绍一下在浏览器里完成一次网络请求的流程步骤。 当在浏览器里输入一行网址，并按下回车执行之后，会经过以下几个流程： 1. DNS解析 将域名解析成IP地址。 2. TCP连接 TCP三次握手，建立TCP连接。 3. HTTP请求 发送HTTP请求并获取数据结果。 4. 构建DOM树 使用HTML字符串构建DOM树。 5. 构建CSSOM树 使用CSS字符串构建CSSOM树。 6. 合成并绘制 使用DOM+CSSOM进行渲染，合成并绘制结果。 ","link":"https://ninglg.com/post/web-browser-do-http-request/"},{"title":"数据结构：图","content":"数据结构：图 概念 图是由点和边构成，用来描述网状关系。 网状没有顺序，也没有层次。 有向图：图的边有箭头方向，单向。 无向图：图的边没有方向，双向。 图由 顶点集合+边集合 进行描述，如果一个图A的顶点和边集合均是另一个图B的子集，那么A就是B的子图。 顶点的度：无向图中连着顶点的边的数目。 顶点的入度和出度：有向图中，以这个顶点为起点的边的数量称为这个顶点的出度，否则为入度。 图的存储 邻接矩阵 边集数组 邻接表 图的遍历 深度优先遍历 广度优先遍历 ","link":"https://ninglg.com/post/graph-intro/"},{"title":"交换机和路由器的区别","content":"介绍一下交换机和路由器的内容。 中继系统 将网络设备互相连接起来的中间设备，称为中继（relay）系统。 根据中继系统所在的层次，分为以下5种： （1）物理层：转发器 （2）数据链路层：网桥、桥接器（bridge） （3）网络层：路由器（router） （4）混合桥路器（brouter）：兼具网桥和路由器的功能 （5）网关：gateway 一般讨论网络互连时，都是使用交换机和路由器进行互连的网络。 交换机 交换机大多是二层网络设备，少部分是三层交换机。 交换机将数据帧从一个端口转发到另一个端口。 路由器 路由器是三层网络设备。 路由器的基本功能是把IP报文传送到正确的网络。 ","link":"https://ninglg.com/post/switch-router-difference/"},{"title":"设计模式","content":"设计模式 设计模式是一套可提高代码重用性的理论。 简单工厂（Simple Factory） 有一个工厂，可以根据传入的不同参数，生产不同的商品 ","link":"https://ninglg.com/post/design-pattern/"},{"title":"数据结构：堆","content":"数据结构：堆 堆的基础概念 堆的实质其实是二叉树 这棵二叉树除了叶子之外的所有节点都是“满”的 最后一层叶子节点也是有要求的，要求叶子节点都靠左对齐 满足这些条件的二叉树称为完全二叉树（complete binary tree） 堆是完全二叉树，但不是所有的完全二叉树都是堆，堆还有一个特殊的性质，就是大小的传递性 堆根据大小传递性的不同分为 大顶堆 和 小顶堆 大顶堆就是堆顶的元素也就是树根的元素是最大的。如果是小顶堆则相反，堆顶元素是最小的 传递性很好理解，就是所有节点的值大于/小于它两个孩子的值 堆的巧妙点在于，可以用数组来存储这个结构，而不需要自己建树 所谓建堆的过程，其实就是将元素一个一个插入堆当中的过程 堆和其他数据结构不同，它对于数据的查询非常有限，只允许查询堆顶的元素 同样也只允许删除堆顶的元素，删除堆顶的元素称为“弹出”（pop） ","link":"https://ninglg.com/post/heap-intro/"},{"title":"常见内网IP段","content":"此篇介绍一下常见的内网IP段。 常见的内网IP段有： 类别 段 区间 A类 10.0.0.0/8 10.0.0.0 - 10.255.255.255 B类 172.16.0.0/12 172.16.0.0 - 172.31.255.255 C类 192.168.0.0/16 192.168.0.0 - 192.168.255.255 除以上常见内网IP段外，还有其它保留IP地址，可参见：维基百科 - 保留IP地址列表 ","link":"https://ninglg.com/post/reserved-intranet-ip-addresses/"},{"title":"字节序：大端和小端","content":"此篇介绍一下字节序的概念。 字节序 字节序是指多字节数据在计算机内存中存储或者网络传输时各字节的存储顺序。 小端（Little-endian，小头） 将 低位字节 存储在起始地址(低地址)。 大端(Big-endian，大头) 将 高位字节 存储在起始地址(低地址)。 即看低地址存储什么样的字节。 举例 Intel系列通常是小头字节序，Arm体系通常是大头序列。 Java平台二进制读写一律采用大头字节序，网络上数据传输也都采用大头字节序。 C++不跨平台，所以它的大小头依赖于系统架构。 网络上通常采用 大头字节序 ，所以大头字节序又叫 网络字节序。 intel占据大量PC，都采用 小头字节序 ，所以小头字节序又叫 主机字节序。 字节序按应用场景也分两种，一是网络字节序，二是主机字节序。网络字节序为大端字节序，是确定的。主机字节序由 CPU 架构确定，可能是小端，也可能是大端，一般使用的 Intel 与 AMD 的 CPU 均为小端字节序。 Go判断大小端 package main import ( &quot;fmt&quot; &quot;unsafe&quot; ) func IsLittleEndian() bool { n := 0x1234 f := *((*byte)(unsafe.Pointer(&amp;n))) return (f ^ 0x34) == 0 } func main() { fmt.Println(IsLittleEndian()) } 注：Golang 是强类型语言，不允许不同类型的指针之间进行强制转化，因此需要借助 unsafe.Pointer 进行一次中转。 ","link":"https://ninglg.com/post/byte-order-big-endian-little-endian/"},{"title":"Chrome浏览器开发者工具","content":"此篇介绍一下Chrome浏览器开发者工具的使用。 打开开发者工具 在Mac系统上使用 command+option+i 快捷键，可以打开开发者工具。 ","link":"https://ninglg.com/post/chrome-browser-dev-tool/"},{"title":"Linux Shell命令技巧","content":"此篇介绍一下Shell命令相关的内容。 $0、$1、2、2、2、#、@、@、@、*、$? 首先介绍一下 $0、$1、2、2、2、#、@、@、@、*、$? 的含义。 比如执行以下命令： /bin/test.sh a b c 命令 含义 备注 $0 表示文件路径和文件名 /bin/test.sh $1、$2 表示第几个参数 如a、b，但如第10个要用${10}而非$10，10相当于10相当于10相当于{1}0 $# 表示传入脚本的参数个数 此处为3，统计不包括$0 $@ 表示所有参数的列表 此处&quot;a&quot;、&quot;b&quot;、&quot;c&quot;，不包括$0 $* 表示所有的参数 其值和 $@ 相同，但区别在于 $* 把所有参数合并成一个字符串，而 $@ 会得到一个字符串参数数组 $? 表示执行脚本命令后的返回值 命令执行成功时默认返回0 示例： #!/bin/sh for x in &quot;$@&quot;; do echo $x done for x in &quot;$*&quot;; do echo $x done 执行 /bin/test.sh a b c 后输出： a b c a b c &amp; 和 wait &amp; 当要执行的命令以 &amp; 结尾时，这个命令会在后台子 shell 执行 wait 当有多个耗时操作可以并发执行，且这些操作都执行完成后，再进行下一步操作，就可以使用 wait 命令来等待这些操作执行完成 例如： command1 &amp; command2 &amp; wait ","link":"https://ninglg.com/post/linux-shell-command-tips/"},{"title":"Mac地址学习的概念","content":"此篇介绍一下Mac地址学习的概念。 Mac地址 在OSI七层网络模型中，Mac地址是数据链路层的标识符。 Mac地址共有48个bit，一般使用16进制进行表示。 源Mac和目的Mac 在一个以太网报文中，有两个Mac地址：源Mac、目的Mac。 交换机在收到报文之后，会将源Mac地址记录在Mac地址表项（Mac Address Table）中，同时根据目的Mac查找出对外交换机接口。 如果找到了出去的交换机接口，则报文会从此接口进行转发出去。 泛洪 如果交换机收到的报文，在Mac地址表项中找不到目的Mac对应的表项怎么办？ 此时，报文将会在同一个VLAN中进行泛洪。 ","link":"https://ninglg.com/post/mac-address-learning-intro/"},{"title":"使用supervisor来守护运行的程序","content":"此篇介绍一下使用supervisor来守护正在运行中的程序。 官网 supervisor 简介 supervisor 是一个使用Python开发的守护程序，它可以对单台机器上的程序进行启停管理、自动重启等。 安装启动 brew install supervisor 安装后会生成两个可执行程序： supervisortd：守护进程服务 supervisorctl：客户端，用于命令行交互 启动 放到后台一直启动： brew services start supervisor 根据配置文件单次启动： supervisord -c /usr/local/etc/supervisord.ini 使用示例 例如使用Supervisor守护进程来配置Redis： 配置守护进程文件，在/etc/supervisord.d/ 下新建 redis.conf vi /etc/supervisord.d/redis.conf 添加以下内容 # 新建一个应用并设置一个名称，这里设置为 redis [program:redis] # 设置命令在指定的目录内执行 directory=/usr/local/redis/bin # 这里为您要管理的项目的启动命令 command=/usr/local/redis/bin/redis-server # 以哪个用户来运行该进程 user=root # supervisor 启动时自动该应用 autostart=true # 进程退出后自动重启进程 autorestart=true # 进程持续运行多久才认为是启动成功 startsecs=1 # 重试次数 startretries=3 # stderr日志输出位置 stderr_logfile=/soft/logs/redis/stderr.log # stdout 日志输出位置 stdout_logfile=/soft/logs/redis/stdout.log 新建日志文件夹 mkdir -p /soft/log/redis/ 更新重启所有Supervisor配置的任务 supervisorctl reload 只启动更新过配置的任务 supervisorctl update [job_name] 单独停止或启动某个任务 supervisorctl [start | stop | restart | status ] [job_name] 查看Supervisor状态，redis是否被添加 supervisorctl status ","link":"https://ninglg.com/post/supervisor-protect-program/"},{"title":"《软技能-代码之外的生存指南》阅读笔记","content":"《软技能-代码之外的生存指南》阅读笔记 首先，要有一个产品或服务 企业需要持续不断的改进和完善自己的产品 仅有服务或产品是不够的。想赚到钱，你就必须能让潜在的客户了解该产品或服务。全世界的公司都认识到了商业社会的这一核心真理，这也是他们在市场营销上投入重金和精力的原因。 市场营销做得越好，你就能给服务定越高的价格，也越有机会吸引更多潜在的客户。 大多数成功的公司都会开发出让客户主动上门购买的产品或服务，它们才不会一个接一个的追逐客户。 营销部 ","link":"https://ninglg.com/post/live-soft-skills-other-than-code-reading/"},{"title":"《富爸爸穷爸爸》阅读笔记","content":"《富爸爸穷爸爸》阅读笔记 序言 这就是你所需要的 第一部分 课程 第1章 富爸爸，穷爸爸 第2章 第一课富人不为钱工作 第3章 第二课为什么要教授财务知识 第4章 第三课关注自己的事业 第5章 第四课税收的历史和公司的力量 第6章 第五课富人的投资 第7章 第六课学会不为钱工作 第二部分 开端 第8章 克服困难 第三部分 开始行动 第9章 开始行动 收支平衡表 + 资产负债表 资产就是能把钱放入你口袋里的东西，负债就是把钱从你口袋里取走的东西。 恐惧把你推出门外，愿望又召唤你过去，诱惑你去触礁，这就是陷阱。 一个人一旦停止寻求知识和信息，就会变得无知。因此，人们需要不停地与自己作斗争，是通过学习打开自己的心扉，还是封闭自己的头脑。 聪明人总是雇佣比他更聪明的人。 激情正是愤怒和热爱的产物。 读书的重要性，加上掌握财务知识 我们开始明白为什么富爸爸说学校是生产好雇员而不是好雇主的地方。 恐惧和欲望，使你落入一生中最大的陷阱。如果你让他们来控制自己的思想，你的一生就会生活在恐惧中，从不探求你的梦想，这是残酷的。为钱工作，以为钱能买来快乐，这也是残酷的。半夜醒来想着许多的账单要付是一种可怕地生活方式，以工资的高低来安排生活不是真正的生活。别让这些问题在你们身上发生，别让钱支配你们的生活。 学会让感情跟随你的思想，而不要让思想跟着你的感情。 记住我以前所说的：工作只是面对长期问题的一种暂时的解决办法。 我想太多的人仍然过多的关注钱，而不是他们最大的财富——所受的教育。如果人们灵活一些，保持开放的头脑并不断的学习，他们将在这些变化中一天比一天富有。 知识才能解决问题并创造财富，不是凭财务知识挣来的钱很快就会消失。 富人获得资产，而穷人和中产阶级获得债务，只不过他们以为那些就是资产。 害怕被排斥的心理，使人们服从而不去质疑那些被广泛接受的观点或流行的趋势。 大多数人的财务困境是由于随大流，简单的跟从其他人所造成的。因此我们都需要不时地照照镜子，去相信我们内在的智慧而不仅只是恐惧。 他憎恶“我们必须这么做，因为其他人也这么做”这类的话，他也憎恶“不能”这个词。 中产阶级发现自己总是在财务问题上挣扎，原因何在呢？中产阶级的主要收入是工资，而当工资增加的时候，税收也就增加了，更重要的是他们的支出倾向也随着收入的增加而同等增加。 财富就是支持一个人生存多长时间的能力，或者说如果我今天停止工作，我还能活多久？ 富人买入资产，穷人只有支出，中产阶级买他们以为是资产的负债。 秘诀就是：关注自己的事业。许多人在停止工作后变得一无所有，因为他们没有自己的事业。 请注意，你的工作和你的事业之间存在着巨大的区别。 只有把你增加的收入用于购买可产生收入的资产时，你才能获得真正的财物安全。 大多数穷人或中产阶级财务保守的基本原因在于：“我不能承担风险”。这意味着他们的财务知识匮乏，他们必须依附于工作。 依我看，真正的资产可以分为下列几类： （1）不需我到场就可以正常运作的业务；我拥有他们，但由别人经营和管理。如果我必须在那儿工作，那它就不是我的事业而是我的职业了。 （2）股票； （3）债券； （4）共同基金； （5）产生收入的房地产； （6）票据（借据）； （7）专利权如音乐、手稿、专利； （8）任何其它有价值、可产生收入或可能增值并且有很好的流通市场的东西； 富爸爸鼓励我开始获得我所喜欢的资产，“因为你如果不爱它，就不会关心它”。如果你喜爱你所投资的对象，了解它并懂得游戏规则，风险就会减少。 当我说关注自己的事业时，我的意思是建立自己强大的资产。想想看，一旦1美元落进了你的资产项，它就成了你的雇员。 关于钱，最妙的是能让它一天24小时的工作并且为你的几代人服务。记住：做个努力工作的雇员，确保你的工作，但要不断构筑你的资产项。 在你花时间并投资建立自己的事业之后，你就准备好去接触那神奇的秘密吧——富人的最大秘密。这个秘密铺平了致富之路，路的尽头有对你付出时间和勤奋关注你自己的事业的回报。 公司雇佣的人越少，花的钱越少，就越能收到投资者的尊敬。 公司并不意味着要有刻着公司名称的大楼、厂房和雇员，它可以只是一个没有灵魂的法律实体，但富人的财富在这里得到保护。 有产者和无产者之间的争斗已经进行了几百年了，它是劫富的人与富人之间的斗争。任何时候、任何地方只要制定法律，就会发生这种斗争。斗争还会持续下去，吃亏的人一定是无知者，即那些每天起来勤奋工作并不假思索的付税的人。 他总在提醒我知识就是力量，而且钱越多，需要的知识也就越多，没有知识，世界就会牵着你走。 让钱为我工作而不是我为钱工作，这是真正的力量。 “精于计算你就不会被别人牵着转”是他给我上的最好的一课。 正是富爸爸不时地提醒，使我拥有自己公司的念头从来未曾消失，并使我走上了另一条道路。 我挣得越多，扣的也就越多，这可不是件振奋人心的事，但我可以通过努力工作跳出作为一名雇员的陷阱。 事实上，我正在不断的把工资投资于资产项，而用资产项为我生产出来的钱购买我想要的东西。 财商，财务智商，Financial I.Q. 财商是由四个方面的专门知识所构成的：第一是会计，第二是投资，第三是了解市场，第四是法律（税收优惠+在诉讼中获得保护）。 富人用公司和信托来隐藏部分财富。 雇员挣钱、纳税，并靠剩下来的东西为生；一个企业挣钱，花掉它的钱，而只对剩下来的东西缴税。这是富人钻的最大的法律的空子，如果你有能带来现金流入的投资，公司便可轻松、廉价的运营。 我们都拥有巨大的潜能，然而，问题是我们都或多或少的存在着某种自我怀疑，从而阻碍了自己的前进。阻碍我们前进的障碍很少是由于缺乏技术性信息，更多的是由于缺乏自信。 我意识到过分的畏惧和自我怀疑是浪费我们才能的最大因素。在现实世界里，人们往往是依靠勇气而不是聪明去领先于其他人的。 为什么去冒险？为什么必须不厌其烦的提高自己的财商？为什么必须懂得财务知识？——“是为了获得更多的选择机会”。 一个人为什么非要提高自己的财商呢？除了自己，没有人能回答这个问题。不过，我可以告诉你为什么我自己要这样做。原因很简单，做这些工作是我生命中最快乐的事情，我更欢迎变化而不是拥抱变化，我更喜欢能挣到数百万元的钱而不是去担心能不能获得提升。 以前，土地是一种财富，因此，谁拥有土地，谁就拥有财富。后来，美国依靠工厂和工业产品上升为世界头号强国，工业家占有了财富。今天，信息便是财富。 今天，我发现许多人在苦苦工作、苦苦挣扎，其原因就是因为他们依然固执于陈旧的观念。他们希望事情都能原封不动，他们抵制任何变化。问题的症结在于他们本身，陈旧的思想是他们最大的包袱，也可以说是最大的债务。为什么呢？原因很简答：他们没有意识到已有的某种思想或方法在昨天还是一种资产，但今天却已经变成了负债。 大部分人只知道一种方法：努力工作、储蓄或者借贷。 为什么你想提高自己的理财能力呢？因为你想成为那种能够自己创造机遇的人。你希望能坦然的接受发生的任何事情，并努力使事情变得更好。很少有人知道机遇和金钱是可以创造的。 小时候，富爸爸经常教导我和迈克：金钱不是真实的资产。穷人和中产阶级为金钱而工作，富人则创造金钱。我们唯一的、最重要的资产是我们的头脑。如果受到良好训练，转瞬间它就能创造大量财富。而一个未经训练的头脑通过教给自己的家庭不正确的生活方式，将会延续给后代极度贫困的生活。 投入到这个人们仅靠脑力而不是依靠体力来工作的时代。我想与勇者为伴，不想与后进的人为伍。 如果你清楚自己再做什么，那就不是在赌博；如果你把钱投进一笔交易然后只是祈祷，那便是在赌博。在任何情况下，成功的办法就是运用你的技术知识、智慧以及对于游戏的热爱来减少意外情况的发生并降低风险。当然，风险总是存在的，但财商可以提高你应对意外事件发生的能力。 好机会是用你的脑子而不是用你的眼睛看到的。大部分人没办法致富仅仅是因为他们没有在财务上受到训练，因为不能认识到机会其实就在他们面前。 大部分人不富有的主要原因就在于他们太担心失去。 想成为职业投资者的三种技能： （1）如何寻找到其他人都忽视的机会； （2）如何增加资金； （3）怎样把精明的人们组织起来； 风险总是无处不在，要学会驾驭风险，而不是一味回避风险； 大部分人需要学习并掌握不止一项技能，只有这样他们的收入才能获得显著增长。 富爸爸告诉我学习在危险形势下领导下属的重要性，“领导才能是你下一步迫切需要学习的”，他说，“如果你不是一个好的领导人，你就会被别人从背后射中，商业活动就像在战争中一样。” 学校没有把财商看做是一种智慧，大部分工人都“按他们的方式活着”，这些方式就是：干活挣钱，支付账单。 我劝告年轻人在寻找工作时要看看能从中学到什么，而不是只看能挣到多少。在选择某种特定的职业之前或者在陷入为生计而忙碌工作的“老鼠赛跑”之前，要仔细看看脚下的道路，弄清楚自己到底需要获得什么技能。 我总是建议他们对自己的人生要有一个长远的眼光。我承认为了金钱和生活安稳而工作是非常重要的，但我仍然主张去寻找另一份工作，以从中学到另一种技能。从长远来看，教育比金钱更有价值。 除非一个人习惯于变化，否则改变自我是十分困难的。 成功所必要的管理素质包括： （1）对现金流的管理； （2）对系统（包括你本人、时间及家庭）的管理； （3）对人员的管理； 最重要的专门技能时销售和懂得市场营销。 人们经过学习，掌握了财务知识，但在通往财务自由的道路上仍面临着许多障碍。我们知道，资产项目可以产生大量的现金流，使人们自由的过上梦想中的生活，而不必整天为了生计忙碌工作，仅掌握财务知识的人很多时候仍然不能拥有充裕的资产项目，其主要原因有五个： （1）恐惧心理； （2）愤世嫉俗； （3）懒惰； （4）不良习惯； （5）自负； 如果你讨厌冒险，对金钱损失干到担心，就早点动手积累属于你的金钱。 “没有人喜欢失败，不过如果一定要让我看到一个失败者，就让我看到一个快乐的失败者”。富爸爸说，“这就是德克萨斯人对于风险、收益和失败的态度。” 这就是他们驾驭生活的方式，他们活得很大度，不向这儿的大部分人碰到金钱问题时，因为两毛钱而抱怨不停。 人们因为太害怕失败，所以才会失败。胜利意味着不害怕失败。大部分人梦想发财，但却害怕在投资过程中损失金钱，所以他们永远不会发财。 我总是试图将每一次灾难转化成机会。 90%的美国公众财务困难的主要原因就在于他们是为了避免损失而理财，而不是为了盈利而理财。 怎样才能克服懒惰心理呢？答案是多一点点“贪婪”，要勇于去追求并得到自己所想要的生活。 我建议你采取以下十个步骤来开发上帝赐予你的才能，这种才能只有你才能控制： （1）精神的力量； （2）每天做出自己的选择：选择的力量，这是人们希望生活在一个自由国度的主要原因； （3）慎重的选择朋友：关系的力量； （4）掌握一种模式，然后再学习一种新的模式：快速学习的力量； （5）首先支付自己：自律的力量；如果你不能控制自己，就别想着能致富； （6）给你的经纪人以优厚报酬：好建议的力量； （7）做一个“印第安给与者”：无私的力量； （8）资产用来购买奢侈品：集中的力量； （9）对英雄的崇拜：神话的力量； （10）先予后取：给予的力量； 从财务上来说，我们每挣到一个美元，就得到了一次选择自己的将来是富裕、贫穷还是一般的机会。我们用钱的习惯反映了我们是什么类型的人，有的人之所以贫穷是因为他们有着不良的用钱习惯。 许多富裕家庭之所以“富不过三代”，就是因为他们没有培养出一位内行的人来管理他们的资产。 第一是时间，这是你最珍贵的资产；第二是学习，因为你没有钱，你更要去学习。 事实上我们每天都应该进行一个选择：即选择如何利用自己的时间、自己的金钱以及我们头脑里所学到的东西去实现我们的目标，这就是选择的力量。 首先投资于教育。实际上，当你还是一个穷人时，你所拥有的唯一真正的资产就是你的头脑，这是我们所控制的最强有力的工具。 我想说，在积累财富的过程中，最困难的事情莫过于坚持自己的选择而不盲目从众。因为在竞争激烈的市场上，群体有时会意味着反应迟钝而被“宰割”； 精明的投资者不会抱怨市场时机不对，如果错过了这一拨，他们就会去寻找下一个机会，并且在其中找到自己的位置。 信息得到的越早，获利的机会就越大，风险就会越小，这就是朋友的作用，这也是一种财商。 在今天这个快速变化的世界中，并不要求你去学太多的东西，因为当你学到时往往已经过时了，问题在于你学的有多快，也就是我前面说的要具备快速学习的能力，这种技能是无价之宝。 如果你想赚到钱，寻找一条捷径是非常关键的。 为金钱而工作是人类在穴居时代产生的一个公式，它早已过时了。 开创你自己的事业所必备的最重要的三种管理技能是： （1）现金流量管理； （2）人事管理； （3）个人时间管理； （1）不要背上数额过大的债务包袱，要使自己的支出保持在低水平； （2）当你资金短缺时，去承受外在压力而不要动用你的储蓄或投资，利用这种压力来激发你的财务天赋，想出新办法挣到更多的钱。 穷人有不好的习惯，一个普遍的坏习惯是随便“动用储蓄”。富人知道储蓄只能用于创造更多的钱，而不是用来支付账单。 在这个世界上有许多力量比我们所拥有的能力更强，你也许可以凭借自己的努力获得成功，但是如果有了这种力量的帮助，你就更容易成功或者取得更伟大的成功。 金钱是一种思想，如果你想要更多的钱，只需改变你的思想。 上天赐予我们每个人两样伟大的礼物：思想和时间。轮到你用这两样礼物去做你愿意做的事情了。 ","link":"https://ninglg.com/post/rich-dad-poor-dad-reading/"},{"title":"查找算法","content":"查找算法 二分查找 前提是数组有序，二分查找时间复杂度O(logN) func BinarySearch(data []int, target int) int { var low, high, mid int low, high = 0, len(data) - 1 for low &lt;= high { mid = low + (high-low)/2 //防止溢出 if data[mid] &gt; target { high = mid - 1 } else if data[mid] &lt; target { low = mid + 1 } else { return mid } } return -1 } 如果有序数组里面有重复数字，要查找重复数字的左右边界，可基于上述二分查找算法略加修改即可。 如查找左边界：return mid 处改为 high=mid-1，return -1 处改为 return low。另外需要加一段判断left越界情况的逻辑 if left &gt; len(data)-1 || data[left] != target 则return -1 TopK问题 quick select 快速选择算法 quick select 算法的主要目的是在一个没有排序的数组里面，找到第k小的元素。 快速选择的总体思路与快速排序一致，选择一个元素作为基准来对元素进行分区，将小于和大于基准的元素分在基准左边和右边的两个区域。不同的是，快速选择并不递归访问双边，而是只递归进入一边的元素中继续寻找。这降低了平均时间复杂度，从O(n log n)至O(n)，不过最坏情况仍然是O(n2)。 func quickselect(nums []int, start, end, k int) int { // use last element as pivot pivotIndex := partition(nums, start, end, end) if k-1 == pivotIndex { return nums[pivotIndex] } else if k-1 &gt; pivotIndex { return quickselect(nums, pivotIndex+1, end, k) } else { return quickselect(nums, start, pivotIndex-1, k) } } func partition(nums []int, start, end, pivot int) int { // move pivot to end nums[end], nums[pivot] = nums[pivot], nums[end] pivotValue := nums[end] i := start for j := start; j &lt; end; j++ { if nums[j] &gt; pivotValue { nums[i], nums[j] = nums[j], nums[i] i++ } } // move pivot to its sorted position nums[i], nums[end] = nums[end], nums[i] // return pivot index return i } ","link":"https://ninglg.com/post/search-algorithm/"},{"title":"排序算法","content":"排序算法 冒泡排序 func BubbleSort(data []int) { n := len(data) if data == nil || n &lt; 2 { return } for i := 0; i &lt; n-1; i++ { for j := 0; j &lt; n-i-1; j++ { // 冒泡排序是一种交换排序，核心是冒泡，排序过程中两两比较相邻记录的元素，每轮确定一个元素的位置。 if data[j] &gt; data[j+1] { data[j], data[j+1] = data[j+1], data[j] } } } } 快速排序 package main import &quot;fmt&quot; func main() { nums := []int{4, 7, 3, 1, 0, 9, 2, 8, 6, 5} QuickSort(nums, 0, 9) fmt.Println(nums) } func QuickSort(data []int, left, right int) { val := data[(left+right)/2] i, j := left, right for data[j] &gt; val { j-- } for data[i] &lt; val { i++ } data[i], data[j] = data[j], data[i] i++ j-- // 递归的方式 if i &lt; right { QuickSort(data, i, right) } if j &gt; left { QuickSort(data, left, j) } } 插入排序 func InsertSort(data []int) { n := len(data) for i := 0; i &lt; n; i++ { t := data[i] // 类似于洗扑克牌，把每个元素插入到前面合适的位置上 for j := i - 1; j &gt;= 0; j-- { if t &lt; data[j] { // 比较并插入 data[j+1], data[j] = data[j], t } else { //前面已经是排好序的，如果比最后一个还大，则此元素无需继续比较 break } } } } 希尔排序 希尔排序的实质就是分组插入排序。 先将整个待排元素序列分割成若干个子序列（由相隔某个“增量”的元素组成）分别进行直接插入排序，然后依次缩减增量再进行排序，待整个序列中的元素基本有序（增量足够小）时，再对全体元素进行一次直接插入排序。 func ShellSort(data []int) { n := len(data) h := 1 for h &lt; n/3 { //寻找合适的间隔h h = 3*h + 1 } for h &gt;= 1 { //将数组变为间隔h个元素有序 for i := h; i &lt; n; i++ { //间隔h插入排序 for j := i; j &gt;= h &amp;&amp; data[j] &lt; data[j-h]; j -= h { data[j], data[j-h] = data[j-h], data[j] } } h /= 3 } } 选择排序 func SelectionSort(data []int) { n := len(data) for i := 0; i &lt; n; i++ { // 循环找到最小元素的坐标，每轮交换一个 m := i for j := i + 1; j &lt; n; j++ { if data[j] &lt; data[m] { m = j } } data[i], data[m] = data[m], data[i] } } 堆排序 归并排序 计数排序 基数排序 桶排序 ","link":"https://ninglg.com/post/sort-algorithm/"},{"title":"常用算法时间复杂度速查表","content":"常用算法时间复杂度速查表 图例 抽象数据结构时间复杂度 排序算法时间复杂度 图操作时间复杂度 堆操作时间复杂度 大O表示法复杂度曲线 ","link":"https://ninglg.com/post/algorithm-time-complexity-cheat-sheet/"},{"title":"常用算法思想","content":"常用算法思想 穷举 递归 分治 动态规划 贪心 回溯 ","link":"https://ninglg.com/post/common-algorithm-thoughts/"},{"title":"awk命令的一些常见用法","content":"此篇介绍一下awk命令的一些常见用法。 awk命令的使用模式 awk 'BEGIN{}pattern{commands}END{}' file_name 取出第2列的内容 awk -F',' '{print $2}' data.txt 输出每一行有多少列 awk '{print NF}' data.txt 输出每一行最后一列的值 awk '{print $NF}' data.txt 如果第一列小于第二列则打印此行 awk '{if ($1 &lt; $2) print $0}' data.txt 如果第一列大于100则打印第一列，否则打印ok awk '{if ($1 &gt; 100) print $1; else print &quot;ok&quot;}' data.txt 打印除最后列之外的所有列 awk -F':' {'$NF=&quot;&quot;;print $0'} data.txt 打印s在每一行第一个域中的位置，若为0表示没有这个字符 awk -F '#' '{print (index($1, &quot;s&quot;))}' data.txt 对某列的数字求和 awk '{sum += $1}END{print sum}' data.txt 在保持文件原有内容顺序的基础上删除重复的行 awk '!visited[$0]++' data.txt &gt; result.txt 1. visited[]相当于维护了一个关联数据，键为一行的内容，值为该行出现的次数 2. 省略的默认动作是打印该行 3. 如用sort会改变文件内容顺序，uniq仅能去重排序连续的行 NR，FNR，NF 1. NR表示从awk开始执行后，按照记录分隔符读取的数据次数。默认的记录分隔符为换行符，因此默认的就是读取的数据行数，NR可以理解为Number of Record的缩写。 2. 在awk处理多个输入文件的时候，在处理完第一个文件后，NR并不会从1开始，而是继续累加，因此就出现了FNR，每当处理一个新文件的时候，FNR就从1开始计数，FNR可以理解为File Number of Record。 3. NR==FNR：用于在读取两个或两个以上的文件时，判断是不是在读取第一个文件。 4. NF表示目前的记录被分割的字段的数目，NF可以理解为Number of Field。 处理多个文件 awk处理多个文件的基本语法是: awk -F分隔符 'BEGIN { 初始化 } { 循环执行部分 } END { 结束处理 }' file_list1 file_list2 其中BEGIN和END可以省略，-F也可以使用默认，循环执行部分，是按行对文件进行处理的。 ","link":"https://ninglg.com/post/awk-command-usage/"},{"title":"二进制安全的概念","content":"本篇介绍一下什么是二进制安全。 二进制安全 二进制安全是一种主要用于字符串操作函数相关的计算机编程术语。如果一个函数或方法能将任意输入作为原始的，无任何特殊格式意义的数据流，那么它就是二进制安全的。 非二进制安全 在C语言中，字符串里面不能包含空字符'\\0'，否则这个空字符会被当做是字符串结尾，这就不是二进制安全的，因为图片、音频等二进制数据里面也可能会有'\\0'字符。 后记 如果一个结构不使用空字符，而是比如使用len的值来判断字符串是否结束，那么这个结构就可以保存特殊数据格式，包括二进制数据，因为它是二进制安全的。 ","link":"https://ninglg.com/post/what-is-binary-safe/"},{"title":"Linux系统中软链接和硬链接的区别","content":"此篇介绍一下在Linux系统中软链接和硬链接的区别。 一切皆是文件 在Linux系统中，一切皆是文件。比如 普通文件 目录文件 链接文件 设备文件 文件描述符（File Descriptor） 文件描述符是内核为了高效管理已被打开的文件所创建的索引，其值是一个非负整数（通常是小整数）。 用于指代被打开的文件，所有执行 I/O 操作的系统调用都通过文件描述符。 示例如： 0 stdin 标准输入 1 stdout 标准输出 2 stderr 标准错误 在 comand ... 2&gt;&amp;1 | tail 中，2表示标准错误，1是标准输出，中间的 &amp; 表示后面跟的数字是文件描述符而不是一个文件。 软链接 ln -s from.txt to.txt ln命令默认创建的是硬链接，如果加入了“-s”参数，则会生成一个软链接。 软链接又叫符号链接。 软连接可以是任意文件或目录，可以链接不同文件系统的文件，在对符号文件进行读或写操作的时候，系统会自动把该操作转换为对源文件的操作，但删除链接文件时，系统仅仅删除链接文件，而不删除源文件本身，这一点类似于 Windows 操作系统下的快捷方式。 硬链接 Linux下的文件是通过索引节点（Inode）来识别文件。 在 Linux 的文件系统中，保存在磁盘分区中的文件不管是什么类型都给它分配一个编号，称为索引节点号(Inode Number)。 在 Linux 中，多个文件名指向同一索引节点是存在的，所以硬连接指通过索引节点来进行的连接，即每一个硬链接都是一个指向对应区域的文件。 硬链接的作用是允许一个文件拥有多个有效路径名，这样用户就可以建立硬链接到重要文件，以防止“误删”的功能。 只删除一个连接并不影响索引节点本身和其它的连接，只有当最后一个链接被删除后，文件的数据块及目录的连接才会被释放，也就是说，文件才会被真正删除。 ","link":"https://ninglg.com/post/difference-between-soft-link-and-hard-link-in-linux/"},{"title":"MySQL查询流程的阶段","content":"此篇简介一下MySQL一次查询流程经过的几个阶段。 图示 ","link":"https://ninglg.com/post/mysql-query-stage/"},{"title":"curl命令模拟Get/Post请求及上传文件","content":"此篇介绍一下curl命令的一些常见用法，比如get、post请求，上传文件等。 get curl http://www.baidu.com curl -v http://www.baidu.com post curl http://www.baidu.com -X POST -d &quot;name=xiaowang&amp;age=17&quot; 还可用 -X PUT 和 -X DELETE 来指定另外的请求方法。 curl http://www.baidu.com -X POST -H &quot;Content-Type:application/json&quot; -d '&quot;name&quot;:&quot;xiaowang&quot;,&quot;age&quot;:&quot;17&quot;' file curl http://www.baidu.com -F &quot;file=@/Users/xiaowang/test.jpg&quot; -H &quot;token:xxxxx&quot; ","link":"https://ninglg.com/post/curl-get-post-file/"},{"title":"常见系统性能指标的英文缩写","content":"此篇介绍一下常见的几个系统性能指标的英文缩写。 指标 全程 含义 QPS Queries Per Second 每秒查询数 TPS Transactions Per Second 每秒处理的事务数目 PV Page View 页面浏览量 UV Unique Visitor 独立访客访问数 GMV Gross Merchandise Volume 商品交易总额 IP Internet Protocol 独立IP数 RPS Requests Per Second 吞吐率，与QPS类似 ","link":"https://ninglg.com/post/system-performance-index/"},{"title":"Mac系统上查询端口占用的命令","content":"此篇介绍一下在Mac上如何查询端口占用的情况。 netstat netstat -an | grep 8080 上述命令可以查询端口是否被占用，如被占用显示类似： tcp4 0 0 *.8080 *.* LISTEN lsof lsof -i:8080 其中i参数表示网络链接，:8080是端口号，该命令同时会列出PID，方便用户进行kill操作。类似： COMMAND PID USER FD TYPE DEVICE SIZE/OFF NODE NAME nginx 451 abc 6u IPv4 bdafc6 0t0 TCP *:http-alt (LISTEN) nginx 544 abc 6u IPv4 bdafc6 0t0 TCP *:http-alt (LISTEN) ","link":"https://ninglg.com/post/mac-port-used-netstat-lsof/"},{"title":"PHP单例设计模式","content":"本篇介绍一下PHP中的单例模式特点及实例。 什么是单例 单例模式，主要是保证在面向对象编程设计中，一个类只能有一个实例对象存在（即仅实例化一次）。 单例的优点 PHP的每次请求访问都是一次独立的进程，比如为了执行多个SQL语句，只实例化一次数据库连接就足够了，可以提高效率 使用单例模式可以避免大量的new操作，减少对资源的消耗，节省内存 单例的应用场景 建立目录 数据库连接及操作 系统日志 单例的实现方法 所有的单例模式都至少拥有以下3种公共元素： 拥有一个构造函数，并且必须被标记为private 拥有一个保存类的实例的静态成员变量 拥有一个访问这个实例的公共静态方法，用于创建或获取它本身的静态私有对象 单例的例子 第一种： &lt;?php /** * PHP单例类 */ class Singleton { /** * 私有静态变量，保存全局实例 */ private static $_instance = null; /** * 私有化默认构造方法，保证外界无法直接实例化，只能内部使用new去创建对象 */ private function __construct() { // 可以在此处实现一些数据库连接等操作 } /** * 静态工厂方法，返回此类的唯一实例 */ public static function getInstance() { if (is_null(self::$_instance)) { self::$_instance = new self(); // 实例化本类对象 } return self::$_instance; } /** * 防止用户克隆实例 */ public function __clone(){ die('Clone is not allowed.' . E_USER_ERROR); } /** * 测试用方法 */ public function test() { echo 'Singleton Test!'; } } /** * 客户端 */ class Client { public static function main() { $instance = Singleton::getInstance(); $instance-&gt;test(); } } Client::main(); 第二种： static function getInstance($class, $param = array()) { if (!isset($obj[$class])) { $obj[$class] = new $class($param); } return $obj[$class]; } ","link":"https://ninglg.com/post/php-singleton/"},{"title":"年轻人的副业","content":"关于副业、兴趣、财富自由这回事。 给别人打工只能谋生，替自己干活才能创富。 副业的好处 抵抗不确定性 副业带来额外的经济收入，可以帮助抵抗经济的不确定性。 做更喜欢的事情 副业带给你更多的选择，可以根据自己的特点选择自己擅长和喜欢的事情和方向。 创造并拥有 为自己创造一些东西，并拥有这些东西的所有权，这是一件非常棒的事情。 做副业就是创造一种用来支持你的生活、你的目标和你的梦想的方式。当然，也能为你带来经济收入。 副业的类型 教学型副业：推广自己擅长的技能 服务型副业：需求了解的越多，得到的回应就越多，生活就会更丰富 填补空白型副业：关注你周边的人，寻找你能满足的需求 临时工作型副业：零工经济，自由职业，短期工作 销售型副业：世界充满了物质，等待有眼光的人去挖掘 创造型副业：与其销售一种制成品，不如考虑自己创造一些东西来销售 三个建议 从你的兴趣出发，努力奋斗到你的兴趣金字塔顶端。 提升自己的认知视角，在你熟视无睹的现象背后，让自己有能力看到别人看不到的东西。 系统整理自己的资源和时间，合理分配有效资源和有效时间，耐心坚持，待机补位。 又三个建议 一定要扩大自己的人脉圈子。 一定不要停止学习的脚步。 想办法开发自己的斜杠能力。 ","link":"https://ninglg.com/post/youth-sideline/"},{"title":"启用php-fpm的状态页","content":"此篇介绍一下启用php-fpm的status后获取到的运行状态信息。 启用php-fpm状态功能 # cat php-fpm.conf | grep status_path pm.status_path = /status nginx配置 server { listen 8080; server_name localhost; location ~ ^/(status|ping)$ { include fastcgi_params; fastcgi_pass 127.0.0.1:9000; fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; } } 重启php-fpm和nginx 打开status页面 # curl 'http://127.0.0.1:8080/status' pool: www //池子名称，大多为www process manager: dynamic //进程管理方式，有static、dynamic或ondemand start time: 14/Jul/2010:10:09:03 +0800 //启动日期，如果reload了php-fpm时间会更新 start since: 3290 //运行时长 accepted conn: 6 //当前池子接受的请求数 listen queue: 0 //请求等待队列，如果此值不为0，则需要增加fpm的进程数量 max listen queue: 0 //请求等待队列最高的数量 listen queue len: 0 //socket等待队列长度 idle processes: 1 //空闲进程数量 active processes: 1 //活跃进程数量 total processes: 2 //总进程数量 max active processes: 1 //最大的活跃进程数量（fpm启动开始算） max children reached: 0 //达到进程最大数量限制的次数，如果此值不为0则要增加进程数 slow requests: 0 //启动fpm的slow-log，慢请求的数量 其他参数 php-fpm状态页可以带参数如json、xml、html并且可以和full做组合。 # curl 'http://127.0.0.1:8080/status?json' # curl 'http://127.0.0.1:8080/status?xml' # curl 'http://127.0.0.1:8080/status?html' # curl 'http://127.0.0.1:8080/status?full' php-fpm的状态页可以用作监控数据观察，展示的话，使用zabbix或者nagios时可以考虑用xml或者默认方式。用web展示的话，可以直接用html格式表格结果。 ","link":"https://ninglg.com/post/php-fpm-status-path/"},{"title":"Linux常用分析定位工具命令","content":"此篇记录一下工作中常用的Linux分析、定位、工具命令。 日志 记录很多信息，系统有问题时的必查文件 /var/log/messages Top top 命令中关于程序使用内存的项介绍： %MEM：Memory usage (RES) 内存占用 使用的物理内存 VIRT：Virtual Image (kb) 虚拟镜像 总虚拟内存的使用数量 SWAP：Swapped size (kb) 非驻留但是存在于程序中的内存，虚拟内存减去物理内存 RES：Resident size (kb) 非 swap 的物理内存 SHR：Shared Mem size (kb) 程序使用的共享内存，可以被其它进程所共享 系统类 CPU总核数 = 物理CPU个数 * 每颗物理CPU的核数 总逻辑CPU数 = 物理CPU个数 * 每颗物理CPU的核数 * 超线程数 查看CPU信息（型号） cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c 查看物理CPU个数 cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l 查看每个物理CPU中core的个数（即核数） cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq 查看逻辑CPU的个数 cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l 查看服务器IP连接数 netstat -tun | awk '{print $5}' | cut -d : -f1 | sort | uniq -c | sort -n 查看是否有僵死进程 lsof | grep deleted 查找文件 命令 作用 说明 which 查看可执行文件的位置 通过 PATH 环境变量到该路径内查找可执行文件 whereis 查看文件的位置 只能查二进制文件（含可执行文件）、说明文档，源文件等，可能有延迟 locate 配合文件数据库查看文件位置 在数据库里查找，数据库大致每天更新一次，文件名是部分匹配 find 实际搜寻硬盘来查询文件名称 最强大，根据条件查找文件，在硬盘上查找效率较低 查找当前路径下大于1M的文件 find . -size +1M 查找当前目录下5天之内修改且以conf结尾的文件 find . -mtime -5 -name '*.conf' 统计类 awk 求和 awk 'BEGIN{sum=0}{sum+=$1}END{print sum}' num.txt grep grep 'keywords' data.txt grep -C5 'keywords' data.txt // 显示keywords的所在行及前后5行的信息 grep -A5 'keywords' data.txt // 显示keywords的所在行及之后5行的信息 grep -B5 'keywords' data.txt // 显示keywords的所在行及之前5行的信息 iostat 监控磁盘IO iostat 1 网络/磁盘IO 网络IO：数据通过以太网接口进行读写时也会造成阻塞，阻塞情况跟网络带宽有关。 netstat 查看网络状态 netstat -an | grep 8080 查看特定的几种网络连接状态 netstat -lna | egrep &quot;TIME_WAIT | CLOSE_WAIT | ESTABLISHED&quot; 文件处理 uniq 使用uniq求文件的交集、并集和差集 交集 sort a.txt b.txt | uniq -d sort后面的参数，如 -n 表示按照数字格式排序，如 -i 表示忽略大小写，如-r 表示为逆序输出。 uniq为删除文件中重复的行，得到文件中唯一的行，参数 -d 表示的是输出出现次数大于1的内容，参数-u表示的是输出出现次数为1的内容。 并集 sort a.txt b.txt | uniq 差集 a.txt-b.txt: sort a.txt b.txt b.txt | uniq -u 将两个文件排序，最后输出a.txt b.txt b.txt文件中只出现过一次的内容，因为有两个b.txt，所以只会输出只在a.txt出现过一次的内容，即a.txt-b.txt差集。对于b.txt-a.txt同理。 b.txt - a.txt: sort b.txt a.txt a.txt | uniq -u 磁盘信息 df -lh curl curl -o /dev/null -s -w &quot; http_code:%{http_code}\\n time_namelookup:%{time_namelookup}\\n time_redirect:%{time_redirect}\\n time_pretransfer:%{time_pretransfer}\\n time_connect:%{time_connect}\\n time_starttransfer:%{time_starttransfer}\\n time_total:%{time_total}\\n speed_download:%{speed_download}\\n &quot; &quot;https://www.baidu.com&quot; curl输出 http_code:200 time_namelookup:0.014694 //DNS解析时间,从请求开始到DNS解析完毕所用时间。 time_redirect:0.000000 //重定向时间，包括到最后一次传输前的几次重定向的DNS解析，连接，预传输，传输时间。 time_pretransfer:0.049093 //从开始到准备传输的时间。 time_connect:0.020436 //连接时间,从开始到建立TCP连接完成所用时间,包括前边DNS解析时间，如果需要单纯的得到连接时间，用这个time_connect时间减去前边time_namelookup时间。 time_starttransfer:0.056731 //开始传输时间。在发出请求之后，Web 服务器返回数据的第一个字节所用的时间。 time_total:0.056884 //总时间，按秒计。精确到小数点后三位。 speed_download:43625.000 另外，如有： time_appconnect //连接建立完成时间，如SSL/SSH等建立连接或者完成三次握手时间。 lsof 列出打开的文件及相应的进程（list open files） lsof -i:8080 进程/调用 strace 使用 strace 跟踪用户进程和 Linux 内核之间的交互 测试 ab Apache Benchmarking tool，一个简易的压力测试工具命令。 ab -c 500 -t 10 -r &quot;http://127.0.0.1:8080/&quot; 参数释义如下： 参数 含义 c 并发量。默认是一次一个。 t 测试执行时间，单位为秒。默认没有时间限制。 r 即使遇到socket接收报错也不退出 n 请求的总数量。默认时，仅执行一个请求。 k 使用HTTP KeepAlive特性，即在一个HTTP会话中执行多个请求 p 需要post的数据文件 v 显示详细信息 V 显示版本号并退出 i 执行HEAD请求，而不是GET w 以html表格方式输出结果 x 设置属性的字符串 X 对请求使用代理服务器 C 对请求附加一个Cookie行 H 对请求附加额外的头信息 T POST数据所使用的Content-type 头信息 使用ab进行post请求压测： ab -n 1000 -c 100 -p text.json http://127.0.0.1:8080 注意：在使用ab命令时，如果并发过高时出现错误：Too many open files，则说明系统打开文件数量被限制了。 查看系统打开文件数量，使用命令：ulimit -a。 修改打开文件数量，修改成102400，命令：ulimit -n 102400。 查看修改后情况，使用命令：ulimit -n。 httpstat httpstat是一个外部工具，可以使用 brew install httpstat 单独安装。 httpstat https://www.baidu.com HTTP/1.1 200 OK Accept-Ranges: bytes Cache-Control: private, no-cache, no-store, proxy-revalidate, no-transform Connection: keep-alive Content-Length: 2443 Content-Type: text/html Date: Sun, 22 Dec 2009 11:15:09 GMT Etag: &quot;588603eb-98b&quot; Last-Modified: Mon, 23 Jan 2009 13:23:55 GMT Pragma: no-cache Server: bfe/1.0.8.18 Set-Cookie: BDORZ=27315; max-age=86400; domain=.baidu.com; path=/ DNS Lookup TCP Connection TLS Handshake Server Processing Content Transfer [ 117ms | 10ms | 32ms | 20ms | 1ms ] | | | | | namelookup:117ms | | | | connect:127ms | | | pretransfer:159ms | | starttransfer:179ms | total:180ms httpstat 作用类似如下： curl -s -o /dev/null -w &quot;\\ntime_namelookup: %{time_namelookup}\\ntime_connect: %{time_connect}\\ntime_appconnect: %{time_appconnect}\\ntime_redirect: %{time_redirect}\\ntime_pretransfer: %{time_pretransfer}\\ntime_starttransfer: %{time_starttransfer}\\n-----------------------------\\ntime_total: %{time_total}\\n&quot; https://www.baidu.com ","link":"https://ninglg.com/post/linux-profiling-debug-tool-command/"},{"title":"虚拟化Xen和KVM的区别","content":"此篇简要介绍一下Xen和KVM。 虚拟化 虚拟化：是指通过虚拟化技术将一台计算机虚拟为多台逻辑计算机。在一台计算机上同时运行多个逻辑计算机，每个逻辑计算机可运行不同的操作系统，并且应用程序都可以在相互独立的空间内运行而互不影响，从而显著提高计算机的工作效率。 全虚拟化：运行在虚拟环境的虚拟机无法感知到自己是运行在虚拟环境之上，只会觉得自己是运行在硬件之上 半虚拟化：运行在虚拟环境的虚拟机可以感知到自己不是直接运行在硬件环境之上 Xen Xen是Linux上的一种应用 Xen的实现方法是运行支持Xen功能的kernel，这个kernel是工作在 Xen的控制之下，叫做Domain0，使用这个kernel启动机器后，你可以在这个机器上使用qemu软件，虚拟出多个系统 Xen较为老旧，后期发展没有KVM迅猛 KVM KVM即Kernel-based Virtual Machine 内置于Linux内核中的一种虚拟化技术 KVM更轻量，更易管理，并且版本更新也可以随着内核的更新 KVM的内核模块叫做kvm.ko，实现对Linux的CPU和内存虚拟化，是Linux的一个进程，负责VCPU和内存的分配，而其他设备的虚拟就交给了qemu qemu运行在用户空间，KVM运行在内核，两者通过/dev/kvm进行交互，KVM仅支持全局虚拟化 磁盘I/O方面KVM更胜一筹 ","link":"https://ninglg.com/post/virtualization-xen-kvm/"},{"title":"Redis的客户端连接数验证","content":"此篇验证一下关于Redis的客户端连接数相关的内容。 查看连接相关的命令 查看clients信息 使用 info clients 命令查看clients相关的信息 # Clients connected_clients:1 client_recent_max_input_buffer:4 client_recent_max_output_buffer:0 blocked_clients:0 监测redis连接数是否会持续增长的命令 watch -n 2 &quot;redis-cli -h 127.0.0.1 -p 6379 info | grep 'connected_clients'&quot; 查看最大连接数限制 使用 config get maxclients 命令查看最大连接数限制 查看连接的client信息 使用 client list 命令查看连接的client信息 设置client连接的超时时间 使用 CONFIG SET timeout 30 命令设置client的连接idle过期时间，默认为0不过期 验证连接的验证脚本 link_redis.php // 短连接方式 &lt;?php set_time_limit (0); $redis = new redis(); $redis-&gt;connect('localhost', 6379); sleep(30); max_redis.php &lt;?php set_time_limit (0); for($i=1;$i&lt;=200;$i++){ exec(&quot;nohup php ./link_redis.php &gt; /dev/null &amp;&quot;); } ","link":"https://ninglg.com/post/redis-client-list-info/"},{"title":"PHP的curl_multi批量发送http请求","content":"此篇介绍一下php的curl_multi系列函数，用于批量发送http请求。 curl_multi原理 注意：CURL在PHP中的多线程处理其实并不是真正的多线程，而是用单线程批处理模拟的多线程效果。 curl_multi使用步骤 使用curl_multi的步骤总结如下： 调用curl_multi_init 循环调用curl_multi_add_handle，这里需要注意的是，curl_multi_add_handle的第二个参数是由curl_init而来的子handle 持续调用curl_multi_exec 根据需要循环调用curl_multi_getcontent获取结果 调用curl_multi_remove_handle，并为每个子handle调用curl_close 调用curl_multi_close 各函数作用解释 curl_multi_init() 初始化一个curl批处理句柄资源。 curl_multi_add_handle() 向curl批处理会话中添加单独的curl句柄资源。 curl_multi_add_handle()函数有两个参数，第一个参数表示一个curl批处理句柄资源，第二个参数表示一个单独的curl句柄资源。 curl_multi_exec() 解析一个curl批处理句柄，curl_multi_exec()函数有两个参数，第一个参数表示一个批处理句柄资源，第二个参数是一个引用值的参数，表示剩余需要处理的单个的curl句柄资源数量。 curl_multi_remove_handle() 移除curl批处理句柄资源中的某个句柄资源，curl_multi_remove_handle()函数有两个参数，第一个参数表示一个curl批处理句柄资源，第二个参数表示一个单独的curl句柄资源。 curl_multi_close() 关闭一个批处理句柄资源。 curl_multi_getcontent() 在设置了CURLOPT_RETURNTRANSFER的情况下，返回获取的输出的文本流。 curl_multi_info_read() 获取当前解析的curl的相关传输信息。 示例代码 &lt;?php $start_time = microtime(true); echo &quot;\\n&quot;; $k = 10; while ($k &gt; 0) { $urls[] = &quot;http://127.0.0.1:8080&quot;; $k = $k - 1; } print_r(async_get_urls($urls)); echo &quot;\\n&quot;; $end_time = microtime(true); echo $end_time - $start_time; echo &quot;\\n&quot;; function async_get_urls($urls) { if (!is_array($urls)) return false; $result = []; $handle = []; $active = 0; $mh = curl_multi_init(); // 初始化一个curl批处理句柄资源 foreach($urls as $i =&gt; $url) { $ch = curl_init(); curl_setopt($ch, CURLOPT_URL, $url); curl_setopt($ch, CURLOPT_HEADER, false); curl_setopt($ch, CURLOPT_RETURNTRANSFER, true); // 返回而非输出 curl_setopt($ch, CURLOPT_TIMEOUT, 1); // 控制每一个请求的超时时间 /* // POST的数据 curl_setopt($ch, CURLOPT_POST, true); curl_setopt($ch, CURLOPT_POSTFIELDS, $postParams); */ curl_multi_add_handle($mh, $ch); // 向curl批处理会话中添加单独的curl句柄资源 $handle[$i] = $ch; } // 执行 /* curl_multi_exec在底层调用了libcurl的curl_multi_perform函数。 在curl7.20.0以前，此函数会返回一个CURLM_CALL_MULTI_PERFORM值，代表它希望立刻再一次被调用。所以就有了检查此返回值，再一次调用curl_multi_exec函数的demo。 在7.20.0之后，libcurl把这个工作自己在内部做了，所以就不用应用端再做了，直接调用curl_multi_exec，只检查$still_running参数就行了。但此种用法要注意用usleep或者select优化，避免造成cpu占用过高出现假死 */ /* do { curl_multi_exec($mh, $running); // 第二个参数表示剩余需要处理的单个curl句柄资源数量 usleep(250000); // 250000 = 0.25 sec } while ($running &gt; 0); */ do { $mrc = curl_multi_exec($mh, $active); } while ($mrc == CURLM_CALL_MULTI_PERFORM); // CURLM_CALL_MULTI_PERFORM (-1)：这意味着你需要再次调用curl_multi_exec()，因为仍有数据可供处理 while ($active &amp;&amp; $mrc == CURLM_OK) { // CURLM_OK(0)：如文档中所说：“都好了”。这意味着可能有更多的数据，但还没有到。 if (curl_multi_select($mh) != -1) { do { $mrc = curl_multi_exec($mh, $active); } while ($mrc == CURLM_CALL_MULTI_PERFORM); } } // 读取结果 foreach($handle as $i =&gt; $ch) { $content['total_time'] = curl_getinfo($ch)['total_time']; $content['error'] = curl_error($ch); $content['data'] = json_decode(curl_multi_getcontent($ch), true); $result[$i] = (curl_errno($ch) == 0) ? $content : false; } // 移除handle foreach($handle as $ch) { curl_multi_remove_handle($mh, $ch); // 移除curl批处理句柄资源中的某个句柄资源 } curl_multi_close($mh); // 关闭批处理句柄资源 return $result; } ","link":"https://ninglg.com/post/php-curl-multi-http-request/"},{"title":"PHP常见配置及使用技巧","content":"此篇记录一下PHP相关的部分配置项及使用技巧。 命令 作用 php --ini 查看当前使用的PHP版本以及php.ini所在的目录 php -i 查看PHP的配置信息 php-config --extension-dir PHP扩展安装目录 ","link":"https://ninglg.com/post/php-configuration-and-tips/"}]}